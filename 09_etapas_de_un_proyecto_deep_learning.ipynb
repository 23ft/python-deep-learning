{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "09-etapas-de-un-proyecto-deep-learning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FKNAOn5Ia7pG",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "# 09. Etapas de un proyecto Deep Learning\n",
        "[**Python Deep Learning** Introducción práctica con Keras y TensorFlow 2. Jordi Torres. Editorial Marcombo ISBN: 9788426728289 ](https://www.marcombo.com/python-deep-learning-9788426728289/)\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VcFrOCQOYU1R",
        "colab_type": "code",
        "outputId": "a19071ca-69d0-4239-8580-195e11ab2e86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n",
            "2.1.0-rc1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPB7-G8G-Sdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DtndO_D__Z2T",
        "colab_type": "text"
      },
      "source": [
        "## Descarga dataset Auto MPG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niPo3Nfh-bVz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset_path = keras.utils.get_file(\"auto-mpg.data\", \"https://archive.ics.uci.edu/ml/machine-learning-databases/auto-mpg/auto-mpg.data\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7TMTyo--bYr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "column_names = ['MPG','Cylinders','Displacement','Horsepower','Weight',   'Acceleration', 'Model Year', 'Origin'] \n",
        "\n",
        "raw_dataset = pd.read_csv(dataset_path, names=column_names,\n",
        "                      na_values = \"?\", comment='\\t',\n",
        "                      sep=\" \", skipinitialspace=True)\n",
        "\n",
        "dataset = raw_dataset.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEvgfenf-pEf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "a0e332c4-7679-4cf9-b8b4-d890d90edd17"
      },
      "source": [
        "dataset.tail()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>Origin</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MPG  Cylinders  Displacement  ...  Acceleration  Model Year  Origin\n",
              "393  27.0          4         140.0  ...          15.6          82       1\n",
              "394  44.0          4          97.0  ...          24.6          82       2\n",
              "395  32.0          4         135.0  ...          11.6          82       1\n",
              "396  28.0          4         120.0  ...          18.6          82       1\n",
              "397  31.0          4         119.0  ...          19.4          82       1\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QawPBGCl-vRd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "590afa6f-77c4-4b0d-9417-a4e8138064ed"
      },
      "source": [
        "dataset.isna().sum()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MPG             0\n",
              "Cylinders       0\n",
              "Displacement    0\n",
              "Horsepower      6\n",
              "Weight          0\n",
              "Acceleration    0\n",
              "Model Year      0\n",
              "Origin          0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ntm2wuai-vUY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = dataset.dropna()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFpVmTFz-vXM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "a10e3a15-68e7-4988-d11a-28637ea0107b"
      },
      "source": [
        "origin = dataset.pop('Origin')\n",
        "dataset['USA'] = (origin == 1)*1.0\n",
        "dataset['Europe'] = (origin == 2)*1.0\n",
        "dataset['Japan'] = (origin == 3)*1.0\n",
        "dataset.tail()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>MPG</th>\n",
              "      <th>Cylinders</th>\n",
              "      <th>Displacement</th>\n",
              "      <th>Horsepower</th>\n",
              "      <th>Weight</th>\n",
              "      <th>Acceleration</th>\n",
              "      <th>Model Year</th>\n",
              "      <th>USA</th>\n",
              "      <th>Europe</th>\n",
              "      <th>Japan</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>27.0</td>\n",
              "      <td>4</td>\n",
              "      <td>140.0</td>\n",
              "      <td>86.0</td>\n",
              "      <td>2790.0</td>\n",
              "      <td>15.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>44.0</td>\n",
              "      <td>4</td>\n",
              "      <td>97.0</td>\n",
              "      <td>52.0</td>\n",
              "      <td>2130.0</td>\n",
              "      <td>24.6</td>\n",
              "      <td>82</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>32.0</td>\n",
              "      <td>4</td>\n",
              "      <td>135.0</td>\n",
              "      <td>84.0</td>\n",
              "      <td>2295.0</td>\n",
              "      <td>11.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>28.0</td>\n",
              "      <td>4</td>\n",
              "      <td>120.0</td>\n",
              "      <td>79.0</td>\n",
              "      <td>2625.0</td>\n",
              "      <td>18.6</td>\n",
              "      <td>82</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>31.0</td>\n",
              "      <td>4</td>\n",
              "      <td>119.0</td>\n",
              "      <td>82.0</td>\n",
              "      <td>2720.0</td>\n",
              "      <td>19.4</td>\n",
              "      <td>82</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      MPG  Cylinders  Displacement  Horsepower  ...  Model Year  USA  Europe  Japan\n",
              "393  27.0          4         140.0        86.0  ...          82  1.0     0.0    0.0\n",
              "394  44.0          4          97.0        52.0  ...          82  0.0     1.0    0.0\n",
              "395  32.0          4         135.0        84.0  ...          82  1.0     0.0    0.0\n",
              "396  28.0          4         120.0        79.0  ...          82  1.0     0.0    0.0\n",
              "397  31.0          4         119.0        82.0  ...          82  1.0     0.0    0.0\n",
              "\n",
              "[5 rows x 10 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBXjhOwa_eFh",
        "colab_type": "text"
      },
      "source": [
        "## Separar los datos para entrenar y test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5yrXBybR_V7j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = dataset.sample(frac=0.8,random_state=0)\n",
        "test_dataset = dataset.drop(train_dataset.index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtq9cEZV_V-m",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_labels = train_dataset.pop('MPG')\n",
        "test_labels = test_dataset.pop('MPG')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FekCNTKP_WBI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 318
        },
        "outputId": "04ca38cb-cdd0-437c-89f1-bbe3e6df268e"
      },
      "source": [
        "train_stats = train_dataset.describe()\n",
        "train_stats = train_stats.transpose()\n",
        "train_stats"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Cylinders</th>\n",
              "      <td>314.0</td>\n",
              "      <td>5.477707</td>\n",
              "      <td>1.699788</td>\n",
              "      <td>3.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>4.0</td>\n",
              "      <td>8.00</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Displacement</th>\n",
              "      <td>314.0</td>\n",
              "      <td>195.318471</td>\n",
              "      <td>104.331589</td>\n",
              "      <td>68.0</td>\n",
              "      <td>105.50</td>\n",
              "      <td>151.0</td>\n",
              "      <td>265.75</td>\n",
              "      <td>455.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Horsepower</th>\n",
              "      <td>314.0</td>\n",
              "      <td>104.869427</td>\n",
              "      <td>38.096214</td>\n",
              "      <td>46.0</td>\n",
              "      <td>76.25</td>\n",
              "      <td>94.5</td>\n",
              "      <td>128.00</td>\n",
              "      <td>225.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Weight</th>\n",
              "      <td>314.0</td>\n",
              "      <td>2990.251592</td>\n",
              "      <td>843.898596</td>\n",
              "      <td>1649.0</td>\n",
              "      <td>2256.50</td>\n",
              "      <td>2822.5</td>\n",
              "      <td>3608.00</td>\n",
              "      <td>5140.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Acceleration</th>\n",
              "      <td>314.0</td>\n",
              "      <td>15.559236</td>\n",
              "      <td>2.789230</td>\n",
              "      <td>8.0</td>\n",
              "      <td>13.80</td>\n",
              "      <td>15.5</td>\n",
              "      <td>17.20</td>\n",
              "      <td>24.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Model Year</th>\n",
              "      <td>314.0</td>\n",
              "      <td>75.898089</td>\n",
              "      <td>3.675642</td>\n",
              "      <td>70.0</td>\n",
              "      <td>73.00</td>\n",
              "      <td>76.0</td>\n",
              "      <td>79.00</td>\n",
              "      <td>82.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>USA</th>\n",
              "      <td>314.0</td>\n",
              "      <td>0.624204</td>\n",
              "      <td>0.485101</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Europe</th>\n",
              "      <td>314.0</td>\n",
              "      <td>0.178344</td>\n",
              "      <td>0.383413</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Japan</th>\n",
              "      <td>314.0</td>\n",
              "      <td>0.197452</td>\n",
              "      <td>0.398712</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "              count         mean         std  ...     50%      75%     max\n",
              "Cylinders     314.0     5.477707    1.699788  ...     4.0     8.00     8.0\n",
              "Displacement  314.0   195.318471  104.331589  ...   151.0   265.75   455.0\n",
              "Horsepower    314.0   104.869427   38.096214  ...    94.5   128.00   225.0\n",
              "Weight        314.0  2990.251592  843.898596  ...  2822.5  3608.00  5140.0\n",
              "Acceleration  314.0    15.559236    2.789230  ...    15.5    17.20    24.8\n",
              "Model Year    314.0    75.898089    3.675642  ...    76.0    79.00    82.0\n",
              "USA           314.0     0.624204    0.485101  ...     1.0     1.00     1.0\n",
              "Europe        314.0     0.178344    0.383413  ...     0.0     0.00     1.0\n",
              "Japan         314.0     0.197452    0.398712  ...     0.0     0.00     1.0\n",
              "\n",
              "[9 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6-D516VCSUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def norm(x):\n",
        "  return (x - train_stats['mean']) / train_stats['std']\n",
        "\n",
        "normed_train_data = norm(train_dataset)\n",
        "normed_test_data = norm(test_dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmNpCfOqCwqv",
        "colab_type": "text"
      },
      "source": [
        "## Desarrollar el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "weuKq7XrCSZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# ULL! Canviar de llista a .add()\n",
        "def build_model():\n",
        "  model = keras.Sequential([\n",
        "    layers.Dense(64, activation='relu',\n",
        "                 input_shape=[len(train_dataset.keys())]),\n",
        "    layers.Dense(64, activation='relu'),\n",
        "    layers.Dense(1)\n",
        "  ])\n",
        "  return model\n",
        "\n",
        "model = build_model()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X26qUEEkCScP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 259
        },
        "outputId": "1c9bac07-c0e8-4449-c0f9-30efb0211a35"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 64)                640       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 4,865\n",
            "Trainable params: 4,865\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FpTRcHXDCSew",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = tf.keras.optimizers.RMSprop(0.001)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EWp8Vcl0CShg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vdfftlXWEG-e",
        "colab_type": "text"
      },
      "source": [
        "##entrenamiento del modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fOaq8eGtCSkd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "18a53b95-ffb1-4f0f-a874-62e724a78079"
      },
      "source": [
        "EPOCHS = 1000\n",
        "\n",
        "history = model.fit(\n",
        "  normed_train_data, train_labels,\n",
        "  epochs=EPOCHS, validation_split = 0.2, verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train on 251 samples, validate on 63 samples\n",
            "Epoch 1/1000\n",
            "251/251 [==============================] - 1s 3ms/sample - loss: 554.0268 - mae: 22.2723 - mse: 554.0269 - val_loss: 536.6461 - val_mae: 21.8698 - val_mse: 536.6461\n",
            "Epoch 2/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 496.5240 - mae: 21.0030 - mse: 496.5240 - val_loss: 474.7017 - val_mae: 20.4741 - val_mse: 474.7016\n",
            "Epoch 3/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 438.5456 - mae: 19.6473 - mse: 438.5456 - val_loss: 408.0192 - val_mae: 18.8656 - val_mse: 408.0192\n",
            "Epoch 4/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 374.3632 - mae: 18.0506 - mse: 374.3632 - val_loss: 334.7384 - val_mae: 16.9448 - val_mse: 334.7384\n",
            "Epoch 5/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 304.4670 - mae: 16.1581 - mse: 304.4670 - val_loss: 259.0270 - val_mae: 14.7249 - val_mse: 259.0270\n",
            "Epoch 6/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 235.0215 - mae: 14.0443 - mse: 235.0215 - val_loss: 188.7491 - val_mae: 12.3420 - val_mse: 188.7491\n",
            "Epoch 7/1000\n",
            "251/251 [==============================] - 0s 169us/sample - loss: 171.5527 - mae: 11.8264 - mse: 171.5527 - val_loss: 129.5380 - val_mae: 9.9554 - val_mse: 129.5380\n",
            "Epoch 8/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 118.6070 - mae: 9.6178 - mse: 118.6070 - val_loss: 84.6162 - val_mae: 7.8988 - val_mse: 84.6162\n",
            "Epoch 9/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 78.1894 - mae: 7.5166 - mse: 78.1894 - val_loss: 55.2185 - val_mae: 6.4835 - val_mse: 55.2185\n",
            "Epoch 10/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 51.9634 - mae: 5.7857 - mse: 51.9634 - val_loss: 41.3976 - val_mae: 5.5690 - val_mse: 41.3976\n",
            "Epoch 11/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 38.1290 - mae: 4.7871 - mse: 38.1290 - val_loss: 35.6659 - val_mae: 4.9746 - val_mse: 35.6659\n",
            "Epoch 12/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 31.5958 - mae: 4.3951 - mse: 31.5958 - val_loss: 32.3986 - val_mae: 4.6103 - val_mse: 32.3986\n",
            "Epoch 13/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 27.4585 - mae: 4.1086 - mse: 27.4585 - val_loss: 29.4485 - val_mae: 4.3482 - val_mse: 29.4485\n",
            "Epoch 14/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 24.3205 - mae: 3.8903 - mse: 24.3205 - val_loss: 27.1871 - val_mae: 4.1588 - val_mse: 27.1871\n",
            "Epoch 15/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 21.9623 - mae: 3.7202 - mse: 21.9623 - val_loss: 23.7509 - val_mae: 3.8763 - val_mse: 23.7509\n",
            "Epoch 16/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 19.8539 - mae: 3.4911 - mse: 19.8539 - val_loss: 21.1488 - val_mae: 3.6871 - val_mse: 21.1488\n",
            "Epoch 17/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 17.9496 - mae: 3.3257 - mse: 17.9496 - val_loss: 18.9959 - val_mae: 3.5727 - val_mse: 18.9959\n",
            "Epoch 18/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 16.4839 - mae: 3.1642 - mse: 16.4839 - val_loss: 17.4661 - val_mae: 3.3224 - val_mse: 17.4661\n",
            "Epoch 19/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 15.1603 - mae: 3.0271 - mse: 15.1603 - val_loss: 15.6237 - val_mae: 3.1992 - val_mse: 15.6237\n",
            "Epoch 20/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 14.0488 - mae: 2.8772 - mse: 14.0488 - val_loss: 14.2399 - val_mae: 3.0342 - val_mse: 14.2399\n",
            "Epoch 21/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 13.0132 - mae: 2.7521 - mse: 13.0132 - val_loss: 13.2702 - val_mae: 2.8966 - val_mse: 13.2702\n",
            "Epoch 22/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 12.2209 - mae: 2.6890 - mse: 12.2209 - val_loss: 12.1889 - val_mae: 2.7743 - val_mse: 12.1889\n",
            "Epoch 23/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 11.3306 - mae: 2.5255 - mse: 11.3306 - val_loss: 11.8105 - val_mae: 2.6688 - val_mse: 11.8105\n",
            "Epoch 24/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 10.7796 - mae: 2.4498 - mse: 10.7796 - val_loss: 11.0504 - val_mae: 2.6203 - val_mse: 11.0504\n",
            "Epoch 25/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 10.6091 - mae: 2.4116 - mse: 10.6091 - val_loss: 10.3728 - val_mae: 2.5578 - val_mse: 10.3728\n",
            "Epoch 26/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 9.8953 - mae: 2.3107 - mse: 9.8953 - val_loss: 9.9340 - val_mae: 2.4895 - val_mse: 9.9340\n",
            "Epoch 27/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 9.5893 - mae: 2.2644 - mse: 9.5893 - val_loss: 9.5975 - val_mae: 2.4479 - val_mse: 9.5975\n",
            "Epoch 28/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 9.3523 - mae: 2.2178 - mse: 9.3523 - val_loss: 9.3752 - val_mae: 2.4507 - val_mse: 9.3752\n",
            "Epoch 29/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 9.0213 - mae: 2.1681 - mse: 9.0213 - val_loss: 9.0816 - val_mae: 2.3826 - val_mse: 9.0816\n",
            "Epoch 30/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 8.7142 - mae: 2.1298 - mse: 8.7142 - val_loss: 8.9029 - val_mae: 2.3444 - val_mse: 8.9029\n",
            "Epoch 31/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 8.5422 - mae: 2.1021 - mse: 8.5422 - val_loss: 8.8020 - val_mae: 2.3495 - val_mse: 8.8020\n",
            "Epoch 32/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 8.3122 - mae: 2.0438 - mse: 8.3122 - val_loss: 8.5870 - val_mae: 2.3423 - val_mse: 8.5870\n",
            "Epoch 33/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 8.2579 - mae: 2.0503 - mse: 8.2579 - val_loss: 8.3753 - val_mae: 2.2981 - val_mse: 8.3753\n",
            "Epoch 34/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 8.0869 - mae: 2.0379 - mse: 8.0869 - val_loss: 8.4453 - val_mae: 2.2959 - val_mse: 8.4453\n",
            "Epoch 35/1000\n",
            "251/251 [==============================] - 0s 165us/sample - loss: 8.0568 - mae: 2.0279 - mse: 8.0568 - val_loss: 8.5083 - val_mae: 2.3011 - val_mse: 8.5083\n",
            "Epoch 36/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 7.9569 - mae: 1.9879 - mse: 7.9569 - val_loss: 8.4337 - val_mae: 2.3111 - val_mse: 8.4337\n",
            "Epoch 37/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 7.7251 - mae: 1.9836 - mse: 7.7251 - val_loss: 8.0591 - val_mae: 2.2432 - val_mse: 8.0591\n",
            "Epoch 38/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 7.7735 - mae: 2.0032 - mse: 7.7735 - val_loss: 8.7706 - val_mae: 2.4341 - val_mse: 8.7706\n",
            "Epoch 39/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 7.5737 - mae: 1.9309 - mse: 7.5737 - val_loss: 8.1281 - val_mae: 2.2452 - val_mse: 8.1281\n",
            "Epoch 40/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 7.3976 - mae: 1.9283 - mse: 7.3976 - val_loss: 8.2981 - val_mae: 2.3114 - val_mse: 8.2981\n",
            "Epoch 41/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 7.5871 - mae: 1.9603 - mse: 7.5871 - val_loss: 8.2721 - val_mae: 2.1943 - val_mse: 8.2721\n",
            "Epoch 42/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 7.5156 - mae: 1.9919 - mse: 7.5156 - val_loss: 8.3719 - val_mae: 2.3143 - val_mse: 8.3719\n",
            "Epoch 43/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 7.5323 - mae: 1.9587 - mse: 7.5323 - val_loss: 8.1289 - val_mae: 2.2860 - val_mse: 8.1289\n",
            "Epoch 44/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 7.3433 - mae: 1.9196 - mse: 7.3433 - val_loss: 8.1574 - val_mae: 2.2165 - val_mse: 8.1574\n",
            "Epoch 45/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 7.2391 - mae: 1.9163 - mse: 7.2391 - val_loss: 8.2933 - val_mae: 2.1735 - val_mse: 8.2933\n",
            "Epoch 46/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 7.1999 - mae: 1.9153 - mse: 7.1999 - val_loss: 8.2249 - val_mae: 2.1770 - val_mse: 8.2249\n",
            "Epoch 47/1000\n",
            "251/251 [==============================] - 0s 163us/sample - loss: 7.3063 - mae: 1.9261 - mse: 7.3063 - val_loss: 8.1435 - val_mae: 2.2352 - val_mse: 8.1435\n",
            "Epoch 48/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 7.3632 - mae: 1.9377 - mse: 7.3632 - val_loss: 8.0248 - val_mae: 2.2162 - val_mse: 8.0248\n",
            "Epoch 49/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 7.0826 - mae: 1.8738 - mse: 7.0826 - val_loss: 8.0393 - val_mae: 2.1925 - val_mse: 8.0393\n",
            "Epoch 50/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 7.2692 - mae: 1.9337 - mse: 7.2692 - val_loss: 8.0959 - val_mae: 2.2564 - val_mse: 8.0959\n",
            "Epoch 51/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 7.1169 - mae: 1.9011 - mse: 7.1169 - val_loss: 8.4284 - val_mae: 2.1699 - val_mse: 8.4284\n",
            "Epoch 52/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 7.1392 - mae: 1.8969 - mse: 7.1392 - val_loss: 8.0313 - val_mae: 2.2390 - val_mse: 8.0313\n",
            "Epoch 53/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 7.2898 - mae: 1.8989 - mse: 7.2898 - val_loss: 7.8988 - val_mae: 2.2015 - val_mse: 7.8988\n",
            "Epoch 54/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 6.8170 - mae: 1.8492 - mse: 6.8170 - val_loss: 8.0240 - val_mae: 2.2067 - val_mse: 8.0240\n",
            "Epoch 55/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 6.8911 - mae: 1.8727 - mse: 6.8911 - val_loss: 7.8449 - val_mae: 2.1678 - val_mse: 7.8449\n",
            "Epoch 56/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 6.9965 - mae: 1.8793 - mse: 6.9965 - val_loss: 7.8851 - val_mae: 2.1652 - val_mse: 7.8851\n",
            "Epoch 57/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 6.9259 - mae: 1.8810 - mse: 6.9259 - val_loss: 7.9184 - val_mae: 2.2293 - val_mse: 7.9184\n",
            "Epoch 58/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 6.9714 - mae: 1.8822 - mse: 6.9714 - val_loss: 8.3289 - val_mae: 2.3283 - val_mse: 8.3289\n",
            "Epoch 59/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 6.7183 - mae: 1.8329 - mse: 6.7183 - val_loss: 7.9762 - val_mae: 2.1830 - val_mse: 7.9762\n",
            "Epoch 60/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 6.6811 - mae: 1.8274 - mse: 6.6811 - val_loss: 8.2754 - val_mae: 2.1565 - val_mse: 8.2754\n",
            "Epoch 61/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 6.8304 - mae: 1.8569 - mse: 6.8304 - val_loss: 7.9064 - val_mae: 2.2230 - val_mse: 7.9064\n",
            "Epoch 62/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 6.8043 - mae: 1.8575 - mse: 6.8043 - val_loss: 7.8497 - val_mae: 2.1949 - val_mse: 7.8497\n",
            "Epoch 63/1000\n",
            "251/251 [==============================] - 0s 170us/sample - loss: 6.7230 - mae: 1.8476 - mse: 6.7230 - val_loss: 7.9655 - val_mae: 2.2370 - val_mse: 7.9655\n",
            "Epoch 64/1000\n",
            "251/251 [==============================] - 0s 158us/sample - loss: 6.8191 - mae: 1.8386 - mse: 6.8191 - val_loss: 8.1437 - val_mae: 2.2809 - val_mse: 8.1437\n",
            "Epoch 65/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 6.7588 - mae: 1.8477 - mse: 6.7588 - val_loss: 7.9589 - val_mae: 2.2287 - val_mse: 7.9589\n",
            "Epoch 66/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 6.7498 - mae: 1.8391 - mse: 6.7498 - val_loss: 8.0644 - val_mae: 2.2257 - val_mse: 8.0644\n",
            "Epoch 67/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 6.6299 - mae: 1.8304 - mse: 6.6299 - val_loss: 7.9666 - val_mae: 2.1532 - val_mse: 7.9666\n",
            "Epoch 68/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 6.6579 - mae: 1.8300 - mse: 6.6579 - val_loss: 8.0370 - val_mae: 2.1768 - val_mse: 8.0370\n",
            "Epoch 69/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 6.7637 - mae: 1.8324 - mse: 6.7637 - val_loss: 7.8936 - val_mae: 2.1673 - val_mse: 7.8936\n",
            "Epoch 70/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 6.5476 - mae: 1.8224 - mse: 6.5476 - val_loss: 7.8962 - val_mae: 2.1499 - val_mse: 7.8962\n",
            "Epoch 71/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 6.5994 - mae: 1.8144 - mse: 6.5994 - val_loss: 8.0850 - val_mae: 2.1800 - val_mse: 8.0850\n",
            "Epoch 72/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 6.6432 - mae: 1.8392 - mse: 6.6432 - val_loss: 8.0233 - val_mae: 2.2311 - val_mse: 8.0233\n",
            "Epoch 73/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 6.5941 - mae: 1.7852 - mse: 6.5941 - val_loss: 8.0900 - val_mae: 2.1457 - val_mse: 8.0900\n",
            "Epoch 74/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 6.6021 - mae: 1.8356 - mse: 6.6021 - val_loss: 7.8823 - val_mae: 2.1895 - val_mse: 7.8823\n",
            "Epoch 75/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 6.4214 - mae: 1.8068 - mse: 6.4214 - val_loss: 7.9063 - val_mae: 2.1732 - val_mse: 7.9063\n",
            "Epoch 76/1000\n",
            "251/251 [==============================] - 0s 157us/sample - loss: 6.4145 - mae: 1.7894 - mse: 6.4145 - val_loss: 8.1774 - val_mae: 2.1342 - val_mse: 8.1774\n",
            "Epoch 77/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 6.6960 - mae: 1.8299 - mse: 6.6960 - val_loss: 7.8421 - val_mae: 2.1898 - val_mse: 7.8421\n",
            "Epoch 78/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 6.3286 - mae: 1.7945 - mse: 6.3286 - val_loss: 8.5900 - val_mae: 2.3511 - val_mse: 8.5900\n",
            "Epoch 79/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 6.6877 - mae: 1.8102 - mse: 6.6877 - val_loss: 7.9489 - val_mae: 2.1864 - val_mse: 7.9489\n",
            "Epoch 80/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 6.2997 - mae: 1.7787 - mse: 6.2997 - val_loss: 8.0377 - val_mae: 2.2222 - val_mse: 8.0377\n",
            "Epoch 81/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 6.3449 - mae: 1.7886 - mse: 6.3449 - val_loss: 7.9528 - val_mae: 2.1851 - val_mse: 7.9528\n",
            "Epoch 82/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 6.4890 - mae: 1.7917 - mse: 6.4890 - val_loss: 8.2497 - val_mae: 2.1408 - val_mse: 8.2497\n",
            "Epoch 83/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 6.3067 - mae: 1.8028 - mse: 6.3067 - val_loss: 7.9085 - val_mae: 2.1778 - val_mse: 7.9085\n",
            "Epoch 84/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 6.4208 - mae: 1.7741 - mse: 6.4208 - val_loss: 7.9441 - val_mae: 2.1561 - val_mse: 7.9441\n",
            "Epoch 85/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 6.4247 - mae: 1.8098 - mse: 6.4247 - val_loss: 7.9145 - val_mae: 2.1768 - val_mse: 7.9145\n",
            "Epoch 86/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 6.5359 - mae: 1.8008 - mse: 6.5359 - val_loss: 7.9082 - val_mae: 2.1271 - val_mse: 7.9082\n",
            "Epoch 87/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 6.2983 - mae: 1.7744 - mse: 6.2983 - val_loss: 7.8544 - val_mae: 2.1460 - val_mse: 7.8544\n",
            "Epoch 88/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 6.2695 - mae: 1.7632 - mse: 6.2695 - val_loss: 7.9010 - val_mae: 2.1853 - val_mse: 7.9010\n",
            "Epoch 89/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 6.3787 - mae: 1.7931 - mse: 6.3787 - val_loss: 8.0105 - val_mae: 2.2443 - val_mse: 8.0105\n",
            "Epoch 90/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 6.2597 - mae: 1.7462 - mse: 6.2597 - val_loss: 7.8618 - val_mae: 2.1953 - val_mse: 7.8618\n",
            "Epoch 91/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 6.1155 - mae: 1.7281 - mse: 6.1155 - val_loss: 8.0199 - val_mae: 2.1317 - val_mse: 8.0199\n",
            "Epoch 92/1000\n",
            "251/251 [==============================] - 0s 158us/sample - loss: 6.3662 - mae: 1.7654 - mse: 6.3662 - val_loss: 7.9487 - val_mae: 2.1940 - val_mse: 7.9487\n",
            "Epoch 93/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 6.2251 - mae: 1.7415 - mse: 6.2251 - val_loss: 8.2662 - val_mae: 2.2584 - val_mse: 8.2662\n",
            "Epoch 94/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 6.0930 - mae: 1.7374 - mse: 6.0930 - val_loss: 8.5270 - val_mae: 2.3086 - val_mse: 8.5270\n",
            "Epoch 95/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 6.3824 - mae: 1.7704 - mse: 6.3824 - val_loss: 7.8949 - val_mae: 2.1847 - val_mse: 7.8949\n",
            "Epoch 96/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 6.0924 - mae: 1.7187 - mse: 6.0924 - val_loss: 8.1550 - val_mae: 2.1114 - val_mse: 8.1550\n",
            "Epoch 97/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 6.1040 - mae: 1.7516 - mse: 6.1040 - val_loss: 7.8699 - val_mae: 2.1357 - val_mse: 7.8699\n",
            "Epoch 98/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 6.0826 - mae: 1.7361 - mse: 6.0826 - val_loss: 8.0778 - val_mae: 2.2258 - val_mse: 8.0778\n",
            "Epoch 99/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 6.2871 - mae: 1.7740 - mse: 6.2871 - val_loss: 7.8835 - val_mae: 2.1586 - val_mse: 7.8835\n",
            "Epoch 100/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 6.1773 - mae: 1.7672 - mse: 6.1773 - val_loss: 7.9875 - val_mae: 2.1597 - val_mse: 7.9875\n",
            "Epoch 101/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 5.9960 - mae: 1.7294 - mse: 5.9960 - val_loss: 8.3521 - val_mae: 2.2864 - val_mse: 8.3521\n",
            "Epoch 102/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 6.0776 - mae: 1.7273 - mse: 6.0776 - val_loss: 8.0615 - val_mae: 2.2399 - val_mse: 8.0615\n",
            "Epoch 103/1000\n",
            "251/251 [==============================] - 0s 156us/sample - loss: 6.1493 - mae: 1.7301 - mse: 6.1493 - val_loss: 8.0089 - val_mae: 2.1246 - val_mse: 8.0089\n",
            "Epoch 104/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 6.2082 - mae: 1.7328 - mse: 6.2082 - val_loss: 8.1154 - val_mae: 2.1945 - val_mse: 8.1154\n",
            "Epoch 105/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 6.1199 - mae: 1.7597 - mse: 6.1199 - val_loss: 8.0047 - val_mae: 2.1331 - val_mse: 8.0047\n",
            "Epoch 106/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 6.1534 - mae: 1.7384 - mse: 6.1534 - val_loss: 7.9650 - val_mae: 2.2067 - val_mse: 7.9650\n",
            "Epoch 107/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 6.0934 - mae: 1.7389 - mse: 6.0934 - val_loss: 7.9532 - val_mae: 2.1395 - val_mse: 7.9532\n",
            "Epoch 108/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 6.1963 - mae: 1.7324 - mse: 6.1963 - val_loss: 7.9256 - val_mae: 2.1749 - val_mse: 7.9256\n",
            "Epoch 109/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 6.0455 - mae: 1.7166 - mse: 6.0455 - val_loss: 7.9230 - val_mae: 2.1292 - val_mse: 7.9230\n",
            "Epoch 110/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 5.9168 - mae: 1.7214 - mse: 5.9168 - val_loss: 7.9548 - val_mae: 2.1745 - val_mse: 7.9548\n",
            "Epoch 111/1000\n",
            "251/251 [==============================] - 0s 157us/sample - loss: 6.0682 - mae: 1.6951 - mse: 6.0682 - val_loss: 7.9454 - val_mae: 2.1071 - val_mse: 7.9454\n",
            "Epoch 112/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 6.0160 - mae: 1.7501 - mse: 6.0160 - val_loss: 7.9410 - val_mae: 2.1887 - val_mse: 7.9410\n",
            "Epoch 113/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 6.0386 - mae: 1.7114 - mse: 6.0386 - val_loss: 7.8567 - val_mae: 2.1268 - val_mse: 7.8567\n",
            "Epoch 114/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 5.8039 - mae: 1.6927 - mse: 5.8039 - val_loss: 8.0478 - val_mae: 2.1951 - val_mse: 8.0478\n",
            "Epoch 115/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 5.8658 - mae: 1.7014 - mse: 5.8658 - val_loss: 8.5701 - val_mae: 2.3028 - val_mse: 8.5701\n",
            "Epoch 116/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 6.1974 - mae: 1.7393 - mse: 6.1974 - val_loss: 7.9600 - val_mae: 2.1553 - val_mse: 7.9600\n",
            "Epoch 117/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 5.7607 - mae: 1.6856 - mse: 5.7607 - val_loss: 8.3138 - val_mae: 2.1137 - val_mse: 8.3138\n",
            "Epoch 118/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 5.8405 - mae: 1.7000 - mse: 5.8405 - val_loss: 8.2093 - val_mae: 2.1783 - val_mse: 8.2093\n",
            "Epoch 119/1000\n",
            "251/251 [==============================] - 0s 182us/sample - loss: 5.9155 - mae: 1.6925 - mse: 5.9155 - val_loss: 8.1564 - val_mae: 2.1948 - val_mse: 8.1564\n",
            "Epoch 120/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 6.0266 - mae: 1.7209 - mse: 6.0266 - val_loss: 7.9285 - val_mae: 2.1749 - val_mse: 7.9285\n",
            "Epoch 121/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 6.0674 - mae: 1.7186 - mse: 6.0674 - val_loss: 7.9841 - val_mae: 2.1312 - val_mse: 7.9841\n",
            "Epoch 122/1000\n",
            "251/251 [==============================] - 0s 159us/sample - loss: 5.8294 - mae: 1.7178 - mse: 5.8294 - val_loss: 7.8879 - val_mae: 2.2053 - val_mse: 7.8879\n",
            "Epoch 123/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 5.8206 - mae: 1.6953 - mse: 5.8206 - val_loss: 7.9452 - val_mae: 2.1891 - val_mse: 7.9452\n",
            "Epoch 124/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 5.9851 - mae: 1.6943 - mse: 5.9851 - val_loss: 7.9203 - val_mae: 2.2003 - val_mse: 7.9203\n",
            "Epoch 125/1000\n",
            "251/251 [==============================] - 0s 151us/sample - loss: 5.8430 - mae: 1.6801 - mse: 5.8430 - val_loss: 7.9810 - val_mae: 2.2270 - val_mse: 7.9810\n",
            "Epoch 126/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 5.9270 - mae: 1.6768 - mse: 5.9270 - val_loss: 7.8985 - val_mae: 2.1608 - val_mse: 7.8985\n",
            "Epoch 127/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 5.7750 - mae: 1.6651 - mse: 5.7750 - val_loss: 8.5054 - val_mae: 2.1349 - val_mse: 8.5054\n",
            "Epoch 128/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 6.0098 - mae: 1.7231 - mse: 6.0098 - val_loss: 7.7478 - val_mae: 2.1521 - val_mse: 7.7478\n",
            "Epoch 129/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 5.9183 - mae: 1.6861 - mse: 5.9183 - val_loss: 8.0951 - val_mae: 2.0970 - val_mse: 8.0951\n",
            "Epoch 130/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 5.7971 - mae: 1.7128 - mse: 5.7971 - val_loss: 7.9192 - val_mae: 2.1239 - val_mse: 7.9192\n",
            "Epoch 131/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 5.7737 - mae: 1.6853 - mse: 5.7737 - val_loss: 8.0898 - val_mae: 2.1063 - val_mse: 8.0898\n",
            "Epoch 132/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 5.9248 - mae: 1.7058 - mse: 5.9248 - val_loss: 7.7621 - val_mae: 2.1544 - val_mse: 7.7621\n",
            "Epoch 133/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 5.9386 - mae: 1.7327 - mse: 5.9386 - val_loss: 8.2321 - val_mae: 2.2845 - val_mse: 8.2321\n",
            "Epoch 134/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 5.8367 - mae: 1.6865 - mse: 5.8367 - val_loss: 7.9187 - val_mae: 2.1639 - val_mse: 7.9187\n",
            "Epoch 135/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 5.6048 - mae: 1.6552 - mse: 5.6048 - val_loss: 7.8253 - val_mae: 2.1419 - val_mse: 7.8253\n",
            "Epoch 136/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 5.6102 - mae: 1.6732 - mse: 5.6102 - val_loss: 8.0099 - val_mae: 2.1919 - val_mse: 8.0099\n",
            "Epoch 137/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 5.7840 - mae: 1.6886 - mse: 5.7840 - val_loss: 7.7791 - val_mae: 2.1436 - val_mse: 7.7791\n",
            "Epoch 138/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 5.8138 - mae: 1.7024 - mse: 5.8138 - val_loss: 7.9908 - val_mae: 2.2301 - val_mse: 7.9908\n",
            "Epoch 139/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 5.7770 - mae: 1.6780 - mse: 5.7770 - val_loss: 8.0468 - val_mae: 2.0986 - val_mse: 8.0468\n",
            "Epoch 140/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 5.6642 - mae: 1.6695 - mse: 5.6642 - val_loss: 8.1440 - val_mae: 2.2917 - val_mse: 8.1439\n",
            "Epoch 141/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 5.6303 - mae: 1.6299 - mse: 5.6303 - val_loss: 7.9002 - val_mae: 2.1198 - val_mse: 7.9002\n",
            "Epoch 142/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 5.7819 - mae: 1.6604 - mse: 5.7819 - val_loss: 8.1655 - val_mae: 2.2270 - val_mse: 8.1655\n",
            "Epoch 143/1000\n",
            "251/251 [==============================] - 0s 158us/sample - loss: 5.8081 - mae: 1.6823 - mse: 5.8081 - val_loss: 7.9258 - val_mae: 2.2069 - val_mse: 7.9258\n",
            "Epoch 144/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 5.6405 - mae: 1.6240 - mse: 5.6405 - val_loss: 8.4251 - val_mae: 2.1283 - val_mse: 8.4251\n",
            "Epoch 145/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 5.6849 - mae: 1.6823 - mse: 5.6849 - val_loss: 7.9348 - val_mae: 2.1496 - val_mse: 7.9348\n",
            "Epoch 146/1000\n",
            "251/251 [==============================] - 0s 181us/sample - loss: 5.5527 - mae: 1.6606 - mse: 5.5527 - val_loss: 7.8086 - val_mae: 2.1537 - val_mse: 7.8086\n",
            "Epoch 147/1000\n",
            "251/251 [==============================] - 0s 193us/sample - loss: 5.6168 - mae: 1.6592 - mse: 5.6168 - val_loss: 7.7315 - val_mae: 2.1408 - val_mse: 7.7315\n",
            "Epoch 148/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 5.7189 - mae: 1.6678 - mse: 5.7189 - val_loss: 7.7786 - val_mae: 2.1093 - val_mse: 7.7786\n",
            "Epoch 149/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 5.7782 - mae: 1.7015 - mse: 5.7782 - val_loss: 7.7283 - val_mae: 2.1354 - val_mse: 7.7283\n",
            "Epoch 150/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 5.5560 - mae: 1.6360 - mse: 5.5560 - val_loss: 7.8108 - val_mae: 2.1709 - val_mse: 7.8108\n",
            "Epoch 151/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 5.6391 - mae: 1.6538 - mse: 5.6391 - val_loss: 7.8578 - val_mae: 2.1968 - val_mse: 7.8578\n",
            "Epoch 152/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 5.7012 - mae: 1.6677 - mse: 5.7012 - val_loss: 8.1829 - val_mae: 2.2479 - val_mse: 8.1829\n",
            "Epoch 153/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 5.5075 - mae: 1.6302 - mse: 5.5075 - val_loss: 7.8938 - val_mae: 2.1616 - val_mse: 7.8938\n",
            "Epoch 154/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 5.7145 - mae: 1.6439 - mse: 5.7145 - val_loss: 7.9641 - val_mae: 2.1521 - val_mse: 7.9641\n",
            "Epoch 155/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 5.6918 - mae: 1.6746 - mse: 5.6918 - val_loss: 7.9055 - val_mae: 2.1828 - val_mse: 7.9055\n",
            "Epoch 156/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 5.6277 - mae: 1.6510 - mse: 5.6277 - val_loss: 8.0557 - val_mae: 2.2052 - val_mse: 8.0557\n",
            "Epoch 157/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 5.5365 - mae: 1.6589 - mse: 5.5365 - val_loss: 7.9780 - val_mae: 2.2144 - val_mse: 7.9780\n",
            "Epoch 158/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 5.7471 - mae: 1.6636 - mse: 5.7471 - val_loss: 8.1429 - val_mae: 2.1131 - val_mse: 8.1429\n",
            "Epoch 159/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 5.7338 - mae: 1.6824 - mse: 5.7338 - val_loss: 7.8431 - val_mae: 2.1629 - val_mse: 7.8431\n",
            "Epoch 160/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 5.3785 - mae: 1.6136 - mse: 5.3785 - val_loss: 8.1881 - val_mae: 2.1026 - val_mse: 8.1881\n",
            "Epoch 161/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 5.7024 - mae: 1.6619 - mse: 5.7024 - val_loss: 7.8186 - val_mae: 2.1452 - val_mse: 7.8186\n",
            "Epoch 162/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 5.5032 - mae: 1.6312 - mse: 5.5032 - val_loss: 7.8002 - val_mae: 2.1296 - val_mse: 7.8002\n",
            "Epoch 163/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 5.5706 - mae: 1.6529 - mse: 5.5706 - val_loss: 8.2633 - val_mae: 2.1654 - val_mse: 8.2633\n",
            "Epoch 164/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 5.5154 - mae: 1.6734 - mse: 5.5154 - val_loss: 7.9149 - val_mae: 2.1947 - val_mse: 7.9149\n",
            "Epoch 165/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 5.4995 - mae: 1.6191 - mse: 5.4995 - val_loss: 7.9389 - val_mae: 2.1713 - val_mse: 7.9389\n",
            "Epoch 166/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 5.5261 - mae: 1.6300 - mse: 5.5261 - val_loss: 8.0498 - val_mae: 2.1702 - val_mse: 8.0498\n",
            "Epoch 167/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 5.4581 - mae: 1.6054 - mse: 5.4581 - val_loss: 7.9770 - val_mae: 2.1597 - val_mse: 7.9770\n",
            "Epoch 168/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 5.4073 - mae: 1.6138 - mse: 5.4073 - val_loss: 7.8885 - val_mae: 2.1741 - val_mse: 7.8885\n",
            "Epoch 169/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 5.4404 - mae: 1.6418 - mse: 5.4404 - val_loss: 7.8499 - val_mae: 2.1620 - val_mse: 7.8499\n",
            "Epoch 170/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 5.3003 - mae: 1.6083 - mse: 5.3003 - val_loss: 8.3641 - val_mae: 2.1244 - val_mse: 8.3641\n",
            "Epoch 171/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 5.6873 - mae: 1.6468 - mse: 5.6873 - val_loss: 8.0316 - val_mae: 2.1765 - val_mse: 8.0316\n",
            "Epoch 172/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 5.4284 - mae: 1.6284 - mse: 5.4284 - val_loss: 7.7588 - val_mae: 2.1736 - val_mse: 7.7588\n",
            "Epoch 173/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 5.4908 - mae: 1.6293 - mse: 5.4908 - val_loss: 7.8950 - val_mae: 2.1688 - val_mse: 7.8950\n",
            "Epoch 174/1000\n",
            "251/251 [==============================] - 0s 163us/sample - loss: 5.4311 - mae: 1.6121 - mse: 5.4311 - val_loss: 7.9142 - val_mae: 2.1451 - val_mse: 7.9142\n",
            "Epoch 175/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 5.4946 - mae: 1.6150 - mse: 5.4946 - val_loss: 7.9992 - val_mae: 2.1059 - val_mse: 7.9992\n",
            "Epoch 176/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 5.5856 - mae: 1.6588 - mse: 5.5856 - val_loss: 7.7327 - val_mae: 2.1679 - val_mse: 7.7327\n",
            "Epoch 177/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 5.3825 - mae: 1.6235 - mse: 5.3825 - val_loss: 7.8117 - val_mae: 2.1705 - val_mse: 7.8117\n",
            "Epoch 178/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 5.4129 - mae: 1.6056 - mse: 5.4129 - val_loss: 7.7625 - val_mae: 2.2069 - val_mse: 7.7625\n",
            "Epoch 179/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 5.3330 - mae: 1.6088 - mse: 5.3330 - val_loss: 7.7074 - val_mae: 2.1387 - val_mse: 7.7074\n",
            "Epoch 180/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 5.5452 - mae: 1.6145 - mse: 5.5452 - val_loss: 7.7452 - val_mae: 2.1058 - val_mse: 7.7452\n",
            "Epoch 181/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 5.3947 - mae: 1.6106 - mse: 5.3947 - val_loss: 8.2195 - val_mae: 2.1160 - val_mse: 8.2195\n",
            "Epoch 182/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 5.2969 - mae: 1.6058 - mse: 5.2969 - val_loss: 7.8646 - val_mae: 2.1542 - val_mse: 7.8646\n",
            "Epoch 183/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 5.5493 - mae: 1.6391 - mse: 5.5493 - val_loss: 7.8040 - val_mae: 2.1749 - val_mse: 7.8040\n",
            "Epoch 184/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 5.2504 - mae: 1.5656 - mse: 5.2504 - val_loss: 8.0229 - val_mae: 2.0949 - val_mse: 8.0229\n",
            "Epoch 185/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 5.4505 - mae: 1.6447 - mse: 5.4505 - val_loss: 7.8773 - val_mae: 2.1755 - val_mse: 7.8773\n",
            "Epoch 186/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 5.1859 - mae: 1.5813 - mse: 5.1859 - val_loss: 8.0580 - val_mae: 2.1077 - val_mse: 8.0580\n",
            "Epoch 187/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 5.2785 - mae: 1.5953 - mse: 5.2785 - val_loss: 7.8772 - val_mae: 2.1732 - val_mse: 7.8772\n",
            "Epoch 188/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 5.2860 - mae: 1.6096 - mse: 5.2860 - val_loss: 7.7785 - val_mae: 2.0979 - val_mse: 7.7785\n",
            "Epoch 189/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 5.4957 - mae: 1.6284 - mse: 5.4957 - val_loss: 8.1853 - val_mae: 2.1070 - val_mse: 8.1853\n",
            "Epoch 190/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 5.3548 - mae: 1.6177 - mse: 5.3548 - val_loss: 7.9127 - val_mae: 2.0934 - val_mse: 7.9127\n",
            "Epoch 191/1000\n",
            "251/251 [==============================] - 0s 124us/sample - loss: 5.3880 - mae: 1.5949 - mse: 5.3880 - val_loss: 7.8723 - val_mae: 2.1326 - val_mse: 7.8723\n",
            "Epoch 192/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 5.3716 - mae: 1.5883 - mse: 5.3716 - val_loss: 7.9208 - val_mae: 2.1727 - val_mse: 7.9208\n",
            "Epoch 193/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 5.2449 - mae: 1.5679 - mse: 5.2449 - val_loss: 7.7764 - val_mae: 2.1556 - val_mse: 7.7764\n",
            "Epoch 194/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 5.3437 - mae: 1.6171 - mse: 5.3437 - val_loss: 8.0911 - val_mae: 2.2345 - val_mse: 8.0911\n",
            "Epoch 195/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 5.3003 - mae: 1.5751 - mse: 5.3003 - val_loss: 8.0656 - val_mae: 2.2447 - val_mse: 8.0656\n",
            "Epoch 196/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 5.3423 - mae: 1.5766 - mse: 5.3423 - val_loss: 8.0267 - val_mae: 2.1483 - val_mse: 8.0267\n",
            "Epoch 197/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 5.0201 - mae: 1.5932 - mse: 5.0201 - val_loss: 8.2402 - val_mae: 2.2303 - val_mse: 8.2402\n",
            "Epoch 198/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 5.2485 - mae: 1.5577 - mse: 5.2485 - val_loss: 7.8665 - val_mae: 2.1770 - val_mse: 7.8665\n",
            "Epoch 199/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 5.1758 - mae: 1.5777 - mse: 5.1758 - val_loss: 8.0630 - val_mae: 2.2268 - val_mse: 8.0630\n",
            "Epoch 200/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 5.4557 - mae: 1.5983 - mse: 5.4557 - val_loss: 7.9857 - val_mae: 2.1501 - val_mse: 7.9857\n",
            "Epoch 201/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 5.1726 - mae: 1.5910 - mse: 5.1726 - val_loss: 8.3388 - val_mae: 2.2392 - val_mse: 8.3388\n",
            "Epoch 202/1000\n",
            "251/251 [==============================] - 0s 166us/sample - loss: 5.2936 - mae: 1.5733 - mse: 5.2936 - val_loss: 7.8571 - val_mae: 2.1396 - val_mse: 7.8571\n",
            "Epoch 203/1000\n",
            "251/251 [==============================] - 0s 159us/sample - loss: 5.1903 - mae: 1.5912 - mse: 5.1903 - val_loss: 7.7382 - val_mae: 2.1291 - val_mse: 7.7382\n",
            "Epoch 204/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 5.1526 - mae: 1.5821 - mse: 5.1526 - val_loss: 7.8150 - val_mae: 2.1557 - val_mse: 7.8150\n",
            "Epoch 205/1000\n",
            "251/251 [==============================] - 0s 123us/sample - loss: 5.3662 - mae: 1.6141 - mse: 5.3662 - val_loss: 7.7405 - val_mae: 2.1296 - val_mse: 7.7405\n",
            "Epoch 206/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 5.1818 - mae: 1.5810 - mse: 5.1818 - val_loss: 8.0400 - val_mae: 2.0949 - val_mse: 8.0400\n",
            "Epoch 207/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 5.1977 - mae: 1.5996 - mse: 5.1977 - val_loss: 7.8318 - val_mae: 2.1131 - val_mse: 7.8318\n",
            "Epoch 208/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 5.1749 - mae: 1.5365 - mse: 5.1749 - val_loss: 7.6005 - val_mae: 2.0923 - val_mse: 7.6005\n",
            "Epoch 209/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 5.2130 - mae: 1.5730 - mse: 5.2130 - val_loss: 7.9875 - val_mae: 2.1593 - val_mse: 7.9875\n",
            "Epoch 210/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 5.1258 - mae: 1.5530 - mse: 5.1258 - val_loss: 8.2417 - val_mae: 2.1325 - val_mse: 8.2417\n",
            "Epoch 211/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 5.1742 - mae: 1.5875 - mse: 5.1742 - val_loss: 7.9445 - val_mae: 2.1577 - val_mse: 7.9445\n",
            "Epoch 212/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 5.0825 - mae: 1.5625 - mse: 5.0825 - val_loss: 7.7749 - val_mae: 2.1624 - val_mse: 7.7749\n",
            "Epoch 213/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 5.1649 - mae: 1.5870 - mse: 5.1649 - val_loss: 7.9037 - val_mae: 2.1475 - val_mse: 7.9037\n",
            "Epoch 214/1000\n",
            "251/251 [==============================] - 0s 151us/sample - loss: 5.0156 - mae: 1.5603 - mse: 5.0156 - val_loss: 8.3512 - val_mae: 2.2583 - val_mse: 8.3512\n",
            "Epoch 215/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 5.2910 - mae: 1.5709 - mse: 5.2910 - val_loss: 8.0962 - val_mae: 2.2191 - val_mse: 8.0962\n",
            "Epoch 216/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 5.1342 - mae: 1.5652 - mse: 5.1342 - val_loss: 7.9914 - val_mae: 2.1080 - val_mse: 7.9914\n",
            "Epoch 217/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 5.0442 - mae: 1.5685 - mse: 5.0442 - val_loss: 8.1968 - val_mae: 2.2110 - val_mse: 8.1968\n",
            "Epoch 218/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 5.0591 - mae: 1.5378 - mse: 5.0591 - val_loss: 7.8380 - val_mae: 2.0879 - val_mse: 7.8380\n",
            "Epoch 219/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 5.1701 - mae: 1.5652 - mse: 5.1701 - val_loss: 7.7752 - val_mae: 2.1408 - val_mse: 7.7752\n",
            "Epoch 220/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 5.2145 - mae: 1.5682 - mse: 5.2145 - val_loss: 7.8675 - val_mae: 2.1743 - val_mse: 7.8675\n",
            "Epoch 221/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 5.1367 - mae: 1.5734 - mse: 5.1367 - val_loss: 7.8921 - val_mae: 2.1469 - val_mse: 7.8921\n",
            "Epoch 222/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 5.0438 - mae: 1.5500 - mse: 5.0438 - val_loss: 7.9601 - val_mae: 2.1767 - val_mse: 7.9601\n",
            "Epoch 223/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 5.1007 - mae: 1.5468 - mse: 5.1007 - val_loss: 7.7999 - val_mae: 2.1472 - val_mse: 7.7999\n",
            "Epoch 224/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 5.0701 - mae: 1.5809 - mse: 5.0701 - val_loss: 8.2375 - val_mae: 2.1305 - val_mse: 8.2375\n",
            "Epoch 225/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 5.0489 - mae: 1.5633 - mse: 5.0489 - val_loss: 7.8331 - val_mae: 2.1673 - val_mse: 7.8331\n",
            "Epoch 226/1000\n",
            "251/251 [==============================] - 0s 176us/sample - loss: 5.0321 - mae: 1.5358 - mse: 5.0321 - val_loss: 7.8705 - val_mae: 2.1697 - val_mse: 7.8705\n",
            "Epoch 227/1000\n",
            "251/251 [==============================] - 0s 181us/sample - loss: 5.1014 - mae: 1.5751 - mse: 5.1014 - val_loss: 7.8199 - val_mae: 2.1795 - val_mse: 7.8199\n",
            "Epoch 228/1000\n",
            "251/251 [==============================] - 0s 156us/sample - loss: 5.0751 - mae: 1.5595 - mse: 5.0751 - val_loss: 8.0601 - val_mae: 2.1850 - val_mse: 8.0601\n",
            "Epoch 229/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 5.2468 - mae: 1.5645 - mse: 5.2468 - val_loss: 7.9555 - val_mae: 2.1252 - val_mse: 7.9555\n",
            "Epoch 230/1000\n",
            "251/251 [==============================] - 0s 179us/sample - loss: 5.0892 - mae: 1.5566 - mse: 5.0892 - val_loss: 8.0063 - val_mae: 2.0917 - val_mse: 8.0063\n",
            "Epoch 231/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 4.9507 - mae: 1.5529 - mse: 4.9507 - val_loss: 8.0349 - val_mae: 2.1685 - val_mse: 8.0349\n",
            "Epoch 232/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 5.0387 - mae: 1.5495 - mse: 5.0387 - val_loss: 7.8179 - val_mae: 2.1586 - val_mse: 7.8179\n",
            "Epoch 233/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 4.8748 - mae: 1.5166 - mse: 4.8748 - val_loss: 7.9383 - val_mae: 2.1854 - val_mse: 7.9383\n",
            "Epoch 234/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 5.0353 - mae: 1.5517 - mse: 5.0353 - val_loss: 8.2738 - val_mae: 2.2779 - val_mse: 8.2738\n",
            "Epoch 235/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 4.9176 - mae: 1.5069 - mse: 4.9176 - val_loss: 8.1331 - val_mae: 2.1524 - val_mse: 8.1331\n",
            "Epoch 236/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 4.9993 - mae: 1.5366 - mse: 4.9993 - val_loss: 7.8436 - val_mae: 2.1323 - val_mse: 7.8436\n",
            "Epoch 237/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.9869 - mae: 1.5383 - mse: 4.9869 - val_loss: 7.9949 - val_mae: 2.1025 - val_mse: 7.9949\n",
            "Epoch 238/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 4.9381 - mae: 1.5371 - mse: 4.9381 - val_loss: 8.2251 - val_mae: 2.1805 - val_mse: 8.2251\n",
            "Epoch 239/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 4.8994 - mae: 1.5385 - mse: 4.8994 - val_loss: 8.1906 - val_mae: 2.1139 - val_mse: 8.1906\n",
            "Epoch 240/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 5.0265 - mae: 1.5559 - mse: 5.0265 - val_loss: 8.2557 - val_mae: 2.2295 - val_mse: 8.2557\n",
            "Epoch 241/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 4.9045 - mae: 1.5239 - mse: 4.9045 - val_loss: 7.9787 - val_mae: 2.1884 - val_mse: 7.9787\n",
            "Epoch 242/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 4.8993 - mae: 1.5484 - mse: 4.8993 - val_loss: 8.1388 - val_mae: 2.1951 - val_mse: 8.1388\n",
            "Epoch 243/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 5.0204 - mae: 1.5378 - mse: 5.0204 - val_loss: 8.1352 - val_mae: 2.1369 - val_mse: 8.1352\n",
            "Epoch 244/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 4.9238 - mae: 1.5175 - mse: 4.9238 - val_loss: 7.8572 - val_mae: 2.1613 - val_mse: 7.8572\n",
            "Epoch 245/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 5.1003 - mae: 1.5365 - mse: 5.1003 - val_loss: 8.2887 - val_mae: 2.2286 - val_mse: 8.2887\n",
            "Epoch 246/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 4.7963 - mae: 1.5391 - mse: 4.7963 - val_loss: 8.1438 - val_mae: 2.2182 - val_mse: 8.1438\n",
            "Epoch 247/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 4.9660 - mae: 1.5259 - mse: 4.9660 - val_loss: 7.8925 - val_mae: 2.1646 - val_mse: 7.8925\n",
            "Epoch 248/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 4.9113 - mae: 1.5174 - mse: 4.9113 - val_loss: 8.0601 - val_mae: 2.1283 - val_mse: 8.0601\n",
            "Epoch 249/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 5.0134 - mae: 1.5563 - mse: 5.0134 - val_loss: 8.1696 - val_mae: 2.1125 - val_mse: 8.1696\n",
            "Epoch 250/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 5.1149 - mae: 1.5724 - mse: 5.1149 - val_loss: 7.7544 - val_mae: 2.1398 - val_mse: 7.7544\n",
            "Epoch 251/1000\n",
            "251/251 [==============================] - 0s 151us/sample - loss: 4.7933 - mae: 1.5239 - mse: 4.7933 - val_loss: 7.6455 - val_mae: 2.1128 - val_mse: 7.6455\n",
            "Epoch 252/1000\n",
            "251/251 [==============================] - 0s 163us/sample - loss: 4.9982 - mae: 1.5270 - mse: 4.9982 - val_loss: 8.1151 - val_mae: 2.1080 - val_mse: 8.1151\n",
            "Epoch 253/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.8861 - mae: 1.5067 - mse: 4.8861 - val_loss: 8.1523 - val_mae: 2.1486 - val_mse: 8.1523\n",
            "Epoch 254/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 4.8400 - mae: 1.5318 - mse: 4.8400 - val_loss: 8.0944 - val_mae: 2.1990 - val_mse: 8.0944\n",
            "Epoch 255/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 5.1201 - mae: 1.5586 - mse: 5.1201 - val_loss: 8.0068 - val_mae: 2.1073 - val_mse: 8.0068\n",
            "Epoch 256/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 4.7635 - mae: 1.5044 - mse: 4.7635 - val_loss: 7.9282 - val_mae: 2.1847 - val_mse: 7.9282\n",
            "Epoch 257/1000\n",
            "251/251 [==============================] - 0s 178us/sample - loss: 4.8771 - mae: 1.5280 - mse: 4.8771 - val_loss: 8.0488 - val_mae: 2.1875 - val_mse: 8.0488\n",
            "Epoch 258/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 4.5637 - mae: 1.4823 - mse: 4.5637 - val_loss: 8.1633 - val_mae: 2.1247 - val_mse: 8.1633\n",
            "Epoch 259/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 5.0416 - mae: 1.5492 - mse: 5.0416 - val_loss: 7.8326 - val_mae: 2.1168 - val_mse: 7.8326\n",
            "Epoch 260/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.7332 - mae: 1.5170 - mse: 4.7332 - val_loss: 7.8151 - val_mae: 2.1069 - val_mse: 7.8151\n",
            "Epoch 261/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 4.9493 - mae: 1.5324 - mse: 4.9493 - val_loss: 7.6905 - val_mae: 2.1403 - val_mse: 7.6905\n",
            "Epoch 262/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.8030 - mae: 1.5013 - mse: 4.8030 - val_loss: 8.1662 - val_mae: 2.2364 - val_mse: 8.1662\n",
            "Epoch 263/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 4.8502 - mae: 1.5174 - mse: 4.8502 - val_loss: 7.7228 - val_mae: 2.1156 - val_mse: 7.7228\n",
            "Epoch 264/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.8354 - mae: 1.5268 - mse: 4.8354 - val_loss: 8.0809 - val_mae: 2.2203 - val_mse: 8.0809\n",
            "Epoch 265/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 4.8361 - mae: 1.5092 - mse: 4.8361 - val_loss: 8.1023 - val_mae: 2.1459 - val_mse: 8.1023\n",
            "Epoch 266/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 4.8346 - mae: 1.5051 - mse: 4.8346 - val_loss: 7.9452 - val_mae: 2.1320 - val_mse: 7.9452\n",
            "Epoch 267/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 4.6721 - mae: 1.4931 - mse: 4.6721 - val_loss: 7.6914 - val_mae: 2.1219 - val_mse: 7.6914\n",
            "Epoch 268/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 4.7832 - mae: 1.4905 - mse: 4.7832 - val_loss: 8.0111 - val_mae: 2.1255 - val_mse: 8.0111\n",
            "Epoch 269/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.7508 - mae: 1.4961 - mse: 4.7508 - val_loss: 7.6942 - val_mae: 2.1006 - val_mse: 7.6942\n",
            "Epoch 270/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 4.6012 - mae: 1.4550 - mse: 4.6012 - val_loss: 7.9846 - val_mae: 2.1011 - val_mse: 7.9846\n",
            "Epoch 271/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 4.9288 - mae: 1.5159 - mse: 4.9288 - val_loss: 7.9309 - val_mae: 2.1035 - val_mse: 7.9309\n",
            "Epoch 272/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 4.8489 - mae: 1.5363 - mse: 4.8489 - val_loss: 8.1412 - val_mae: 2.2056 - val_mse: 8.1412\n",
            "Epoch 273/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 4.7452 - mae: 1.5192 - mse: 4.7452 - val_loss: 8.6682 - val_mae: 2.2777 - val_mse: 8.6682\n",
            "Epoch 274/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 4.8043 - mae: 1.4857 - mse: 4.8043 - val_loss: 8.2191 - val_mae: 2.1327 - val_mse: 8.2191\n",
            "Epoch 275/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 4.7965 - mae: 1.5278 - mse: 4.7965 - val_loss: 8.0558 - val_mae: 2.1667 - val_mse: 8.0558\n",
            "Epoch 276/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 4.6789 - mae: 1.5061 - mse: 4.6789 - val_loss: 7.7552 - val_mae: 2.1517 - val_mse: 7.7552\n",
            "Epoch 277/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 4.7113 - mae: 1.4783 - mse: 4.7113 - val_loss: 7.6681 - val_mae: 2.0866 - val_mse: 7.6681\n",
            "Epoch 278/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 4.8217 - mae: 1.5143 - mse: 4.8217 - val_loss: 8.0340 - val_mae: 2.1764 - val_mse: 8.0340\n",
            "Epoch 279/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.6951 - mae: 1.4865 - mse: 4.6951 - val_loss: 8.1355 - val_mae: 2.1556 - val_mse: 8.1355\n",
            "Epoch 280/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 4.7239 - mae: 1.4863 - mse: 4.7239 - val_loss: 7.7498 - val_mae: 2.1039 - val_mse: 7.7498\n",
            "Epoch 281/1000\n",
            "251/251 [==============================] - 0s 119us/sample - loss: 4.4676 - mae: 1.4499 - mse: 4.4676 - val_loss: 8.5603 - val_mae: 2.1501 - val_mse: 8.5603\n",
            "Epoch 282/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 4.6369 - mae: 1.4996 - mse: 4.6369 - val_loss: 7.8334 - val_mae: 2.1461 - val_mse: 7.8334\n",
            "Epoch 283/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 4.8662 - mae: 1.5106 - mse: 4.8662 - val_loss: 7.9874 - val_mae: 2.1721 - val_mse: 7.9874\n",
            "Epoch 284/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 4.6682 - mae: 1.4695 - mse: 4.6682 - val_loss: 7.9460 - val_mae: 2.1641 - val_mse: 7.9460\n",
            "Epoch 285/1000\n",
            "251/251 [==============================] - 0s 167us/sample - loss: 4.6448 - mae: 1.4935 - mse: 4.6448 - val_loss: 8.0793 - val_mae: 2.1941 - val_mse: 8.0793\n",
            "Epoch 286/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 4.6878 - mae: 1.4892 - mse: 4.6878 - val_loss: 8.2188 - val_mae: 2.1975 - val_mse: 8.2188\n",
            "Epoch 287/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 4.8077 - mae: 1.5152 - mse: 4.8077 - val_loss: 8.1328 - val_mae: 2.1950 - val_mse: 8.1328\n",
            "Epoch 288/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 4.4466 - mae: 1.4503 - mse: 4.4466 - val_loss: 8.0619 - val_mae: 2.1184 - val_mse: 8.0619\n",
            "Epoch 289/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.6392 - mae: 1.5087 - mse: 4.6392 - val_loss: 8.1302 - val_mae: 2.1823 - val_mse: 8.1302\n",
            "Epoch 290/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 4.6528 - mae: 1.4831 - mse: 4.6528 - val_loss: 8.0877 - val_mae: 2.1619 - val_mse: 8.0877\n",
            "Epoch 291/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 4.5053 - mae: 1.4384 - mse: 4.5053 - val_loss: 8.6561 - val_mae: 2.1799 - val_mse: 8.6561\n",
            "Epoch 292/1000\n",
            "251/251 [==============================] - 0s 124us/sample - loss: 4.7042 - mae: 1.4924 - mse: 4.7042 - val_loss: 8.0799 - val_mae: 2.1335 - val_mse: 8.0799\n",
            "Epoch 293/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 4.8804 - mae: 1.5261 - mse: 4.8804 - val_loss: 7.9580 - val_mae: 2.1702 - val_mse: 7.9580\n",
            "Epoch 294/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 4.4839 - mae: 1.4355 - mse: 4.4839 - val_loss: 7.9154 - val_mae: 2.1137 - val_mse: 7.9154\n",
            "Epoch 295/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 4.5096 - mae: 1.4517 - mse: 4.5096 - val_loss: 8.2122 - val_mae: 2.1416 - val_mse: 8.2122\n",
            "Epoch 296/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.7204 - mae: 1.5144 - mse: 4.7204 - val_loss: 7.8083 - val_mae: 2.1303 - val_mse: 7.8083\n",
            "Epoch 297/1000\n",
            "251/251 [==============================] - 0s 124us/sample - loss: 4.5552 - mae: 1.4547 - mse: 4.5552 - val_loss: 7.9308 - val_mae: 2.1062 - val_mse: 7.9308\n",
            "Epoch 298/1000\n",
            "251/251 [==============================] - 0s 120us/sample - loss: 4.7497 - mae: 1.5382 - mse: 4.7497 - val_loss: 8.0696 - val_mae: 2.1807 - val_mse: 8.0696\n",
            "Epoch 299/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 4.4449 - mae: 1.4433 - mse: 4.4449 - val_loss: 7.9338 - val_mae: 2.1759 - val_mse: 7.9338\n",
            "Epoch 300/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 4.6978 - mae: 1.4718 - mse: 4.6978 - val_loss: 7.8603 - val_mae: 2.1290 - val_mse: 7.8603\n",
            "Epoch 301/1000\n",
            "251/251 [==============================] - 0s 159us/sample - loss: 4.4779 - mae: 1.4351 - mse: 4.4779 - val_loss: 7.6639 - val_mae: 2.1325 - val_mse: 7.6639\n",
            "Epoch 302/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 4.4313 - mae: 1.4302 - mse: 4.4313 - val_loss: 8.1689 - val_mae: 2.1355 - val_mse: 8.1689\n",
            "Epoch 303/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 4.6835 - mae: 1.4812 - mse: 4.6835 - val_loss: 8.2509 - val_mae: 2.1396 - val_mse: 8.2509\n",
            "Epoch 304/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 4.5506 - mae: 1.5131 - mse: 4.5506 - val_loss: 8.1089 - val_mae: 2.1345 - val_mse: 8.1089\n",
            "Epoch 305/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.4959 - mae: 1.4638 - mse: 4.4959 - val_loss: 8.0306 - val_mae: 2.1605 - val_mse: 8.0306\n",
            "Epoch 306/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.6137 - mae: 1.4516 - mse: 4.6137 - val_loss: 7.8016 - val_mae: 2.0920 - val_mse: 7.8016\n",
            "Epoch 307/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.4397 - mae: 1.4524 - mse: 4.4397 - val_loss: 7.7657 - val_mae: 2.1644 - val_mse: 7.7657\n",
            "Epoch 308/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.6276 - mae: 1.4785 - mse: 4.6276 - val_loss: 7.7622 - val_mae: 2.1353 - val_mse: 7.7622\n",
            "Epoch 309/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 4.3577 - mae: 1.4197 - mse: 4.3577 - val_loss: 7.8686 - val_mae: 2.1350 - val_mse: 7.8686\n",
            "Epoch 310/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.8100 - mae: 1.4840 - mse: 4.8100 - val_loss: 7.9330 - val_mae: 2.1675 - val_mse: 7.9330\n",
            "Epoch 311/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 4.5478 - mae: 1.4332 - mse: 4.5478 - val_loss: 7.8331 - val_mae: 2.1004 - val_mse: 7.8331\n",
            "Epoch 312/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 4.3671 - mae: 1.4350 - mse: 4.3671 - val_loss: 8.0641 - val_mae: 2.1554 - val_mse: 8.0641\n",
            "Epoch 313/1000\n",
            "251/251 [==============================] - 0s 190us/sample - loss: 4.3718 - mae: 1.4165 - mse: 4.3718 - val_loss: 8.0729 - val_mae: 2.2039 - val_mse: 8.0729\n",
            "Epoch 314/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 4.4241 - mae: 1.4602 - mse: 4.4241 - val_loss: 8.2404 - val_mae: 2.1921 - val_mse: 8.2404\n",
            "Epoch 315/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 4.3922 - mae: 1.4253 - mse: 4.3922 - val_loss: 8.2564 - val_mae: 2.1468 - val_mse: 8.2564\n",
            "Epoch 316/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.4486 - mae: 1.4494 - mse: 4.4486 - val_loss: 8.0624 - val_mae: 2.1335 - val_mse: 8.0624\n",
            "Epoch 317/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 4.6543 - mae: 1.4660 - mse: 4.6543 - val_loss: 7.8541 - val_mae: 2.1127 - val_mse: 7.8541\n",
            "Epoch 318/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.3098 - mae: 1.4327 - mse: 4.3098 - val_loss: 8.2145 - val_mae: 2.2010 - val_mse: 8.2145\n",
            "Epoch 319/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 4.4440 - mae: 1.4345 - mse: 4.4440 - val_loss: 8.0151 - val_mae: 2.1362 - val_mse: 8.0151\n",
            "Epoch 320/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 4.5886 - mae: 1.4856 - mse: 4.5886 - val_loss: 7.8767 - val_mae: 2.1215 - val_mse: 7.8767\n",
            "Epoch 321/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 4.3731 - mae: 1.4305 - mse: 4.3731 - val_loss: 7.8366 - val_mae: 2.1317 - val_mse: 7.8366\n",
            "Epoch 322/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 4.5371 - mae: 1.4545 - mse: 4.5371 - val_loss: 7.9912 - val_mae: 2.1531 - val_mse: 7.9912\n",
            "Epoch 323/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.3325 - mae: 1.4347 - mse: 4.3325 - val_loss: 8.1656 - val_mae: 2.1421 - val_mse: 8.1656\n",
            "Epoch 324/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.2897 - mae: 1.4255 - mse: 4.2897 - val_loss: 8.0801 - val_mae: 2.1622 - val_mse: 8.0801\n",
            "Epoch 325/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 4.6272 - mae: 1.4732 - mse: 4.6272 - val_loss: 8.5362 - val_mae: 2.2308 - val_mse: 8.5362\n",
            "Epoch 326/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 4.3382 - mae: 1.4376 - mse: 4.3382 - val_loss: 7.8494 - val_mae: 2.1239 - val_mse: 7.8494\n",
            "Epoch 327/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 4.3651 - mae: 1.4453 - mse: 4.3651 - val_loss: 7.9104 - val_mae: 2.1140 - val_mse: 7.9104\n",
            "Epoch 328/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 4.4199 - mae: 1.4376 - mse: 4.4199 - val_loss: 8.3497 - val_mae: 2.2632 - val_mse: 8.3497\n",
            "Epoch 329/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 4.3631 - mae: 1.4062 - mse: 4.3631 - val_loss: 7.6930 - val_mae: 2.0998 - val_mse: 7.6930\n",
            "Epoch 330/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.4978 - mae: 1.4621 - mse: 4.4978 - val_loss: 7.9516 - val_mae: 2.1153 - val_mse: 7.9516\n",
            "Epoch 331/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.4349 - mae: 1.4459 - mse: 4.4349 - val_loss: 7.9985 - val_mae: 2.1630 - val_mse: 7.9985\n",
            "Epoch 332/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.4265 - mae: 1.4462 - mse: 4.4265 - val_loss: 8.1003 - val_mae: 2.1767 - val_mse: 8.1003\n",
            "Epoch 333/1000\n",
            "251/251 [==============================] - 0s 120us/sample - loss: 4.3975 - mae: 1.4076 - mse: 4.3975 - val_loss: 7.8830 - val_mae: 2.1170 - val_mse: 7.8830\n",
            "Epoch 334/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 4.4270 - mae: 1.4262 - mse: 4.4270 - val_loss: 8.2429 - val_mae: 2.2143 - val_mse: 8.2429\n",
            "Epoch 335/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 4.2553 - mae: 1.4217 - mse: 4.2553 - val_loss: 8.0572 - val_mae: 2.1347 - val_mse: 8.0572\n",
            "Epoch 336/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 4.2818 - mae: 1.4430 - mse: 4.2818 - val_loss: 7.8685 - val_mae: 2.1521 - val_mse: 7.8685\n",
            "Epoch 337/1000\n",
            "251/251 [==============================] - 0s 157us/sample - loss: 4.4929 - mae: 1.4105 - mse: 4.4929 - val_loss: 7.7510 - val_mae: 2.1031 - val_mse: 7.7510\n",
            "Epoch 338/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 4.5692 - mae: 1.4488 - mse: 4.5692 - val_loss: 7.9812 - val_mae: 2.1515 - val_mse: 7.9812\n",
            "Epoch 339/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 4.4067 - mae: 1.4130 - mse: 4.4067 - val_loss: 7.8350 - val_mae: 2.1365 - val_mse: 7.8350\n",
            "Epoch 340/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.2805 - mae: 1.4378 - mse: 4.2805 - val_loss: 7.8641 - val_mae: 2.1255 - val_mse: 7.8641\n",
            "Epoch 341/1000\n",
            "251/251 [==============================] - 0s 154us/sample - loss: 4.3475 - mae: 1.4232 - mse: 4.3475 - val_loss: 7.7256 - val_mae: 2.1077 - val_mse: 7.7256\n",
            "Epoch 342/1000\n",
            "251/251 [==============================] - 0s 165us/sample - loss: 4.4129 - mae: 1.4333 - mse: 4.4129 - val_loss: 8.2073 - val_mae: 2.1789 - val_mse: 8.2073\n",
            "Epoch 343/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 4.4495 - mae: 1.4242 - mse: 4.4495 - val_loss: 7.7504 - val_mae: 2.1031 - val_mse: 7.7504\n",
            "Epoch 344/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 4.2440 - mae: 1.3911 - mse: 4.2440 - val_loss: 7.9647 - val_mae: 2.1423 - val_mse: 7.9647\n",
            "Epoch 345/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 4.1921 - mae: 1.3821 - mse: 4.1921 - val_loss: 7.9374 - val_mae: 2.1175 - val_mse: 7.9374\n",
            "Epoch 346/1000\n",
            "251/251 [==============================] - 0s 157us/sample - loss: 4.4349 - mae: 1.4474 - mse: 4.4349 - val_loss: 8.0925 - val_mae: 2.1737 - val_mse: 8.0925\n",
            "Epoch 347/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 4.1755 - mae: 1.4191 - mse: 4.1755 - val_loss: 8.0742 - val_mae: 2.1652 - val_mse: 8.0742\n",
            "Epoch 348/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 4.4173 - mae: 1.4513 - mse: 4.4173 - val_loss: 7.8333 - val_mae: 2.1153 - val_mse: 7.8333\n",
            "Epoch 349/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 4.3156 - mae: 1.3850 - mse: 4.3156 - val_loss: 7.8388 - val_mae: 2.1111 - val_mse: 7.8388\n",
            "Epoch 350/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 4.3634 - mae: 1.4133 - mse: 4.3634 - val_loss: 8.1213 - val_mae: 2.1722 - val_mse: 8.1213\n",
            "Epoch 351/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 4.2135 - mae: 1.3906 - mse: 4.2135 - val_loss: 8.1715 - val_mae: 2.1791 - val_mse: 8.1715\n",
            "Epoch 352/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 4.1216 - mae: 1.3830 - mse: 4.1216 - val_loss: 7.8167 - val_mae: 2.1353 - val_mse: 7.8167\n",
            "Epoch 353/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.2131 - mae: 1.3989 - mse: 4.2131 - val_loss: 7.9341 - val_mae: 2.1341 - val_mse: 7.9341\n",
            "Epoch 354/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.4354 - mae: 1.4012 - mse: 4.4354 - val_loss: 7.8100 - val_mae: 2.1146 - val_mse: 7.8100\n",
            "Epoch 355/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.0902 - mae: 1.3744 - mse: 4.0902 - val_loss: 8.0846 - val_mae: 2.1781 - val_mse: 8.0846\n",
            "Epoch 356/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 4.2112 - mae: 1.3713 - mse: 4.2112 - val_loss: 7.7534 - val_mae: 2.1121 - val_mse: 7.7534\n",
            "Epoch 357/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.2035 - mae: 1.3936 - mse: 4.2035 - val_loss: 7.9194 - val_mae: 2.1235 - val_mse: 7.9194\n",
            "Epoch 358/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 4.1598 - mae: 1.3970 - mse: 4.1598 - val_loss: 8.0992 - val_mae: 2.1508 - val_mse: 8.0992\n",
            "Epoch 359/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 4.3564 - mae: 1.4145 - mse: 4.3564 - val_loss: 7.6917 - val_mae: 2.0971 - val_mse: 7.6917\n",
            "Epoch 360/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 4.1707 - mae: 1.3884 - mse: 4.1707 - val_loss: 8.0800 - val_mae: 2.1642 - val_mse: 8.0800\n",
            "Epoch 361/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.3885 - mae: 1.3837 - mse: 4.3885 - val_loss: 7.8038 - val_mae: 2.1162 - val_mse: 7.8038\n",
            "Epoch 362/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.1648 - mae: 1.3779 - mse: 4.1648 - val_loss: 7.7867 - val_mae: 2.1165 - val_mse: 7.7867\n",
            "Epoch 363/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 4.1939 - mae: 1.3895 - mse: 4.1939 - val_loss: 7.9601 - val_mae: 2.1236 - val_mse: 7.9601\n",
            "Epoch 364/1000\n",
            "251/251 [==============================] - 0s 157us/sample - loss: 4.2713 - mae: 1.4073 - mse: 4.2713 - val_loss: 7.7560 - val_mae: 2.1075 - val_mse: 7.7560\n",
            "Epoch 365/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 4.2458 - mae: 1.4065 - mse: 4.2458 - val_loss: 8.1766 - val_mae: 2.1735 - val_mse: 8.1766\n",
            "Epoch 366/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 4.0251 - mae: 1.3976 - mse: 4.0251 - val_loss: 8.2035 - val_mae: 2.1855 - val_mse: 8.2035\n",
            "Epoch 367/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 4.1033 - mae: 1.3684 - mse: 4.1033 - val_loss: 7.9819 - val_mae: 2.1568 - val_mse: 7.9819\n",
            "Epoch 368/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 4.1779 - mae: 1.3873 - mse: 4.1779 - val_loss: 7.8907 - val_mae: 2.1251 - val_mse: 7.8907\n",
            "Epoch 369/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 4.2171 - mae: 1.4052 - mse: 4.2171 - val_loss: 7.7976 - val_mae: 2.1203 - val_mse: 7.7976\n",
            "Epoch 370/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 4.1365 - mae: 1.3737 - mse: 4.1365 - val_loss: 7.9201 - val_mae: 2.1278 - val_mse: 7.9201\n",
            "Epoch 371/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 4.1796 - mae: 1.3847 - mse: 4.1796 - val_loss: 7.9089 - val_mae: 2.1341 - val_mse: 7.9089\n",
            "Epoch 372/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 4.2220 - mae: 1.4060 - mse: 4.2220 - val_loss: 8.3228 - val_mae: 2.2009 - val_mse: 8.3228\n",
            "Epoch 373/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.1290 - mae: 1.3926 - mse: 4.1290 - val_loss: 8.0183 - val_mae: 2.1407 - val_mse: 8.0183\n",
            "Epoch 374/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 4.0737 - mae: 1.3650 - mse: 4.0737 - val_loss: 8.0502 - val_mae: 2.1491 - val_mse: 8.0502\n",
            "Epoch 375/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 4.1389 - mae: 1.3956 - mse: 4.1389 - val_loss: 8.3645 - val_mae: 2.2185 - val_mse: 8.3645\n",
            "Epoch 376/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.0658 - mae: 1.3662 - mse: 4.0658 - val_loss: 8.1173 - val_mae: 2.1536 - val_mse: 8.1173\n",
            "Epoch 377/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 4.1685 - mae: 1.3996 - mse: 4.1685 - val_loss: 8.1481 - val_mae: 2.1758 - val_mse: 8.1481\n",
            "Epoch 378/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.1919 - mae: 1.3706 - mse: 4.1919 - val_loss: 8.0030 - val_mae: 2.1414 - val_mse: 8.0030\n",
            "Epoch 379/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 4.2489 - mae: 1.3668 - mse: 4.2489 - val_loss: 7.9331 - val_mae: 2.1401 - val_mse: 7.9331\n",
            "Epoch 380/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.9677 - mae: 1.3590 - mse: 3.9677 - val_loss: 7.8160 - val_mae: 2.1472 - val_mse: 7.8160\n",
            "Epoch 381/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 4.1430 - mae: 1.3653 - mse: 4.1430 - val_loss: 7.9622 - val_mae: 2.1647 - val_mse: 7.9622\n",
            "Epoch 382/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 4.0562 - mae: 1.3671 - mse: 4.0562 - val_loss: 7.9344 - val_mae: 2.1467 - val_mse: 7.9344\n",
            "Epoch 383/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 4.2242 - mae: 1.3374 - mse: 4.2242 - val_loss: 7.8017 - val_mae: 2.1105 - val_mse: 7.8017\n",
            "Epoch 384/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 3.9846 - mae: 1.3459 - mse: 3.9846 - val_loss: 7.9886 - val_mae: 2.1376 - val_mse: 7.9886\n",
            "Epoch 385/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 4.1373 - mae: 1.3972 - mse: 4.1373 - val_loss: 7.7460 - val_mae: 2.1192 - val_mse: 7.7460\n",
            "Epoch 386/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 4.2078 - mae: 1.3802 - mse: 4.2078 - val_loss: 7.8691 - val_mae: 2.1284 - val_mse: 7.8691\n",
            "Epoch 387/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 4.0112 - mae: 1.3635 - mse: 4.0112 - val_loss: 8.1681 - val_mae: 2.1576 - val_mse: 8.1681\n",
            "Epoch 388/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 4.1238 - mae: 1.3733 - mse: 4.1238 - val_loss: 7.8770 - val_mae: 2.1499 - val_mse: 7.8770\n",
            "Epoch 389/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 4.0957 - mae: 1.3668 - mse: 4.0957 - val_loss: 7.9125 - val_mae: 2.1532 - val_mse: 7.9125\n",
            "Epoch 390/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.0200 - mae: 1.3517 - mse: 4.0200 - val_loss: 7.8076 - val_mae: 2.1149 - val_mse: 7.8076\n",
            "Epoch 391/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.9703 - mae: 1.3742 - mse: 3.9703 - val_loss: 8.1475 - val_mae: 2.1674 - val_mse: 8.1475\n",
            "Epoch 392/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.0237 - mae: 1.3690 - mse: 4.0237 - val_loss: 7.7625 - val_mae: 2.1099 - val_mse: 7.7625\n",
            "Epoch 393/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 3.8590 - mae: 1.3209 - mse: 3.8590 - val_loss: 8.1880 - val_mae: 2.2160 - val_mse: 8.1880\n",
            "Epoch 394/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 3.9948 - mae: 1.3516 - mse: 3.9948 - val_loss: 7.9958 - val_mae: 2.1402 - val_mse: 7.9958\n",
            "Epoch 395/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 4.0827 - mae: 1.3248 - mse: 4.0827 - val_loss: 8.1143 - val_mae: 2.1615 - val_mse: 8.1143\n",
            "Epoch 396/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 4.1973 - mae: 1.3948 - mse: 4.1973 - val_loss: 7.8061 - val_mae: 2.1198 - val_mse: 7.8061\n",
            "Epoch 397/1000\n",
            "251/251 [==============================] - 0s 176us/sample - loss: 4.1574 - mae: 1.3473 - mse: 4.1574 - val_loss: 7.9570 - val_mae: 2.1403 - val_mse: 7.9570\n",
            "Epoch 398/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.9369 - mae: 1.3538 - mse: 3.9369 - val_loss: 7.9089 - val_mae: 2.1374 - val_mse: 7.9089\n",
            "Epoch 399/1000\n",
            "251/251 [==============================] - 0s 156us/sample - loss: 3.9295 - mae: 1.3288 - mse: 3.9295 - val_loss: 7.7864 - val_mae: 2.1248 - val_mse: 7.7864\n",
            "Epoch 400/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 4.0256 - mae: 1.3264 - mse: 4.0256 - val_loss: 7.7917 - val_mae: 2.1195 - val_mse: 7.7917\n",
            "Epoch 401/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 3.9940 - mae: 1.3393 - mse: 3.9940 - val_loss: 7.9271 - val_mae: 2.1434 - val_mse: 7.9271\n",
            "Epoch 402/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.1662 - mae: 1.3683 - mse: 4.1662 - val_loss: 8.0369 - val_mae: 2.1471 - val_mse: 8.0369\n",
            "Epoch 403/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.9321 - mae: 1.3367 - mse: 3.9321 - val_loss: 7.9526 - val_mae: 2.1410 - val_mse: 7.9526\n",
            "Epoch 404/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 4.0217 - mae: 1.3737 - mse: 4.0217 - val_loss: 8.4767 - val_mae: 2.2265 - val_mse: 8.4767\n",
            "Epoch 405/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 4.0497 - mae: 1.3601 - mse: 4.0497 - val_loss: 7.9585 - val_mae: 2.1474 - val_mse: 7.9585\n",
            "Epoch 406/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.9586 - mae: 1.3236 - mse: 3.9586 - val_loss: 8.2802 - val_mae: 2.1926 - val_mse: 8.2802\n",
            "Epoch 407/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 4.0067 - mae: 1.3561 - mse: 4.0067 - val_loss: 7.9553 - val_mae: 2.1425 - val_mse: 7.9553\n",
            "Epoch 408/1000\n",
            "251/251 [==============================] - 0s 124us/sample - loss: 4.0719 - mae: 1.3867 - mse: 4.0719 - val_loss: 8.4194 - val_mae: 2.2120 - val_mse: 8.4194\n",
            "Epoch 409/1000\n",
            "251/251 [==============================] - 0s 124us/sample - loss: 4.1022 - mae: 1.3502 - mse: 4.1022 - val_loss: 8.0144 - val_mae: 2.1585 - val_mse: 8.0144\n",
            "Epoch 410/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 3.8888 - mae: 1.3303 - mse: 3.8888 - val_loss: 8.2189 - val_mae: 2.2061 - val_mse: 8.2189\n",
            "Epoch 411/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.9003 - mae: 1.3215 - mse: 3.9003 - val_loss: 8.3157 - val_mae: 2.2110 - val_mse: 8.3157\n",
            "Epoch 412/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 4.0994 - mae: 1.3724 - mse: 4.0994 - val_loss: 7.8175 - val_mae: 2.1329 - val_mse: 7.8175\n",
            "Epoch 413/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 4.0631 - mae: 1.3542 - mse: 4.0631 - val_loss: 7.8000 - val_mae: 2.1284 - val_mse: 7.8000\n",
            "Epoch 414/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.9075 - mae: 1.3312 - mse: 3.9075 - val_loss: 7.9393 - val_mae: 2.1421 - val_mse: 7.9393\n",
            "Epoch 415/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 4.0608 - mae: 1.3693 - mse: 4.0608 - val_loss: 7.8566 - val_mae: 2.1260 - val_mse: 7.8566\n",
            "Epoch 416/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 3.9850 - mae: 1.3562 - mse: 3.9850 - val_loss: 7.9804 - val_mae: 2.1366 - val_mse: 7.9804\n",
            "Epoch 417/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.7680 - mae: 1.2978 - mse: 3.7680 - val_loss: 7.5938 - val_mae: 2.1075 - val_mse: 7.5938\n",
            "Epoch 418/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.0229 - mae: 1.3645 - mse: 4.0229 - val_loss: 8.2083 - val_mae: 2.1958 - val_mse: 8.2083\n",
            "Epoch 419/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 4.0044 - mae: 1.3367 - mse: 4.0044 - val_loss: 7.9057 - val_mae: 2.1385 - val_mse: 7.9057\n",
            "Epoch 420/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.9210 - mae: 1.3586 - mse: 3.9210 - val_loss: 7.9427 - val_mae: 2.1399 - val_mse: 7.9427\n",
            "Epoch 421/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.8219 - mae: 1.3222 - mse: 3.8219 - val_loss: 7.7965 - val_mae: 2.1181 - val_mse: 7.7965\n",
            "Epoch 422/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.9295 - mae: 1.3439 - mse: 3.9295 - val_loss: 7.9357 - val_mae: 2.1433 - val_mse: 7.9357\n",
            "Epoch 423/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.7649 - mae: 1.3109 - mse: 3.7649 - val_loss: 8.1244 - val_mae: 2.1711 - val_mse: 8.1244\n",
            "Epoch 424/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.9551 - mae: 1.3298 - mse: 3.9551 - val_loss: 7.8296 - val_mae: 2.1407 - val_mse: 7.8296\n",
            "Epoch 425/1000\n",
            "251/251 [==============================] - 0s 196us/sample - loss: 3.8056 - mae: 1.3256 - mse: 3.8056 - val_loss: 7.6238 - val_mae: 2.1044 - val_mse: 7.6238\n",
            "Epoch 426/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 4.0810 - mae: 1.3250 - mse: 4.0810 - val_loss: 7.6466 - val_mae: 2.1053 - val_mse: 7.6466\n",
            "Epoch 427/1000\n",
            "251/251 [==============================] - 0s 166us/sample - loss: 3.7320 - mae: 1.2810 - mse: 3.7320 - val_loss: 8.0490 - val_mae: 2.1579 - val_mse: 8.0490\n",
            "Epoch 428/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 3.8614 - mae: 1.3350 - mse: 3.8614 - val_loss: 7.9869 - val_mae: 2.1911 - val_mse: 7.9869\n",
            "Epoch 429/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 4.0341 - mae: 1.3265 - mse: 4.0341 - val_loss: 8.0486 - val_mae: 2.1670 - val_mse: 8.0486\n",
            "Epoch 430/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 4.0998 - mae: 1.3682 - mse: 4.0998 - val_loss: 7.9482 - val_mae: 2.1354 - val_mse: 7.9482\n",
            "Epoch 431/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 3.9402 - mae: 1.3460 - mse: 3.9402 - val_loss: 7.8487 - val_mae: 2.1375 - val_mse: 7.8487\n",
            "Epoch 432/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.9940 - mae: 1.3518 - mse: 3.9940 - val_loss: 8.0156 - val_mae: 2.1556 - val_mse: 8.0156\n",
            "Epoch 433/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.8197 - mae: 1.3169 - mse: 3.8197 - val_loss: 7.6051 - val_mae: 2.1133 - val_mse: 7.6051\n",
            "Epoch 434/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.7552 - mae: 1.3047 - mse: 3.7552 - val_loss: 8.1653 - val_mae: 2.1727 - val_mse: 8.1653\n",
            "Epoch 435/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 4.0353 - mae: 1.3652 - mse: 4.0353 - val_loss: 7.8400 - val_mae: 2.1466 - val_mse: 7.8400\n",
            "Epoch 436/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.7978 - mae: 1.3220 - mse: 3.7979 - val_loss: 8.0074 - val_mae: 2.1481 - val_mse: 8.0074\n",
            "Epoch 437/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.8863 - mae: 1.3258 - mse: 3.8863 - val_loss: 8.0727 - val_mae: 2.1544 - val_mse: 8.0727\n",
            "Epoch 438/1000\n",
            "251/251 [==============================] - 0s 154us/sample - loss: 3.7139 - mae: 1.2800 - mse: 3.7139 - val_loss: 7.9333 - val_mae: 2.1524 - val_mse: 7.9333\n",
            "Epoch 439/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 3.6804 - mae: 1.2911 - mse: 3.6804 - val_loss: 8.8848 - val_mae: 2.2595 - val_mse: 8.8848\n",
            "Epoch 440/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.8808 - mae: 1.3296 - mse: 3.8808 - val_loss: 7.7954 - val_mae: 2.1247 - val_mse: 7.7954\n",
            "Epoch 441/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 4.0142 - mae: 1.3339 - mse: 4.0142 - val_loss: 7.7672 - val_mae: 2.1327 - val_mse: 7.7672\n",
            "Epoch 442/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.7379 - mae: 1.3082 - mse: 3.7379 - val_loss: 7.8518 - val_mae: 2.1396 - val_mse: 7.8518\n",
            "Epoch 443/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.7710 - mae: 1.2797 - mse: 3.7710 - val_loss: 7.9070 - val_mae: 2.1693 - val_mse: 7.9070\n",
            "Epoch 444/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.9260 - mae: 1.3215 - mse: 3.9260 - val_loss: 8.1904 - val_mae: 2.2254 - val_mse: 8.1904\n",
            "Epoch 445/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.8185 - mae: 1.3136 - mse: 3.8185 - val_loss: 7.7551 - val_mae: 2.1781 - val_mse: 7.7551\n",
            "Epoch 446/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.8094 - mae: 1.3063 - mse: 3.8094 - val_loss: 8.0817 - val_mae: 2.1838 - val_mse: 8.0817\n",
            "Epoch 447/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.7884 - mae: 1.2662 - mse: 3.7884 - val_loss: 7.8590 - val_mae: 2.1316 - val_mse: 7.8590\n",
            "Epoch 448/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 3.8493 - mae: 1.2726 - mse: 3.8493 - val_loss: 8.4629 - val_mae: 2.2186 - val_mse: 8.4629\n",
            "Epoch 449/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 3.9351 - mae: 1.3336 - mse: 3.9351 - val_loss: 7.7706 - val_mae: 2.1333 - val_mse: 7.7705\n",
            "Epoch 450/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.7016 - mae: 1.2833 - mse: 3.7016 - val_loss: 7.9928 - val_mae: 2.1589 - val_mse: 7.9928\n",
            "Epoch 451/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.9215 - mae: 1.3303 - mse: 3.9215 - val_loss: 7.9068 - val_mae: 2.1303 - val_mse: 7.9068\n",
            "Epoch 452/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.7624 - mae: 1.3246 - mse: 3.7624 - val_loss: 7.8416 - val_mae: 2.1386 - val_mse: 7.8416\n",
            "Epoch 453/1000\n",
            "251/251 [==============================] - 0s 156us/sample - loss: 3.7462 - mae: 1.3288 - mse: 3.7462 - val_loss: 7.9147 - val_mae: 2.1673 - val_mse: 7.9147\n",
            "Epoch 454/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 3.7987 - mae: 1.2803 - mse: 3.7987 - val_loss: 7.9297 - val_mae: 2.1641 - val_mse: 7.9297\n",
            "Epoch 455/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 3.8971 - mae: 1.3354 - mse: 3.8971 - val_loss: 7.6377 - val_mae: 2.1265 - val_mse: 7.6377\n",
            "Epoch 456/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.6405 - mae: 1.2840 - mse: 3.6405 - val_loss: 7.8828 - val_mae: 2.1369 - val_mse: 7.8828\n",
            "Epoch 457/1000\n",
            "251/251 [==============================] - 0s 159us/sample - loss: 3.7885 - mae: 1.3246 - mse: 3.7885 - val_loss: 8.1956 - val_mae: 2.1670 - val_mse: 8.1956\n",
            "Epoch 458/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 3.7482 - mae: 1.2867 - mse: 3.7482 - val_loss: 7.8206 - val_mae: 2.1553 - val_mse: 7.8206\n",
            "Epoch 459/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.7697 - mae: 1.3248 - mse: 3.7697 - val_loss: 7.7863 - val_mae: 2.1235 - val_mse: 7.7863\n",
            "Epoch 460/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.8639 - mae: 1.2973 - mse: 3.8639 - val_loss: 8.1112 - val_mae: 2.1918 - val_mse: 8.1112\n",
            "Epoch 461/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.8218 - mae: 1.3151 - mse: 3.8218 - val_loss: 7.9398 - val_mae: 2.1315 - val_mse: 7.9398\n",
            "Epoch 462/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.7443 - mae: 1.3076 - mse: 3.7443 - val_loss: 7.9017 - val_mae: 2.1583 - val_mse: 7.9017\n",
            "Epoch 463/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 3.9965 - mae: 1.3529 - mse: 3.9965 - val_loss: 7.6978 - val_mae: 2.1121 - val_mse: 7.6978\n",
            "Epoch 464/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.6919 - mae: 1.2630 - mse: 3.6919 - val_loss: 7.7620 - val_mae: 2.1309 - val_mse: 7.7620\n",
            "Epoch 465/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.7196 - mae: 1.3098 - mse: 3.7196 - val_loss: 7.9376 - val_mae: 2.1555 - val_mse: 7.9376\n",
            "Epoch 466/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 3.5400 - mae: 1.2458 - mse: 3.5400 - val_loss: 7.7931 - val_mae: 2.1328 - val_mse: 7.7931\n",
            "Epoch 467/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.6525 - mae: 1.2757 - mse: 3.6525 - val_loss: 8.2616 - val_mae: 2.1910 - val_mse: 8.2616\n",
            "Epoch 468/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.8414 - mae: 1.2742 - mse: 3.8414 - val_loss: 7.9576 - val_mae: 2.1607 - val_mse: 7.9576\n",
            "Epoch 469/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.6550 - mae: 1.2790 - mse: 3.6550 - val_loss: 8.3650 - val_mae: 2.2134 - val_mse: 8.3650\n",
            "Epoch 470/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.7430 - mae: 1.2525 - mse: 3.7430 - val_loss: 7.7236 - val_mae: 2.1382 - val_mse: 7.7236\n",
            "Epoch 471/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.9192 - mae: 1.3193 - mse: 3.9192 - val_loss: 7.7901 - val_mae: 2.1346 - val_mse: 7.7901\n",
            "Epoch 472/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.6889 - mae: 1.2702 - mse: 3.6889 - val_loss: 8.4612 - val_mae: 2.2706 - val_mse: 8.4612\n",
            "Epoch 473/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.6428 - mae: 1.2926 - mse: 3.6428 - val_loss: 8.2246 - val_mae: 2.1716 - val_mse: 8.2246\n",
            "Epoch 474/1000\n",
            "251/251 [==============================] - 0s 151us/sample - loss: 3.6936 - mae: 1.2956 - mse: 3.6936 - val_loss: 8.1296 - val_mae: 2.2177 - val_mse: 8.1296\n",
            "Epoch 475/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.9873 - mae: 1.3410 - mse: 3.9873 - val_loss: 7.8888 - val_mae: 2.1332 - val_mse: 7.8888\n",
            "Epoch 476/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.5615 - mae: 1.2597 - mse: 3.5615 - val_loss: 7.8832 - val_mae: 2.1604 - val_mse: 7.8832\n",
            "Epoch 477/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.8432 - mae: 1.3269 - mse: 3.8432 - val_loss: 7.9778 - val_mae: 2.1824 - val_mse: 7.9778\n",
            "Epoch 478/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 3.6782 - mae: 1.2623 - mse: 3.6782 - val_loss: 7.7319 - val_mae: 2.1674 - val_mse: 7.7319\n",
            "Epoch 479/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.6331 - mae: 1.2829 - mse: 3.6331 - val_loss: 7.9789 - val_mae: 2.1500 - val_mse: 7.9789\n",
            "Epoch 480/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 3.6792 - mae: 1.2455 - mse: 3.6792 - val_loss: 8.5579 - val_mae: 2.2954 - val_mse: 8.5579\n",
            "Epoch 481/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.6054 - mae: 1.2897 - mse: 3.6054 - val_loss: 8.0813 - val_mae: 2.1536 - val_mse: 8.0813\n",
            "Epoch 482/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 3.6898 - mae: 1.2983 - mse: 3.6898 - val_loss: 7.7549 - val_mae: 2.1414 - val_mse: 7.7549\n",
            "Epoch 483/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.7098 - mae: 1.2621 - mse: 3.7098 - val_loss: 7.7953 - val_mae: 2.1403 - val_mse: 7.7953\n",
            "Epoch 484/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 3.7373 - mae: 1.2673 - mse: 3.7373 - val_loss: 7.6250 - val_mae: 2.1137 - val_mse: 7.6250\n",
            "Epoch 485/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.5964 - mae: 1.2823 - mse: 3.5964 - val_loss: 7.5959 - val_mae: 2.1127 - val_mse: 7.5959\n",
            "Epoch 486/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.6260 - mae: 1.2499 - mse: 3.6260 - val_loss: 7.8323 - val_mae: 2.1543 - val_mse: 7.8323\n",
            "Epoch 487/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.5805 - mae: 1.2800 - mse: 3.5805 - val_loss: 7.6358 - val_mae: 2.1035 - val_mse: 7.6358\n",
            "Epoch 488/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.8458 - mae: 1.3212 - mse: 3.8458 - val_loss: 7.6833 - val_mae: 2.1306 - val_mse: 7.6833\n",
            "Epoch 489/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.5490 - mae: 1.2663 - mse: 3.5490 - val_loss: 7.8580 - val_mae: 2.1260 - val_mse: 7.8580\n",
            "Epoch 490/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.6907 - mae: 1.2895 - mse: 3.6907 - val_loss: 7.7923 - val_mae: 2.1216 - val_mse: 7.7923\n",
            "Epoch 491/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.6679 - mae: 1.2699 - mse: 3.6679 - val_loss: 8.0816 - val_mae: 2.1618 - val_mse: 8.0816\n",
            "Epoch 492/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.6485 - mae: 1.2920 - mse: 3.6485 - val_loss: 7.5748 - val_mae: 2.1070 - val_mse: 7.5748\n",
            "Epoch 493/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.7103 - mae: 1.3011 - mse: 3.7103 - val_loss: 7.5746 - val_mae: 2.1015 - val_mse: 7.5746\n",
            "Epoch 494/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 3.6100 - mae: 1.2455 - mse: 3.6100 - val_loss: 7.6694 - val_mae: 2.1297 - val_mse: 7.6694\n",
            "Epoch 495/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.6030 - mae: 1.2491 - mse: 3.6030 - val_loss: 7.6454 - val_mae: 2.1636 - val_mse: 7.6454\n",
            "Epoch 496/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.5233 - mae: 1.2394 - mse: 3.5233 - val_loss: 7.6568 - val_mae: 2.1399 - val_mse: 7.6568\n",
            "Epoch 497/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.7412 - mae: 1.2677 - mse: 3.7412 - val_loss: 8.0001 - val_mae: 2.1488 - val_mse: 8.0001\n",
            "Epoch 498/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.8006 - mae: 1.2841 - mse: 3.8006 - val_loss: 7.5210 - val_mae: 2.1238 - val_mse: 7.5210\n",
            "Epoch 499/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.5249 - mae: 1.2464 - mse: 3.5249 - val_loss: 7.5600 - val_mae: 2.1125 - val_mse: 7.5600\n",
            "Epoch 500/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.4346 - mae: 1.2115 - mse: 3.4346 - val_loss: 7.9755 - val_mae: 2.1740 - val_mse: 7.9755\n",
            "Epoch 501/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.5174 - mae: 1.2842 - mse: 3.5174 - val_loss: 7.3858 - val_mae: 2.1198 - val_mse: 7.3858\n",
            "Epoch 502/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 3.6105 - mae: 1.2617 - mse: 3.6105 - val_loss: 8.5310 - val_mae: 2.2569 - val_mse: 8.5310\n",
            "Epoch 503/1000\n",
            "251/251 [==============================] - 0s 154us/sample - loss: 3.8388 - mae: 1.3244 - mse: 3.8388 - val_loss: 7.7499 - val_mae: 2.1227 - val_mse: 7.7499\n",
            "Epoch 504/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.6278 - mae: 1.2808 - mse: 3.6278 - val_loss: 7.6681 - val_mae: 2.1268 - val_mse: 7.6681\n",
            "Epoch 505/1000\n",
            "251/251 [==============================] - 0s 156us/sample - loss: 3.5674 - mae: 1.2439 - mse: 3.5674 - val_loss: 7.6738 - val_mae: 2.1110 - val_mse: 7.6738\n",
            "Epoch 506/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.5129 - mae: 1.2303 - mse: 3.5129 - val_loss: 7.5931 - val_mae: 2.1098 - val_mse: 7.5931\n",
            "Epoch 507/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.5342 - mae: 1.2531 - mse: 3.5342 - val_loss: 8.0461 - val_mae: 2.1855 - val_mse: 8.0461\n",
            "Epoch 508/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.8474 - mae: 1.3135 - mse: 3.8474 - val_loss: 7.9275 - val_mae: 2.1632 - val_mse: 7.9275\n",
            "Epoch 509/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 3.8363 - mae: 1.2963 - mse: 3.8363 - val_loss: 7.7254 - val_mae: 2.1458 - val_mse: 7.7254\n",
            "Epoch 510/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 3.3462 - mae: 1.2357 - mse: 3.3462 - val_loss: 7.6789 - val_mae: 2.1442 - val_mse: 7.6789\n",
            "Epoch 511/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 3.4555 - mae: 1.2532 - mse: 3.4555 - val_loss: 7.5762 - val_mae: 2.1100 - val_mse: 7.5762\n",
            "Epoch 512/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.5717 - mae: 1.2574 - mse: 3.5717 - val_loss: 7.6721 - val_mae: 2.1101 - val_mse: 7.6721\n",
            "Epoch 513/1000\n",
            "251/251 [==============================] - 0s 171us/sample - loss: 3.4515 - mae: 1.2316 - mse: 3.4515 - val_loss: 8.0821 - val_mae: 2.1836 - val_mse: 8.0821\n",
            "Epoch 514/1000\n",
            "251/251 [==============================] - 0s 172us/sample - loss: 3.6529 - mae: 1.2849 - mse: 3.6529 - val_loss: 8.6131 - val_mae: 2.2396 - val_mse: 8.6130\n",
            "Epoch 515/1000\n",
            "251/251 [==============================] - 0s 163us/sample - loss: 3.6628 - mae: 1.2990 - mse: 3.6628 - val_loss: 7.7580 - val_mae: 2.1289 - val_mse: 7.7580\n",
            "Epoch 516/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.5720 - mae: 1.2483 - mse: 3.5720 - val_loss: 8.0973 - val_mae: 2.1915 - val_mse: 8.0973\n",
            "Epoch 517/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 3.6023 - mae: 1.2573 - mse: 3.6023 - val_loss: 7.6080 - val_mae: 2.1306 - val_mse: 7.6080\n",
            "Epoch 518/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.3916 - mae: 1.2454 - mse: 3.3916 - val_loss: 7.5559 - val_mae: 2.1258 - val_mse: 7.5559\n",
            "Epoch 519/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 3.7135 - mae: 1.2971 - mse: 3.7135 - val_loss: 7.4218 - val_mae: 2.0966 - val_mse: 7.4218\n",
            "Epoch 520/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.5299 - mae: 1.2240 - mse: 3.5299 - val_loss: 7.5630 - val_mae: 2.1155 - val_mse: 7.5630\n",
            "Epoch 521/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.3682 - mae: 1.2360 - mse: 3.3682 - val_loss: 8.2538 - val_mae: 2.1868 - val_mse: 8.2538\n",
            "Epoch 522/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.6226 - mae: 1.2516 - mse: 3.6226 - val_loss: 7.4678 - val_mae: 2.1649 - val_mse: 7.4678\n",
            "Epoch 523/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.6229 - mae: 1.2666 - mse: 3.6229 - val_loss: 7.2951 - val_mae: 2.0966 - val_mse: 7.2951\n",
            "Epoch 524/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 3.6506 - mae: 1.2516 - mse: 3.6506 - val_loss: 7.8966 - val_mae: 2.1663 - val_mse: 7.8966\n",
            "Epoch 525/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.7120 - mae: 1.2925 - mse: 3.7120 - val_loss: 7.6826 - val_mae: 2.1330 - val_mse: 7.6826\n",
            "Epoch 526/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.4371 - mae: 1.2416 - mse: 3.4371 - val_loss: 7.6815 - val_mae: 2.1196 - val_mse: 7.6815\n",
            "Epoch 527/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.4844 - mae: 1.2245 - mse: 3.4844 - val_loss: 7.4424 - val_mae: 2.1169 - val_mse: 7.4424\n",
            "Epoch 528/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 3.4471 - mae: 1.2356 - mse: 3.4471 - val_loss: 7.6924 - val_mae: 2.1479 - val_mse: 7.6924\n",
            "Epoch 529/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 3.4881 - mae: 1.2309 - mse: 3.4881 - val_loss: 7.6500 - val_mae: 2.1381 - val_mse: 7.6500\n",
            "Epoch 530/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 3.8175 - mae: 1.2748 - mse: 3.8175 - val_loss: 7.6566 - val_mae: 2.1209 - val_mse: 7.6566\n",
            "Epoch 531/1000\n",
            "251/251 [==============================] - 0s 171us/sample - loss: 3.5520 - mae: 1.2478 - mse: 3.5520 - val_loss: 7.6048 - val_mae: 2.1231 - val_mse: 7.6048\n",
            "Epoch 532/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.4839 - mae: 1.2243 - mse: 3.4839 - val_loss: 7.6803 - val_mae: 2.1183 - val_mse: 7.6803\n",
            "Epoch 533/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.3486 - mae: 1.2151 - mse: 3.3486 - val_loss: 7.4509 - val_mae: 2.1225 - val_mse: 7.4509\n",
            "Epoch 534/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.3427 - mae: 1.2055 - mse: 3.3427 - val_loss: 8.0534 - val_mae: 2.1828 - val_mse: 8.0534\n",
            "Epoch 535/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.5336 - mae: 1.2442 - mse: 3.5336 - val_loss: 7.5510 - val_mae: 2.1287 - val_mse: 7.5510\n",
            "Epoch 536/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.3952 - mae: 1.2345 - mse: 3.3952 - val_loss: 7.5068 - val_mae: 2.1350 - val_mse: 7.5068\n",
            "Epoch 537/1000\n",
            "251/251 [==============================] - 0s 164us/sample - loss: 3.4021 - mae: 1.2243 - mse: 3.4021 - val_loss: 7.5222 - val_mae: 2.1092 - val_mse: 7.5222\n",
            "Epoch 538/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.5235 - mae: 1.2480 - mse: 3.5235 - val_loss: 7.8644 - val_mae: 2.1847 - val_mse: 7.8644\n",
            "Epoch 539/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.5386 - mae: 1.2680 - mse: 3.5386 - val_loss: 7.3946 - val_mae: 2.1068 - val_mse: 7.3946\n",
            "Epoch 540/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.4894 - mae: 1.2399 - mse: 3.4894 - val_loss: 7.5818 - val_mae: 2.1158 - val_mse: 7.5818\n",
            "Epoch 541/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.4828 - mae: 1.2423 - mse: 3.4828 - val_loss: 7.4553 - val_mae: 2.1418 - val_mse: 7.4553\n",
            "Epoch 542/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 3.6070 - mae: 1.2415 - mse: 3.6070 - val_loss: 7.3405 - val_mae: 2.0836 - val_mse: 7.3405\n",
            "Epoch 543/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.3597 - mae: 1.2101 - mse: 3.3597 - val_loss: 7.7561 - val_mae: 2.1337 - val_mse: 7.7561\n",
            "Epoch 544/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.3812 - mae: 1.2263 - mse: 3.3812 - val_loss: 7.9708 - val_mae: 2.1489 - val_mse: 7.9708\n",
            "Epoch 545/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 3.5081 - mae: 1.2391 - mse: 3.5081 - val_loss: 7.5112 - val_mae: 2.1129 - val_mse: 7.5112\n",
            "Epoch 546/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.3212 - mae: 1.1970 - mse: 3.3212 - val_loss: 7.9435 - val_mae: 2.1733 - val_mse: 7.9435\n",
            "Epoch 547/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.5032 - mae: 1.2403 - mse: 3.5032 - val_loss: 7.4818 - val_mae: 2.1057 - val_mse: 7.4818\n",
            "Epoch 548/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.4156 - mae: 1.2835 - mse: 3.4156 - val_loss: 8.3513 - val_mae: 2.1980 - val_mse: 8.3513\n",
            "Epoch 549/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.4007 - mae: 1.2175 - mse: 3.4007 - val_loss: 7.2721 - val_mae: 2.0905 - val_mse: 7.2721\n",
            "Epoch 550/1000\n",
            "251/251 [==============================] - 0s 158us/sample - loss: 3.5137 - mae: 1.2286 - mse: 3.5137 - val_loss: 7.5367 - val_mae: 2.1194 - val_mse: 7.5367\n",
            "Epoch 551/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.3635 - mae: 1.2271 - mse: 3.3635 - val_loss: 7.8379 - val_mae: 2.1367 - val_mse: 7.8379\n",
            "Epoch 552/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.5750 - mae: 1.2353 - mse: 3.5750 - val_loss: 7.4936 - val_mae: 2.1249 - val_mse: 7.4936\n",
            "Epoch 553/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.5125 - mae: 1.2101 - mse: 3.5125 - val_loss: 7.4914 - val_mae: 2.1086 - val_mse: 7.4914\n",
            "Epoch 554/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.3953 - mae: 1.2185 - mse: 3.3953 - val_loss: 8.1172 - val_mae: 2.2099 - val_mse: 8.1172\n",
            "Epoch 555/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.6326 - mae: 1.2374 - mse: 3.6326 - val_loss: 7.3549 - val_mae: 2.1023 - val_mse: 7.3549\n",
            "Epoch 556/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.4988 - mae: 1.2093 - mse: 3.4988 - val_loss: 7.3179 - val_mae: 2.1013 - val_mse: 7.3179\n",
            "Epoch 557/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.3356 - mae: 1.2229 - mse: 3.3356 - val_loss: 7.7921 - val_mae: 2.1367 - val_mse: 7.7921\n",
            "Epoch 558/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.3622 - mae: 1.1796 - mse: 3.3622 - val_loss: 7.3674 - val_mae: 2.1104 - val_mse: 7.3674\n",
            "Epoch 559/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.5635 - mae: 1.2200 - mse: 3.5635 - val_loss: 7.4196 - val_mae: 2.1021 - val_mse: 7.4196\n",
            "Epoch 560/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.6308 - mae: 1.2075 - mse: 3.6308 - val_loss: 7.6575 - val_mae: 2.1449 - val_mse: 7.6575\n",
            "Epoch 561/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 3.4091 - mae: 1.2166 - mse: 3.4091 - val_loss: 7.6261 - val_mae: 2.1142 - val_mse: 7.6261\n",
            "Epoch 562/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.3651 - mae: 1.2246 - mse: 3.3651 - val_loss: 7.3450 - val_mae: 2.0786 - val_mse: 7.3450\n",
            "Epoch 563/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.4249 - mae: 1.2415 - mse: 3.4249 - val_loss: 7.2019 - val_mae: 2.0867 - val_mse: 7.2019\n",
            "Epoch 564/1000\n",
            "251/251 [==============================] - 0s 166us/sample - loss: 3.3930 - mae: 1.2288 - mse: 3.3930 - val_loss: 7.2465 - val_mae: 2.0742 - val_mse: 7.2465\n",
            "Epoch 565/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.3649 - mae: 1.2009 - mse: 3.3649 - val_loss: 7.5118 - val_mae: 2.1109 - val_mse: 7.5118\n",
            "Epoch 566/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.6331 - mae: 1.2389 - mse: 3.6331 - val_loss: 7.3725 - val_mae: 2.1293 - val_mse: 7.3725\n",
            "Epoch 567/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 3.4018 - mae: 1.2197 - mse: 3.4018 - val_loss: 7.5167 - val_mae: 2.0988 - val_mse: 7.5167\n",
            "Epoch 568/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.3896 - mae: 1.2405 - mse: 3.3896 - val_loss: 7.4048 - val_mae: 2.0906 - val_mse: 7.4048\n",
            "Epoch 569/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.5501 - mae: 1.2201 - mse: 3.5501 - val_loss: 7.2628 - val_mae: 2.0817 - val_mse: 7.2628\n",
            "Epoch 570/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.3578 - mae: 1.2321 - mse: 3.3578 - val_loss: 7.2568 - val_mae: 2.0755 - val_mse: 7.2568\n",
            "Epoch 571/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.2550 - mae: 1.1778 - mse: 3.2550 - val_loss: 7.6105 - val_mae: 2.1287 - val_mse: 7.6105\n",
            "Epoch 572/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.5501 - mae: 1.2192 - mse: 3.5501 - val_loss: 7.6018 - val_mae: 2.1105 - val_mse: 7.6018\n",
            "Epoch 573/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 3.2741 - mae: 1.1664 - mse: 3.2741 - val_loss: 7.8604 - val_mae: 2.1350 - val_mse: 7.8604\n",
            "Epoch 574/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.3499 - mae: 1.1918 - mse: 3.3499 - val_loss: 8.5620 - val_mae: 2.2717 - val_mse: 8.5620\n",
            "Epoch 575/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.5880 - mae: 1.2501 - mse: 3.5880 - val_loss: 7.4114 - val_mae: 2.1046 - val_mse: 7.4114\n",
            "Epoch 576/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.4088 - mae: 1.2039 - mse: 3.4088 - val_loss: 7.6933 - val_mae: 2.1541 - val_mse: 7.6933\n",
            "Epoch 577/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.2381 - mae: 1.1815 - mse: 3.2381 - val_loss: 7.4927 - val_mae: 2.0912 - val_mse: 7.4927\n",
            "Epoch 578/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.3986 - mae: 1.2296 - mse: 3.3986 - val_loss: 7.5422 - val_mae: 2.1219 - val_mse: 7.5422\n",
            "Epoch 579/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.4423 - mae: 1.2149 - mse: 3.4423 - val_loss: 7.5404 - val_mae: 2.1056 - val_mse: 7.5404\n",
            "Epoch 580/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.4676 - mae: 1.2067 - mse: 3.4676 - val_loss: 7.3899 - val_mae: 2.0899 - val_mse: 7.3899\n",
            "Epoch 581/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 3.2371 - mae: 1.1839 - mse: 3.2371 - val_loss: 7.3766 - val_mae: 2.0890 - val_mse: 7.3766\n",
            "Epoch 582/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.3456 - mae: 1.2200 - mse: 3.3456 - val_loss: 7.5671 - val_mae: 2.1566 - val_mse: 7.5671\n",
            "Epoch 583/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.2570 - mae: 1.1858 - mse: 3.2570 - val_loss: 7.4163 - val_mae: 2.0859 - val_mse: 7.4163\n",
            "Epoch 584/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.5152 - mae: 1.2425 - mse: 3.5152 - val_loss: 7.3433 - val_mae: 2.1363 - val_mse: 7.3433\n",
            "Epoch 585/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.4429 - mae: 1.2233 - mse: 3.4429 - val_loss: 7.1280 - val_mae: 2.0662 - val_mse: 7.1280\n",
            "Epoch 586/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 3.3078 - mae: 1.2052 - mse: 3.3078 - val_loss: 7.3909 - val_mae: 2.1047 - val_mse: 7.3909\n",
            "Epoch 587/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.2826 - mae: 1.1865 - mse: 3.2826 - val_loss: 7.4285 - val_mae: 2.1296 - val_mse: 7.4285\n",
            "Epoch 588/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.4809 - mae: 1.2364 - mse: 3.4809 - val_loss: 7.2211 - val_mae: 2.0746 - val_mse: 7.2211\n",
            "Epoch 589/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.3793 - mae: 1.1941 - mse: 3.3793 - val_loss: 7.3331 - val_mae: 2.0987 - val_mse: 7.3331\n",
            "Epoch 590/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.3413 - mae: 1.1885 - mse: 3.3413 - val_loss: 7.6648 - val_mae: 2.1125 - val_mse: 7.6648\n",
            "Epoch 591/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.3505 - mae: 1.2017 - mse: 3.3505 - val_loss: 7.4574 - val_mae: 2.1081 - val_mse: 7.4574\n",
            "Epoch 592/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.3658 - mae: 1.2041 - mse: 3.3658 - val_loss: 7.4231 - val_mae: 2.1168 - val_mse: 7.4231\n",
            "Epoch 593/1000\n",
            "251/251 [==============================] - 0s 201us/sample - loss: 3.5288 - mae: 1.2277 - mse: 3.5288 - val_loss: 7.7475 - val_mae: 2.1394 - val_mse: 7.7475\n",
            "Epoch 594/1000\n",
            "251/251 [==============================] - 0s 160us/sample - loss: 3.4596 - mae: 1.1974 - mse: 3.4596 - val_loss: 7.3981 - val_mae: 2.1361 - val_mse: 7.3981\n",
            "Epoch 595/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.3895 - mae: 1.1991 - mse: 3.3895 - val_loss: 7.6081 - val_mae: 2.1325 - val_mse: 7.6081\n",
            "Epoch 596/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 3.2145 - mae: 1.1671 - mse: 3.2145 - val_loss: 7.5511 - val_mae: 2.1135 - val_mse: 7.5511\n",
            "Epoch 597/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 3.3518 - mae: 1.2043 - mse: 3.3518 - val_loss: 7.4866 - val_mae: 2.1448 - val_mse: 7.4866\n",
            "Epoch 598/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.2582 - mae: 1.1822 - mse: 3.2582 - val_loss: 7.8104 - val_mae: 2.1640 - val_mse: 7.8104\n",
            "Epoch 599/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.2530 - mae: 1.2142 - mse: 3.2530 - val_loss: 7.4459 - val_mae: 2.1356 - val_mse: 7.4459\n",
            "Epoch 600/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.4067 - mae: 1.2084 - mse: 3.4067 - val_loss: 7.3026 - val_mae: 2.0879 - val_mse: 7.3026\n",
            "Epoch 601/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 3.3859 - mae: 1.2150 - mse: 3.3859 - val_loss: 7.7249 - val_mae: 2.1498 - val_mse: 7.7249\n",
            "Epoch 602/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.1467 - mae: 1.1985 - mse: 3.1467 - val_loss: 8.3443 - val_mae: 2.2109 - val_mse: 8.3443\n",
            "Epoch 603/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 3.7669 - mae: 1.2989 - mse: 3.7669 - val_loss: 7.3043 - val_mae: 2.0746 - val_mse: 7.3043\n",
            "Epoch 604/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.2124 - mae: 1.1627 - mse: 3.2124 - val_loss: 7.3527 - val_mae: 2.0736 - val_mse: 7.3527\n",
            "Epoch 605/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.2577 - mae: 1.2282 - mse: 3.2577 - val_loss: 7.5774 - val_mae: 2.1112 - val_mse: 7.5774\n",
            "Epoch 606/1000\n",
            "251/251 [==============================] - 0s 163us/sample - loss: 3.2502 - mae: 1.1627 - mse: 3.2502 - val_loss: 7.3884 - val_mae: 2.0792 - val_mse: 7.3884\n",
            "Epoch 607/1000\n",
            "251/251 [==============================] - 0s 162us/sample - loss: 3.5472 - mae: 1.2183 - mse: 3.5472 - val_loss: 7.5572 - val_mae: 2.1059 - val_mse: 7.5572\n",
            "Epoch 608/1000\n",
            "251/251 [==============================] - 0s 162us/sample - loss: 3.2411 - mae: 1.1715 - mse: 3.2411 - val_loss: 7.0038 - val_mae: 2.0553 - val_mse: 7.0038\n",
            "Epoch 609/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.3032 - mae: 1.2023 - mse: 3.3032 - val_loss: 6.9204 - val_mae: 2.0487 - val_mse: 6.9204\n",
            "Epoch 610/1000\n",
            "251/251 [==============================] - 0s 151us/sample - loss: 3.3368 - mae: 1.1870 - mse: 3.3368 - val_loss: 7.2004 - val_mae: 2.0665 - val_mse: 7.2004\n",
            "Epoch 611/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.1913 - mae: 1.1452 - mse: 3.1913 - val_loss: 7.5905 - val_mae: 2.1383 - val_mse: 7.5905\n",
            "Epoch 612/1000\n",
            "251/251 [==============================] - 0s 171us/sample - loss: 3.2179 - mae: 1.1799 - mse: 3.2179 - val_loss: 8.6335 - val_mae: 2.2491 - val_mse: 8.6335\n",
            "Epoch 613/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 3.3500 - mae: 1.2541 - mse: 3.3500 - val_loss: 7.9678 - val_mae: 2.1662 - val_mse: 7.9678\n",
            "Epoch 614/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.3014 - mae: 1.1872 - mse: 3.3014 - val_loss: 7.4956 - val_mae: 2.1341 - val_mse: 7.4956\n",
            "Epoch 615/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.0993 - mae: 1.1641 - mse: 3.0993 - val_loss: 7.8730 - val_mae: 2.1542 - val_mse: 7.8730\n",
            "Epoch 616/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.3569 - mae: 1.1965 - mse: 3.3569 - val_loss: 7.2551 - val_mae: 2.1169 - val_mse: 7.2551\n",
            "Epoch 617/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.4541 - mae: 1.2336 - mse: 3.4541 - val_loss: 7.3872 - val_mae: 2.1205 - val_mse: 7.3872\n",
            "Epoch 618/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 3.1649 - mae: 1.1448 - mse: 3.1649 - val_loss: 7.2781 - val_mae: 2.0797 - val_mse: 7.2781\n",
            "Epoch 619/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.2666 - mae: 1.1970 - mse: 3.2666 - val_loss: 7.4014 - val_mae: 2.1201 - val_mse: 7.4014\n",
            "Epoch 620/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 3.1629 - mae: 1.1446 - mse: 3.1629 - val_loss: 7.5874 - val_mae: 2.1192 - val_mse: 7.5874\n",
            "Epoch 621/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.1926 - mae: 1.1306 - mse: 3.1926 - val_loss: 7.7615 - val_mae: 2.1851 - val_mse: 7.7615\n",
            "Epoch 622/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.3831 - mae: 1.2003 - mse: 3.3831 - val_loss: 7.6856 - val_mae: 2.1153 - val_mse: 7.6856\n",
            "Epoch 623/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 3.2549 - mae: 1.1488 - mse: 3.2549 - val_loss: 7.2166 - val_mae: 2.0700 - val_mse: 7.2166\n",
            "Epoch 624/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.2345 - mae: 1.1443 - mse: 3.2345 - val_loss: 7.6414 - val_mae: 2.1711 - val_mse: 7.6414\n",
            "Epoch 625/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.2204 - mae: 1.1679 - mse: 3.2204 - val_loss: 7.0552 - val_mae: 2.0660 - val_mse: 7.0552\n",
            "Epoch 626/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.2983 - mae: 1.1754 - mse: 3.2983 - val_loss: 7.2926 - val_mae: 2.1062 - val_mse: 7.2926\n",
            "Epoch 627/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.1578 - mae: 1.1783 - mse: 3.1578 - val_loss: 7.1841 - val_mae: 2.0725 - val_mse: 7.1841\n",
            "Epoch 628/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.2665 - mae: 1.1863 - mse: 3.2665 - val_loss: 7.3139 - val_mae: 2.1256 - val_mse: 7.3139\n",
            "Epoch 629/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.1915 - mae: 1.1491 - mse: 3.1915 - val_loss: 7.6200 - val_mae: 2.1502 - val_mse: 7.6200\n",
            "Epoch 630/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 3.2176 - mae: 1.1734 - mse: 3.2176 - val_loss: 7.2758 - val_mae: 2.0931 - val_mse: 7.2758\n",
            "Epoch 631/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.1625 - mae: 1.1343 - mse: 3.1625 - val_loss: 7.7226 - val_mae: 2.1897 - val_mse: 7.7226\n",
            "Epoch 632/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.1098 - mae: 1.1929 - mse: 3.1098 - val_loss: 7.5596 - val_mae: 2.1323 - val_mse: 7.5596\n",
            "Epoch 633/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.3937 - mae: 1.1896 - mse: 3.3937 - val_loss: 7.5029 - val_mae: 2.1142 - val_mse: 7.5029\n",
            "Epoch 634/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.1100 - mae: 1.2057 - mse: 3.1100 - val_loss: 7.3493 - val_mae: 2.1015 - val_mse: 7.3493\n",
            "Epoch 635/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 3.1089 - mae: 1.1556 - mse: 3.1089 - val_loss: 7.1168 - val_mae: 2.0863 - val_mse: 7.1168\n",
            "Epoch 636/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.1819 - mae: 1.1779 - mse: 3.1819 - val_loss: 7.2261 - val_mae: 2.0930 - val_mse: 7.2261\n",
            "Epoch 637/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.1458 - mae: 1.1506 - mse: 3.1458 - val_loss: 7.0763 - val_mae: 2.0813 - val_mse: 7.0763\n",
            "Epoch 638/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.2703 - mae: 1.1713 - mse: 3.2703 - val_loss: 7.4952 - val_mae: 2.1669 - val_mse: 7.4952\n",
            "Epoch 639/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.3301 - mae: 1.1519 - mse: 3.3301 - val_loss: 7.2501 - val_mae: 2.0803 - val_mse: 7.2501\n",
            "Epoch 640/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 3.1033 - mae: 1.1379 - mse: 3.1033 - val_loss: 8.2107 - val_mae: 2.1931 - val_mse: 8.2107\n",
            "Epoch 641/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.1992 - mae: 1.1724 - mse: 3.1992 - val_loss: 7.0163 - val_mae: 2.0695 - val_mse: 7.0163\n",
            "Epoch 642/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 3.2830 - mae: 1.1604 - mse: 3.2830 - val_loss: 7.7079 - val_mae: 2.1874 - val_mse: 7.7079\n",
            "Epoch 643/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 3.1119 - mae: 1.1620 - mse: 3.1119 - val_loss: 7.2708 - val_mae: 2.1098 - val_mse: 7.2708\n",
            "Epoch 644/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.2864 - mae: 1.1548 - mse: 3.2864 - val_loss: 7.2916 - val_mae: 2.1051 - val_mse: 7.2916\n",
            "Epoch 645/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.2731 - mae: 1.1787 - mse: 3.2731 - val_loss: 8.0945 - val_mae: 2.1829 - val_mse: 8.0945\n",
            "Epoch 646/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.3959 - mae: 1.1844 - mse: 3.3959 - val_loss: 7.4811 - val_mae: 2.1007 - val_mse: 7.4811\n",
            "Epoch 647/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.2058 - mae: 1.1513 - mse: 3.2058 - val_loss: 7.2259 - val_mae: 2.0855 - val_mse: 7.2259\n",
            "Epoch 648/1000\n",
            "251/251 [==============================] - 0s 159us/sample - loss: 3.1201 - mae: 1.1530 - mse: 3.1201 - val_loss: 7.6757 - val_mae: 2.1544 - val_mse: 7.6757\n",
            "Epoch 649/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.2768 - mae: 1.1784 - mse: 3.2768 - val_loss: 7.1123 - val_mae: 2.0607 - val_mse: 7.1123\n",
            "Epoch 650/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.1900 - mae: 1.1437 - mse: 3.1900 - val_loss: 7.3116 - val_mae: 2.1183 - val_mse: 7.3116\n",
            "Epoch 651/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 3.2036 - mae: 1.1720 - mse: 3.2036 - val_loss: 7.3766 - val_mae: 2.1166 - val_mse: 7.3766\n",
            "Epoch 652/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 3.0896 - mae: 1.1543 - mse: 3.0896 - val_loss: 7.2104 - val_mae: 2.0995 - val_mse: 7.2104\n",
            "Epoch 653/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.0761 - mae: 1.1843 - mse: 3.0761 - val_loss: 7.7437 - val_mae: 2.1316 - val_mse: 7.7437\n",
            "Epoch 654/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.2949 - mae: 1.1686 - mse: 3.2949 - val_loss: 7.2401 - val_mae: 2.0720 - val_mse: 7.2401\n",
            "Epoch 655/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.0354 - mae: 1.1359 - mse: 3.0354 - val_loss: 7.2141 - val_mae: 2.0775 - val_mse: 7.2141\n",
            "Epoch 656/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.2731 - mae: 1.1345 - mse: 3.2731 - val_loss: 7.3524 - val_mae: 2.1024 - val_mse: 7.3524\n",
            "Epoch 657/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.3345 - mae: 1.1825 - mse: 3.3345 - val_loss: 7.3781 - val_mae: 2.1036 - val_mse: 7.3781\n",
            "Epoch 658/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 3.1864 - mae: 1.1488 - mse: 3.1864 - val_loss: 7.5867 - val_mae: 2.1135 - val_mse: 7.5867\n",
            "Epoch 659/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.1488 - mae: 1.1437 - mse: 3.1488 - val_loss: 7.2325 - val_mae: 2.0829 - val_mse: 7.2325\n",
            "Epoch 660/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.2791 - mae: 1.1699 - mse: 3.2791 - val_loss: 7.1650 - val_mae: 2.0844 - val_mse: 7.1650\n",
            "Epoch 661/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 3.1625 - mae: 1.1205 - mse: 3.1625 - val_loss: 7.5525 - val_mae: 2.1344 - val_mse: 7.5525\n",
            "Epoch 662/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 3.2205 - mae: 1.1827 - mse: 3.2205 - val_loss: 7.2939 - val_mae: 2.0929 - val_mse: 7.2939\n",
            "Epoch 663/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.9751 - mae: 1.1148 - mse: 2.9751 - val_loss: 7.2221 - val_mae: 2.1108 - val_mse: 7.2221\n",
            "Epoch 664/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.1425 - mae: 1.1001 - mse: 3.1425 - val_loss: 7.4005 - val_mae: 2.1281 - val_mse: 7.4005\n",
            "Epoch 665/1000\n",
            "251/251 [==============================] - 0s 167us/sample - loss: 3.1999 - mae: 1.1877 - mse: 3.1999 - val_loss: 7.6011 - val_mae: 2.1637 - val_mse: 7.6011\n",
            "Epoch 666/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 3.1840 - mae: 1.2110 - mse: 3.1840 - val_loss: 7.2709 - val_mae: 2.0939 - val_mse: 7.2709\n",
            "Epoch 667/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.0917 - mae: 1.1279 - mse: 3.0917 - val_loss: 7.5430 - val_mae: 2.1106 - val_mse: 7.5430\n",
            "Epoch 668/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.0135 - mae: 1.1070 - mse: 3.0135 - val_loss: 7.4939 - val_mae: 2.1397 - val_mse: 7.4939\n",
            "Epoch 669/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.1084 - mae: 1.1547 - mse: 3.1084 - val_loss: 7.2882 - val_mae: 2.0894 - val_mse: 7.2882\n",
            "Epoch 670/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.0866 - mae: 1.1391 - mse: 3.0866 - val_loss: 7.1420 - val_mae: 2.0739 - val_mse: 7.1420\n",
            "Epoch 671/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.0459 - mae: 1.1244 - mse: 3.0459 - val_loss: 7.7462 - val_mae: 2.1746 - val_mse: 7.7462\n",
            "Epoch 672/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.2981 - mae: 1.1842 - mse: 3.2981 - val_loss: 7.4656 - val_mae: 2.1449 - val_mse: 7.4656\n",
            "Epoch 673/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.0072 - mae: 1.1405 - mse: 3.0072 - val_loss: 7.4798 - val_mae: 2.1138 - val_mse: 7.4798\n",
            "Epoch 674/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 3.1989 - mae: 1.1515 - mse: 3.1989 - val_loss: 7.2571 - val_mae: 2.0943 - val_mse: 7.2571\n",
            "Epoch 675/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.2143 - mae: 1.1483 - mse: 3.2143 - val_loss: 7.6533 - val_mae: 2.1304 - val_mse: 7.6533\n",
            "Epoch 676/1000\n",
            "251/251 [==============================] - 0s 164us/sample - loss: 2.9508 - mae: 1.1022 - mse: 2.9508 - val_loss: 7.1964 - val_mae: 2.0951 - val_mse: 7.1964\n",
            "Epoch 677/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 3.2114 - mae: 1.1662 - mse: 3.2114 - val_loss: 7.4999 - val_mae: 2.1139 - val_mse: 7.4999\n",
            "Epoch 678/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.0891 - mae: 1.1366 - mse: 3.0891 - val_loss: 7.0108 - val_mae: 2.0803 - val_mse: 7.0108\n",
            "Epoch 679/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.9089 - mae: 1.1026 - mse: 2.9089 - val_loss: 7.5045 - val_mae: 2.1454 - val_mse: 7.5045\n",
            "Epoch 680/1000\n",
            "251/251 [==============================] - 0s 120us/sample - loss: 3.1706 - mae: 1.1351 - mse: 3.1706 - val_loss: 7.2851 - val_mae: 2.0855 - val_mse: 7.2851\n",
            "Epoch 681/1000\n",
            "251/251 [==============================] - 0s 119us/sample - loss: 3.0482 - mae: 1.1467 - mse: 3.0482 - val_loss: 8.2424 - val_mae: 2.2375 - val_mse: 8.2424\n",
            "Epoch 682/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.1685 - mae: 1.2038 - mse: 3.1685 - val_loss: 7.5633 - val_mae: 2.1273 - val_mse: 7.5633\n",
            "Epoch 683/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.9761 - mae: 1.0803 - mse: 2.9761 - val_loss: 6.9805 - val_mae: 2.0628 - val_mse: 6.9805\n",
            "Epoch 684/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 3.1411 - mae: 1.1400 - mse: 3.1411 - val_loss: 7.5550 - val_mae: 2.1478 - val_mse: 7.5550\n",
            "Epoch 685/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.1281 - mae: 1.1655 - mse: 3.1281 - val_loss: 7.7669 - val_mae: 2.1722 - val_mse: 7.7669\n",
            "Epoch 686/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 2.9212 - mae: 1.0908 - mse: 2.9212 - val_loss: 7.0937 - val_mae: 2.0873 - val_mse: 7.0937\n",
            "Epoch 687/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.3132 - mae: 1.1900 - mse: 3.3132 - val_loss: 7.5058 - val_mae: 2.1178 - val_mse: 7.5058\n",
            "Epoch 688/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 3.1504 - mae: 1.1354 - mse: 3.1504 - val_loss: 7.0857 - val_mae: 2.0780 - val_mse: 7.0857\n",
            "Epoch 689/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 3.1326 - mae: 1.1472 - mse: 3.1326 - val_loss: 7.2585 - val_mae: 2.1165 - val_mse: 7.2585\n",
            "Epoch 690/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.3736 - mae: 1.2182 - mse: 3.3736 - val_loss: 7.1822 - val_mae: 2.0948 - val_mse: 7.1822\n",
            "Epoch 691/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 3.2307 - mae: 1.1534 - mse: 3.2307 - val_loss: 7.1901 - val_mae: 2.0891 - val_mse: 7.1901\n",
            "Epoch 692/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 3.0723 - mae: 1.1141 - mse: 3.0723 - val_loss: 7.0638 - val_mae: 2.0874 - val_mse: 7.0638\n",
            "Epoch 693/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.9598 - mae: 1.0927 - mse: 2.9598 - val_loss: 7.2043 - val_mae: 2.1171 - val_mse: 7.2043\n",
            "Epoch 694/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 3.0141 - mae: 1.0931 - mse: 3.0141 - val_loss: 7.1574 - val_mae: 2.0929 - val_mse: 7.1574\n",
            "Epoch 695/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.1543 - mae: 1.1395 - mse: 3.1543 - val_loss: 7.3837 - val_mae: 2.1316 - val_mse: 7.3837\n",
            "Epoch 696/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 3.1525 - mae: 1.1318 - mse: 3.1525 - val_loss: 7.4372 - val_mae: 2.1439 - val_mse: 7.4372\n",
            "Epoch 697/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 3.0204 - mae: 1.1055 - mse: 3.0204 - val_loss: 7.4959 - val_mae: 2.1527 - val_mse: 7.4959\n",
            "Epoch 698/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 3.1699 - mae: 1.1450 - mse: 3.1699 - val_loss: 7.5209 - val_mae: 2.1620 - val_mse: 7.5209\n",
            "Epoch 699/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 3.1133 - mae: 1.1165 - mse: 3.1133 - val_loss: 7.4463 - val_mae: 2.1425 - val_mse: 7.4463\n",
            "Epoch 700/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.3716 - mae: 1.1771 - mse: 3.3716 - val_loss: 7.4001 - val_mae: 2.1587 - val_mse: 7.4001\n",
            "Epoch 701/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.0038 - mae: 1.1451 - mse: 3.0038 - val_loss: 7.6251 - val_mae: 2.1304 - val_mse: 7.6251\n",
            "Epoch 702/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 3.3179 - mae: 1.1710 - mse: 3.3179 - val_loss: 7.4728 - val_mae: 2.1136 - val_mse: 7.4728\n",
            "Epoch 703/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.9232 - mae: 1.0961 - mse: 2.9232 - val_loss: 7.2649 - val_mae: 2.1704 - val_mse: 7.2649\n",
            "Epoch 704/1000\n",
            "251/251 [==============================] - 0s 158us/sample - loss: 3.1513 - mae: 1.1886 - mse: 3.1513 - val_loss: 6.9785 - val_mae: 2.0729 - val_mse: 6.9785\n",
            "Epoch 705/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 3.1862 - mae: 1.1444 - mse: 3.1862 - val_loss: 7.4946 - val_mae: 2.1488 - val_mse: 7.4946\n",
            "Epoch 706/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.0972 - mae: 1.1342 - mse: 3.0972 - val_loss: 7.1788 - val_mae: 2.0922 - val_mse: 7.1788\n",
            "Epoch 707/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 3.2653 - mae: 1.1251 - mse: 3.2653 - val_loss: 7.4892 - val_mae: 2.1692 - val_mse: 7.4892\n",
            "Epoch 708/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.9254 - mae: 1.0902 - mse: 2.9254 - val_loss: 7.5916 - val_mae: 2.1762 - val_mse: 7.5916\n",
            "Epoch 709/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 3.2676 - mae: 1.1495 - mse: 3.2676 - val_loss: 7.3389 - val_mae: 2.1372 - val_mse: 7.3389\n",
            "Epoch 710/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.9904 - mae: 1.1100 - mse: 2.9904 - val_loss: 7.7766 - val_mae: 2.2267 - val_mse: 7.7766\n",
            "Epoch 711/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.9701 - mae: 1.1243 - mse: 2.9701 - val_loss: 7.1709 - val_mae: 2.0916 - val_mse: 7.1709\n",
            "Epoch 712/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.9349 - mae: 1.0823 - mse: 2.9349 - val_loss: 7.4068 - val_mae: 2.1201 - val_mse: 7.4068\n",
            "Epoch 713/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.0858 - mae: 1.1166 - mse: 3.0858 - val_loss: 7.3605 - val_mae: 2.1247 - val_mse: 7.3605\n",
            "Epoch 714/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.1554 - mae: 1.1675 - mse: 3.1554 - val_loss: 7.6009 - val_mae: 2.1881 - val_mse: 7.6009\n",
            "Epoch 715/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 3.0079 - mae: 1.1358 - mse: 3.0079 - val_loss: 7.3917 - val_mae: 2.1501 - val_mse: 7.3917\n",
            "Epoch 716/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 3.0505 - mae: 1.1343 - mse: 3.0505 - val_loss: 7.6277 - val_mae: 2.1775 - val_mse: 7.6277\n",
            "Epoch 717/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.1863 - mae: 1.1437 - mse: 3.1863 - val_loss: 7.2825 - val_mae: 2.1240 - val_mse: 7.2825\n",
            "Epoch 718/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 2.9385 - mae: 1.0777 - mse: 2.9385 - val_loss: 7.9834 - val_mae: 2.2006 - val_mse: 7.9834\n",
            "Epoch 719/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 3.2132 - mae: 1.2082 - mse: 3.2132 - val_loss: 7.3997 - val_mae: 2.1022 - val_mse: 7.3997\n",
            "Epoch 720/1000\n",
            "251/251 [==============================] - 0s 157us/sample - loss: 3.0850 - mae: 1.1463 - mse: 3.0850 - val_loss: 7.1289 - val_mae: 2.0847 - val_mse: 7.1289\n",
            "Epoch 721/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.8972 - mae: 1.0743 - mse: 2.8972 - val_loss: 7.2972 - val_mae: 2.1335 - val_mse: 7.2972\n",
            "Epoch 722/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 3.0255 - mae: 1.1417 - mse: 3.0255 - val_loss: 7.9199 - val_mae: 2.1722 - val_mse: 7.9199\n",
            "Epoch 723/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.0566 - mae: 1.1476 - mse: 3.0566 - val_loss: 7.0613 - val_mae: 2.0878 - val_mse: 7.0613\n",
            "Epoch 724/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.1575 - mae: 1.1869 - mse: 3.1575 - val_loss: 7.5911 - val_mae: 2.1448 - val_mse: 7.5911\n",
            "Epoch 725/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.9840 - mae: 1.1055 - mse: 2.9840 - val_loss: 7.2599 - val_mae: 2.1063 - val_mse: 7.2599\n",
            "Epoch 726/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.1844 - mae: 1.1508 - mse: 3.1844 - val_loss: 7.2687 - val_mae: 2.1074 - val_mse: 7.2687\n",
            "Epoch 727/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.9256 - mae: 1.0871 - mse: 2.9256 - val_loss: 7.8105 - val_mae: 2.1936 - val_mse: 7.8105\n",
            "Epoch 728/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.9531 - mae: 1.1265 - mse: 2.9531 - val_loss: 7.7413 - val_mae: 2.1839 - val_mse: 7.7413\n",
            "Epoch 729/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.9544 - mae: 1.1285 - mse: 2.9544 - val_loss: 7.1369 - val_mae: 2.0734 - val_mse: 7.1369\n",
            "Epoch 730/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.0414 - mae: 1.0993 - mse: 3.0414 - val_loss: 7.4765 - val_mae: 2.1482 - val_mse: 7.4765\n",
            "Epoch 731/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.9325 - mae: 1.0686 - mse: 2.9325 - val_loss: 6.9971 - val_mae: 2.0527 - val_mse: 6.9971\n",
            "Epoch 732/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 3.0984 - mae: 1.1376 - mse: 3.0984 - val_loss: 7.3238 - val_mae: 2.1285 - val_mse: 7.3238\n",
            "Epoch 733/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 3.0142 - mae: 1.1180 - mse: 3.0142 - val_loss: 7.1014 - val_mae: 2.1067 - val_mse: 7.1014\n",
            "Epoch 734/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.8850 - mae: 1.0865 - mse: 2.8850 - val_loss: 7.8538 - val_mae: 2.1983 - val_mse: 7.8538\n",
            "Epoch 735/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 3.3725 - mae: 1.2103 - mse: 3.3725 - val_loss: 7.2094 - val_mae: 2.0904 - val_mse: 7.2094\n",
            "Epoch 736/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.9695 - mae: 1.1369 - mse: 2.9695 - val_loss: 7.5788 - val_mae: 2.1497 - val_mse: 7.5788\n",
            "Epoch 737/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.8735 - mae: 1.1004 - mse: 2.8735 - val_loss: 7.2268 - val_mae: 2.1060 - val_mse: 7.2268\n",
            "Epoch 738/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.0774 - mae: 1.1366 - mse: 3.0774 - val_loss: 7.2294 - val_mae: 2.0846 - val_mse: 7.2294\n",
            "Epoch 739/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 3.2059 - mae: 1.1442 - mse: 3.2059 - val_loss: 6.8551 - val_mae: 2.0612 - val_mse: 6.8551\n",
            "Epoch 740/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 3.2274 - mae: 1.1569 - mse: 3.2274 - val_loss: 7.0799 - val_mae: 2.0874 - val_mse: 7.0799\n",
            "Epoch 741/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 2.9366 - mae: 1.1193 - mse: 2.9366 - val_loss: 7.6138 - val_mae: 2.1292 - val_mse: 7.6138\n",
            "Epoch 742/1000\n",
            "251/251 [==============================] - 0s 151us/sample - loss: 3.0199 - mae: 1.1070 - mse: 3.0199 - val_loss: 7.1304 - val_mae: 2.0817 - val_mse: 7.1304\n",
            "Epoch 743/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.9543 - mae: 1.1195 - mse: 2.9543 - val_loss: 6.9783 - val_mae: 2.0585 - val_mse: 6.9783\n",
            "Epoch 744/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 2.8154 - mae: 1.0676 - mse: 2.8154 - val_loss: 7.8035 - val_mae: 2.2245 - val_mse: 7.8035\n",
            "Epoch 745/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 3.1183 - mae: 1.1497 - mse: 3.1183 - val_loss: 7.3049 - val_mae: 2.0991 - val_mse: 7.3049\n",
            "Epoch 746/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.0637 - mae: 1.1017 - mse: 3.0637 - val_loss: 7.5940 - val_mae: 2.1541 - val_mse: 7.5940\n",
            "Epoch 747/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.9420 - mae: 1.1072 - mse: 2.9420 - val_loss: 7.0094 - val_mae: 2.1153 - val_mse: 7.0094\n",
            "Epoch 748/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 2.9716 - mae: 1.1024 - mse: 2.9716 - val_loss: 7.5892 - val_mae: 2.1429 - val_mse: 7.5892\n",
            "Epoch 749/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.9100 - mae: 1.0773 - mse: 2.9100 - val_loss: 7.4718 - val_mae: 2.1051 - val_mse: 7.4718\n",
            "Epoch 750/1000\n",
            "251/251 [==============================] - 0s 163us/sample - loss: 3.0973 - mae: 1.1327 - mse: 3.0973 - val_loss: 7.4066 - val_mae: 2.1168 - val_mse: 7.4066\n",
            "Epoch 751/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.0533 - mae: 1.1276 - mse: 3.0533 - val_loss: 6.9524 - val_mae: 2.0643 - val_mse: 6.9524\n",
            "Epoch 752/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.9279 - mae: 1.1113 - mse: 2.9279 - val_loss: 7.0351 - val_mae: 2.0701 - val_mse: 7.0351\n",
            "Epoch 753/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 3.2302 - mae: 1.1804 - mse: 3.2302 - val_loss: 7.1975 - val_mae: 2.0788 - val_mse: 7.1975\n",
            "Epoch 754/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.8911 - mae: 1.1259 - mse: 2.8911 - val_loss: 7.1205 - val_mae: 2.0796 - val_mse: 7.1205\n",
            "Epoch 755/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 2.9580 - mae: 1.1195 - mse: 2.9580 - val_loss: 7.8607 - val_mae: 2.1629 - val_mse: 7.8607\n",
            "Epoch 756/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.8908 - mae: 1.0909 - mse: 2.8908 - val_loss: 7.7726 - val_mae: 2.1550 - val_mse: 7.7726\n",
            "Epoch 757/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.7936 - mae: 1.0911 - mse: 2.7936 - val_loss: 7.6287 - val_mae: 2.1619 - val_mse: 7.6287\n",
            "Epoch 758/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 3.1198 - mae: 1.1488 - mse: 3.1198 - val_loss: 7.3919 - val_mae: 2.1283 - val_mse: 7.3919\n",
            "Epoch 759/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 3.0916 - mae: 1.1126 - mse: 3.0916 - val_loss: 7.0836 - val_mae: 2.0874 - val_mse: 7.0836\n",
            "Epoch 760/1000\n",
            "251/251 [==============================] - 0s 170us/sample - loss: 2.9539 - mae: 1.0845 - mse: 2.9539 - val_loss: 7.7118 - val_mae: 2.1515 - val_mse: 7.7118\n",
            "Epoch 761/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 3.0732 - mae: 1.1172 - mse: 3.0732 - val_loss: 7.4231 - val_mae: 2.1679 - val_mse: 7.4231\n",
            "Epoch 762/1000\n",
            "251/251 [==============================] - 0s 123us/sample - loss: 2.9467 - mae: 1.0871 - mse: 2.9467 - val_loss: 7.4310 - val_mae: 2.1062 - val_mse: 7.4310\n",
            "Epoch 763/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.8159 - mae: 1.0905 - mse: 2.8159 - val_loss: 7.3034 - val_mae: 2.0931 - val_mse: 7.3034\n",
            "Epoch 764/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.8434 - mae: 1.0611 - mse: 2.8434 - val_loss: 7.3424 - val_mae: 2.0935 - val_mse: 7.3424\n",
            "Epoch 765/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.9203 - mae: 1.1096 - mse: 2.9203 - val_loss: 7.3678 - val_mae: 2.1029 - val_mse: 7.3678\n",
            "Epoch 766/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.8969 - mae: 1.0757 - mse: 2.8969 - val_loss: 6.9030 - val_mae: 2.0884 - val_mse: 6.9030\n",
            "Epoch 767/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.0019 - mae: 1.1243 - mse: 3.0019 - val_loss: 7.6676 - val_mae: 2.1656 - val_mse: 7.6676\n",
            "Epoch 768/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.8456 - mae: 1.0829 - mse: 2.8456 - val_loss: 7.6339 - val_mae: 2.1405 - val_mse: 7.6339\n",
            "Epoch 769/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 2.7238 - mae: 1.1119 - mse: 2.7238 - val_loss: 7.1642 - val_mae: 2.1350 - val_mse: 7.1642\n",
            "Epoch 770/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 2.9169 - mae: 1.1023 - mse: 2.9169 - val_loss: 7.2357 - val_mae: 2.1264 - val_mse: 7.2357\n",
            "Epoch 771/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.7925 - mae: 1.1102 - mse: 2.7925 - val_loss: 6.9228 - val_mae: 2.0634 - val_mse: 6.9228\n",
            "Epoch 772/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.9646 - mae: 1.1294 - mse: 2.9646 - val_loss: 7.2016 - val_mae: 2.1063 - val_mse: 7.2016\n",
            "Epoch 773/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.8696 - mae: 1.0974 - mse: 2.8696 - val_loss: 7.1011 - val_mae: 2.0716 - val_mse: 7.1011\n",
            "Epoch 774/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 3.0047 - mae: 1.1079 - mse: 3.0047 - val_loss: 7.0342 - val_mae: 2.0671 - val_mse: 7.0342\n",
            "Epoch 775/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 3.0660 - mae: 1.1337 - mse: 3.0660 - val_loss: 7.3454 - val_mae: 2.0967 - val_mse: 7.3454\n",
            "Epoch 776/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.9356 - mae: 1.0969 - mse: 2.9356 - val_loss: 7.1439 - val_mae: 2.1094 - val_mse: 7.1439\n",
            "Epoch 777/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.9723 - mae: 1.0979 - mse: 2.9723 - val_loss: 7.1592 - val_mae: 2.0795 - val_mse: 7.1592\n",
            "Epoch 778/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 2.8299 - mae: 1.0640 - mse: 2.8299 - val_loss: 7.0341 - val_mae: 2.0766 - val_mse: 7.0341\n",
            "Epoch 779/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.9249 - mae: 1.1078 - mse: 2.9249 - val_loss: 6.8620 - val_mae: 2.0674 - val_mse: 6.8620\n",
            "Epoch 780/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 2.9207 - mae: 1.0842 - mse: 2.9207 - val_loss: 7.6103 - val_mae: 2.1785 - val_mse: 7.6103\n",
            "Epoch 781/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 2.9423 - mae: 1.0845 - mse: 2.9423 - val_loss: 7.2104 - val_mae: 2.1044 - val_mse: 7.2104\n",
            "Epoch 782/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.8885 - mae: 1.0878 - mse: 2.8885 - val_loss: 7.3428 - val_mae: 2.1349 - val_mse: 7.3428\n",
            "Epoch 783/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.8499 - mae: 1.0668 - mse: 2.8499 - val_loss: 7.8890 - val_mae: 2.2087 - val_mse: 7.8890\n",
            "Epoch 784/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.8925 - mae: 1.1022 - mse: 2.8925 - val_loss: 7.3626 - val_mae: 2.1376 - val_mse: 7.3626\n",
            "Epoch 785/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.8347 - mae: 1.0874 - mse: 2.8347 - val_loss: 7.2957 - val_mae: 2.1216 - val_mse: 7.2957\n",
            "Epoch 786/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.8316 - mae: 1.0697 - mse: 2.8316 - val_loss: 7.1348 - val_mae: 2.0970 - val_mse: 7.1348\n",
            "Epoch 787/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 2.8705 - mae: 1.0931 - mse: 2.8705 - val_loss: 7.4419 - val_mae: 2.1162 - val_mse: 7.4419\n",
            "Epoch 788/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 2.9172 - mae: 1.1213 - mse: 2.9172 - val_loss: 7.0350 - val_mae: 2.0821 - val_mse: 7.0350\n",
            "Epoch 789/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 2.8857 - mae: 1.1013 - mse: 2.8857 - val_loss: 7.1989 - val_mae: 2.0802 - val_mse: 7.1989\n",
            "Epoch 790/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.7221 - mae: 1.0597 - mse: 2.7221 - val_loss: 7.2933 - val_mae: 2.1212 - val_mse: 7.2933\n",
            "Epoch 791/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 3.0326 - mae: 1.1150 - mse: 3.0326 - val_loss: 7.4008 - val_mae: 2.1307 - val_mse: 7.4008\n",
            "Epoch 792/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.8994 - mae: 1.1141 - mse: 2.8994 - val_loss: 7.0301 - val_mae: 2.0885 - val_mse: 7.0301\n",
            "Epoch 793/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 2.7892 - mae: 1.0676 - mse: 2.7892 - val_loss: 7.8464 - val_mae: 2.1807 - val_mse: 7.8464\n",
            "Epoch 794/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.9787 - mae: 1.0887 - mse: 2.9787 - val_loss: 6.9572 - val_mae: 2.0833 - val_mse: 6.9572\n",
            "Epoch 795/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.9278 - mae: 1.1051 - mse: 2.9278 - val_loss: 7.0690 - val_mae: 2.0787 - val_mse: 7.0690\n",
            "Epoch 796/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.9271 - mae: 1.0820 - mse: 2.9271 - val_loss: 7.2839 - val_mae: 2.1073 - val_mse: 7.2839\n",
            "Epoch 797/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.8012 - mae: 1.0847 - mse: 2.8012 - val_loss: 7.2090 - val_mae: 2.1300 - val_mse: 7.2090\n",
            "Epoch 798/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.9558 - mae: 1.1004 - mse: 2.9558 - val_loss: 7.1107 - val_mae: 2.0974 - val_mse: 7.1107\n",
            "Epoch 799/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 3.0248 - mae: 1.0837 - mse: 3.0248 - val_loss: 6.9539 - val_mae: 2.0989 - val_mse: 6.9539\n",
            "Epoch 800/1000\n",
            "251/251 [==============================] - 0s 170us/sample - loss: 2.7715 - mae: 1.0768 - mse: 2.7715 - val_loss: 7.4421 - val_mae: 2.1129 - val_mse: 7.4421\n",
            "Epoch 801/1000\n",
            "251/251 [==============================] - 0s 189us/sample - loss: 2.9290 - mae: 1.0820 - mse: 2.9290 - val_loss: 6.7784 - val_mae: 2.0397 - val_mse: 6.7784\n",
            "Epoch 802/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 2.8094 - mae: 1.0804 - mse: 2.8094 - val_loss: 6.9554 - val_mae: 2.0987 - val_mse: 6.9554\n",
            "Epoch 803/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.9047 - mae: 1.1215 - mse: 2.9047 - val_loss: 6.9496 - val_mae: 2.0636 - val_mse: 6.9496\n",
            "Epoch 804/1000\n",
            "251/251 [==============================] - 0s 161us/sample - loss: 2.7104 - mae: 1.0457 - mse: 2.7104 - val_loss: 7.1745 - val_mae: 2.0963 - val_mse: 7.1745\n",
            "Epoch 805/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 2.9983 - mae: 1.0877 - mse: 2.9983 - val_loss: 6.9558 - val_mae: 2.1090 - val_mse: 6.9558\n",
            "Epoch 806/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.7769 - mae: 1.0902 - mse: 2.7769 - val_loss: 7.2125 - val_mae: 2.0935 - val_mse: 7.2125\n",
            "Epoch 807/1000\n",
            "251/251 [==============================] - 0s 157us/sample - loss: 2.7684 - mae: 1.0659 - mse: 2.7684 - val_loss: 7.3263 - val_mae: 2.1410 - val_mse: 7.3263\n",
            "Epoch 808/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 2.7208 - mae: 1.0349 - mse: 2.7208 - val_loss: 7.1075 - val_mae: 2.1188 - val_mse: 7.1075\n",
            "Epoch 809/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 3.0605 - mae: 1.0985 - mse: 3.0605 - val_loss: 7.0623 - val_mae: 2.1104 - val_mse: 7.0623\n",
            "Epoch 810/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.8785 - mae: 1.0698 - mse: 2.8785 - val_loss: 7.1254 - val_mae: 2.1285 - val_mse: 7.1254\n",
            "Epoch 811/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 2.8020 - mae: 1.1015 - mse: 2.8020 - val_loss: 8.0377 - val_mae: 2.1943 - val_mse: 8.0377\n",
            "Epoch 812/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 2.7126 - mae: 1.0555 - mse: 2.7126 - val_loss: 6.9924 - val_mae: 2.1034 - val_mse: 6.9924\n",
            "Epoch 813/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 2.8776 - mae: 1.1079 - mse: 2.8776 - val_loss: 7.1281 - val_mae: 2.0974 - val_mse: 7.1281\n",
            "Epoch 814/1000\n",
            "251/251 [==============================] - 0s 154us/sample - loss: 2.7371 - mae: 1.0292 - mse: 2.7371 - val_loss: 7.0530 - val_mae: 2.1084 - val_mse: 7.0530\n",
            "Epoch 815/1000\n",
            "251/251 [==============================] - 0s 182us/sample - loss: 2.7554 - mae: 1.0679 - mse: 2.7554 - val_loss: 6.8506 - val_mae: 2.0409 - val_mse: 6.8506\n",
            "Epoch 816/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 2.9609 - mae: 1.1236 - mse: 2.9609 - val_loss: 7.1704 - val_mae: 2.0924 - val_mse: 7.1704\n",
            "Epoch 817/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 2.8621 - mae: 1.0786 - mse: 2.8621 - val_loss: 7.2335 - val_mae: 2.1021 - val_mse: 7.2335\n",
            "Epoch 818/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 2.6505 - mae: 1.0792 - mse: 2.6505 - val_loss: 7.9431 - val_mae: 2.2124 - val_mse: 7.9431\n",
            "Epoch 819/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.9492 - mae: 1.1078 - mse: 2.9492 - val_loss: 7.0443 - val_mae: 2.0925 - val_mse: 7.0443\n",
            "Epoch 820/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 2.9267 - mae: 1.0538 - mse: 2.9267 - val_loss: 6.8855 - val_mae: 2.0783 - val_mse: 6.8855\n",
            "Epoch 821/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 2.7705 - mae: 1.0841 - mse: 2.7705 - val_loss: 7.6638 - val_mae: 2.1569 - val_mse: 7.6638\n",
            "Epoch 822/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.7248 - mae: 1.0502 - mse: 2.7248 - val_loss: 7.4585 - val_mae: 2.1529 - val_mse: 7.4585\n",
            "Epoch 823/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.7443 - mae: 1.0514 - mse: 2.7443 - val_loss: 7.0466 - val_mae: 2.1026 - val_mse: 7.0466\n",
            "Epoch 824/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 3.1163 - mae: 1.1393 - mse: 3.1163 - val_loss: 7.2424 - val_mae: 2.1329 - val_mse: 7.2424\n",
            "Epoch 825/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.7693 - mae: 1.0518 - mse: 2.7693 - val_loss: 7.3497 - val_mae: 2.1359 - val_mse: 7.3497\n",
            "Epoch 826/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.8543 - mae: 1.1009 - mse: 2.8543 - val_loss: 6.9280 - val_mae: 2.0857 - val_mse: 6.9280\n",
            "Epoch 827/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.9529 - mae: 1.0964 - mse: 2.9529 - val_loss: 6.7910 - val_mae: 2.0684 - val_mse: 6.7910\n",
            "Epoch 828/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.7066 - mae: 1.0522 - mse: 2.7066 - val_loss: 7.0725 - val_mae: 2.0721 - val_mse: 7.0725\n",
            "Epoch 829/1000\n",
            "251/251 [==============================] - 0s 162us/sample - loss: 2.9007 - mae: 1.1128 - mse: 2.9007 - val_loss: 7.0436 - val_mae: 2.0931 - val_mse: 7.0436\n",
            "Epoch 830/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.9072 - mae: 1.0914 - mse: 2.9072 - val_loss: 6.8709 - val_mae: 2.0908 - val_mse: 6.8709\n",
            "Epoch 831/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.7435 - mae: 1.0503 - mse: 2.7435 - val_loss: 6.8468 - val_mae: 2.0597 - val_mse: 6.8468\n",
            "Epoch 832/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.8619 - mae: 1.0898 - mse: 2.8619 - val_loss: 6.7885 - val_mae: 2.0627 - val_mse: 6.7885\n",
            "Epoch 833/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.7804 - mae: 1.0624 - mse: 2.7804 - val_loss: 7.0726 - val_mae: 2.0692 - val_mse: 7.0726\n",
            "Epoch 834/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.8249 - mae: 1.0793 - mse: 2.8249 - val_loss: 6.8870 - val_mae: 2.0943 - val_mse: 6.8870\n",
            "Epoch 835/1000\n",
            "251/251 [==============================] - 0s 123us/sample - loss: 2.6695 - mae: 1.0493 - mse: 2.6695 - val_loss: 7.3435 - val_mae: 2.0952 - val_mse: 7.3435\n",
            "Epoch 836/1000\n",
            "251/251 [==============================] - 0s 120us/sample - loss: 2.7074 - mae: 1.0493 - mse: 2.7074 - val_loss: 7.2814 - val_mae: 2.1255 - val_mse: 7.2814\n",
            "Epoch 837/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 2.7329 - mae: 1.0539 - mse: 2.7329 - val_loss: 7.1476 - val_mae: 2.0827 - val_mse: 7.1476\n",
            "Epoch 838/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.8780 - mae: 1.0935 - mse: 2.8780 - val_loss: 6.7540 - val_mae: 2.0439 - val_mse: 6.7540\n",
            "Epoch 839/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 2.7201 - mae: 1.0502 - mse: 2.7201 - val_loss: 7.2273 - val_mae: 2.1235 - val_mse: 7.2273\n",
            "Epoch 840/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.8875 - mae: 1.0786 - mse: 2.8875 - val_loss: 7.2368 - val_mae: 2.1016 - val_mse: 7.2368\n",
            "Epoch 841/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.7360 - mae: 1.0221 - mse: 2.7360 - val_loss: 7.1982 - val_mae: 2.1046 - val_mse: 7.1982\n",
            "Epoch 842/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.8251 - mae: 1.1110 - mse: 2.8251 - val_loss: 6.8910 - val_mae: 2.0664 - val_mse: 6.8910\n",
            "Epoch 843/1000\n",
            "251/251 [==============================] - 0s 162us/sample - loss: 2.8805 - mae: 1.1129 - mse: 2.8805 - val_loss: 7.2280 - val_mae: 2.1022 - val_mse: 7.2280\n",
            "Epoch 844/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.8018 - mae: 1.0872 - mse: 2.8018 - val_loss: 7.2047 - val_mae: 2.1313 - val_mse: 7.2047\n",
            "Epoch 845/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.9627 - mae: 1.0476 - mse: 2.9627 - val_loss: 6.7408 - val_mae: 2.0516 - val_mse: 6.7408\n",
            "Epoch 846/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.7046 - mae: 1.0982 - mse: 2.7046 - val_loss: 7.4908 - val_mae: 2.1368 - val_mse: 7.4908\n",
            "Epoch 847/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.8267 - mae: 1.0768 - mse: 2.8267 - val_loss: 6.6909 - val_mae: 2.0338 - val_mse: 6.6909\n",
            "Epoch 848/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 2.6461 - mae: 1.0412 - mse: 2.6461 - val_loss: 6.9227 - val_mae: 2.0957 - val_mse: 6.9227\n",
            "Epoch 849/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.9492 - mae: 1.0899 - mse: 2.9492 - val_loss: 7.1203 - val_mae: 2.0956 - val_mse: 7.1203\n",
            "Epoch 850/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.8758 - mae: 1.0707 - mse: 2.8758 - val_loss: 6.7797 - val_mae: 2.0706 - val_mse: 6.7797\n",
            "Epoch 851/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.5951 - mae: 1.0359 - mse: 2.5951 - val_loss: 6.8101 - val_mae: 2.0676 - val_mse: 6.8101\n",
            "Epoch 852/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.6172 - mae: 1.0408 - mse: 2.6172 - val_loss: 6.9544 - val_mae: 2.0699 - val_mse: 6.9544\n",
            "Epoch 853/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 2.8871 - mae: 1.0666 - mse: 2.8871 - val_loss: 7.8485 - val_mae: 2.1493 - val_mse: 7.8485\n",
            "Epoch 854/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.8204 - mae: 1.1053 - mse: 2.8204 - val_loss: 7.2174 - val_mae: 2.0941 - val_mse: 7.2174\n",
            "Epoch 855/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.6849 - mae: 1.0439 - mse: 2.6849 - val_loss: 7.1665 - val_mae: 2.0941 - val_mse: 7.1665\n",
            "Epoch 856/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.7393 - mae: 1.0766 - mse: 2.7393 - val_loss: 7.3231 - val_mae: 2.1663 - val_mse: 7.3231\n",
            "Epoch 857/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.8378 - mae: 1.1136 - mse: 2.8378 - val_loss: 7.0838 - val_mae: 2.0941 - val_mse: 7.0838\n",
            "Epoch 858/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.6111 - mae: 1.0357 - mse: 2.6111 - val_loss: 7.1922 - val_mae: 2.1227 - val_mse: 7.1922\n",
            "Epoch 859/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.8039 - mae: 1.0879 - mse: 2.8039 - val_loss: 7.4717 - val_mae: 2.1242 - val_mse: 7.4717\n",
            "Epoch 860/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.8622 - mae: 1.0695 - mse: 2.8622 - val_loss: 6.9653 - val_mae: 2.0802 - val_mse: 6.9653\n",
            "Epoch 861/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 2.7716 - mae: 1.0933 - mse: 2.7716 - val_loss: 7.1372 - val_mae: 2.1135 - val_mse: 7.1372\n",
            "Epoch 862/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 2.8215 - mae: 1.0766 - mse: 2.8215 - val_loss: 6.8008 - val_mae: 2.0635 - val_mse: 6.8008\n",
            "Epoch 863/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.8715 - mae: 1.0823 - mse: 2.8715 - val_loss: 6.6131 - val_mae: 2.0610 - val_mse: 6.6131\n",
            "Epoch 864/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 2.7898 - mae: 1.0605 - mse: 2.7898 - val_loss: 6.8618 - val_mae: 2.0825 - val_mse: 6.8618\n",
            "Epoch 865/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.6742 - mae: 1.0388 - mse: 2.6742 - val_loss: 6.7075 - val_mae: 2.0627 - val_mse: 6.7075\n",
            "Epoch 866/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.6286 - mae: 1.0162 - mse: 2.6286 - val_loss: 7.9456 - val_mae: 2.2174 - val_mse: 7.9456\n",
            "Epoch 867/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.9594 - mae: 1.1417 - mse: 2.9594 - val_loss: 7.0234 - val_mae: 2.1223 - val_mse: 7.0234\n",
            "Epoch 868/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 2.8049 - mae: 1.0567 - mse: 2.8049 - val_loss: 6.9207 - val_mae: 2.1095 - val_mse: 6.9207\n",
            "Epoch 869/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.8055 - mae: 1.0651 - mse: 2.8055 - val_loss: 7.2357 - val_mae: 2.1213 - val_mse: 7.2357\n",
            "Epoch 870/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 2.6274 - mae: 1.0104 - mse: 2.6274 - val_loss: 6.8443 - val_mae: 2.0630 - val_mse: 6.8443\n",
            "Epoch 871/1000\n",
            "251/251 [==============================] - 0s 167us/sample - loss: 2.7497 - mae: 1.0493 - mse: 2.7497 - val_loss: 6.8897 - val_mae: 2.0828 - val_mse: 6.8897\n",
            "Epoch 872/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.7920 - mae: 1.0428 - mse: 2.7920 - val_loss: 6.9949 - val_mae: 2.0832 - val_mse: 6.9949\n",
            "Epoch 873/1000\n",
            "251/251 [==============================] - 0s 163us/sample - loss: 2.9259 - mae: 1.0729 - mse: 2.9259 - val_loss: 7.4332 - val_mae: 2.1254 - val_mse: 7.4332\n",
            "Epoch 874/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.7399 - mae: 1.0627 - mse: 2.7399 - val_loss: 7.0630 - val_mae: 2.1259 - val_mse: 7.0630\n",
            "Epoch 875/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 2.7034 - mae: 1.0399 - mse: 2.7034 - val_loss: 7.0916 - val_mae: 2.0824 - val_mse: 7.0916\n",
            "Epoch 876/1000\n",
            "251/251 [==============================] - 0s 145us/sample - loss: 2.9586 - mae: 1.0811 - mse: 2.9586 - val_loss: 7.1898 - val_mae: 2.0936 - val_mse: 7.1898\n",
            "Epoch 877/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 2.7172 - mae: 1.0779 - mse: 2.7172 - val_loss: 6.9473 - val_mae: 2.0812 - val_mse: 6.9473\n",
            "Epoch 878/1000\n",
            "251/251 [==============================] - 0s 122us/sample - loss: 2.8388 - mae: 1.0559 - mse: 2.8388 - val_loss: 6.8177 - val_mae: 2.0777 - val_mse: 6.8177\n",
            "Epoch 879/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.8495 - mae: 1.0783 - mse: 2.8495 - val_loss: 7.0497 - val_mae: 2.0812 - val_mse: 7.0497\n",
            "Epoch 880/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.7410 - mae: 1.0736 - mse: 2.7410 - val_loss: 7.0522 - val_mae: 2.1203 - val_mse: 7.0522\n",
            "Epoch 881/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.7300 - mae: 1.0574 - mse: 2.7300 - val_loss: 6.7820 - val_mae: 2.0635 - val_mse: 6.7820\n",
            "Epoch 882/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 2.7795 - mae: 1.0390 - mse: 2.7795 - val_loss: 7.1022 - val_mae: 2.1048 - val_mse: 7.1022\n",
            "Epoch 883/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.8769 - mae: 1.1156 - mse: 2.8769 - val_loss: 7.2754 - val_mae: 2.1425 - val_mse: 7.2754\n",
            "Epoch 884/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.7073 - mae: 1.0506 - mse: 2.7073 - val_loss: 6.9306 - val_mae: 2.0765 - val_mse: 6.9306\n",
            "Epoch 885/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.6033 - mae: 1.0064 - mse: 2.6033 - val_loss: 7.0581 - val_mae: 2.1257 - val_mse: 7.0581\n",
            "Epoch 886/1000\n",
            "251/251 [==============================] - 0s 157us/sample - loss: 2.6760 - mae: 1.0189 - mse: 2.6760 - val_loss: 6.8024 - val_mae: 2.0687 - val_mse: 6.8024\n",
            "Epoch 887/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.6075 - mae: 1.0319 - mse: 2.6075 - val_loss: 6.8505 - val_mae: 2.0935 - val_mse: 6.8505\n",
            "Epoch 888/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 2.9091 - mae: 1.0952 - mse: 2.9091 - val_loss: 7.0646 - val_mae: 2.0985 - val_mse: 7.0646\n",
            "Epoch 889/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 2.7016 - mae: 1.0438 - mse: 2.7016 - val_loss: 6.9988 - val_mae: 2.1069 - val_mse: 6.9988\n",
            "Epoch 890/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 2.6843 - mae: 1.0365 - mse: 2.6843 - val_loss: 6.8735 - val_mae: 2.0785 - val_mse: 6.8735\n",
            "Epoch 891/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.7714 - mae: 1.0762 - mse: 2.7714 - val_loss: 7.2337 - val_mae: 2.1547 - val_mse: 7.2337\n",
            "Epoch 892/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.6033 - mae: 1.0915 - mse: 2.6033 - val_loss: 7.5945 - val_mae: 2.1492 - val_mse: 7.5945\n",
            "Epoch 893/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.5862 - mae: 1.0333 - mse: 2.5862 - val_loss: 6.7343 - val_mae: 2.0772 - val_mse: 6.7343\n",
            "Epoch 894/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.8583 - mae: 1.0893 - mse: 2.8583 - val_loss: 6.8285 - val_mae: 2.0965 - val_mse: 6.8285\n",
            "Epoch 895/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.7309 - mae: 1.0576 - mse: 2.7309 - val_loss: 6.8804 - val_mae: 2.0773 - val_mse: 6.8804\n",
            "Epoch 896/1000\n",
            "251/251 [==============================] - 0s 129us/sample - loss: 2.6957 - mae: 1.0406 - mse: 2.6957 - val_loss: 7.0112 - val_mae: 2.0678 - val_mse: 7.0112\n",
            "Epoch 897/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 2.5603 - mae: 1.0074 - mse: 2.5603 - val_loss: 6.8476 - val_mae: 2.0553 - val_mse: 6.8476\n",
            "Epoch 898/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.7212 - mae: 1.0871 - mse: 2.7212 - val_loss: 6.6862 - val_mae: 2.0603 - val_mse: 6.6862\n",
            "Epoch 899/1000\n",
            "251/251 [==============================] - 0s 166us/sample - loss: 2.9046 - mae: 1.1129 - mse: 2.9046 - val_loss: 7.0136 - val_mae: 2.0857 - val_mse: 7.0136\n",
            "Epoch 900/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.6541 - mae: 1.0737 - mse: 2.6541 - val_loss: 6.6477 - val_mae: 2.0377 - val_mse: 6.6477\n",
            "Epoch 901/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.6782 - mae: 1.0653 - mse: 2.6782 - val_loss: 6.9021 - val_mae: 2.0557 - val_mse: 6.9021\n",
            "Epoch 902/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.6612 - mae: 1.0467 - mse: 2.6612 - val_loss: 7.0064 - val_mae: 2.0758 - val_mse: 7.0064\n",
            "Epoch 903/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.6421 - mae: 1.0407 - mse: 2.6421 - val_loss: 6.8756 - val_mae: 2.0637 - val_mse: 6.8756\n",
            "Epoch 904/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.6070 - mae: 1.0203 - mse: 2.6070 - val_loss: 7.4281 - val_mae: 2.1163 - val_mse: 7.4281\n",
            "Epoch 905/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 2.7608 - mae: 1.0821 - mse: 2.7608 - val_loss: 7.3280 - val_mae: 2.1380 - val_mse: 7.3280\n",
            "Epoch 906/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.6072 - mae: 1.0479 - mse: 2.6072 - val_loss: 6.9797 - val_mae: 2.0688 - val_mse: 6.9797\n",
            "Epoch 907/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.7498 - mae: 1.0693 - mse: 2.7498 - val_loss: 7.1780 - val_mae: 2.1400 - val_mse: 7.1780\n",
            "Epoch 908/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.5227 - mae: 1.0165 - mse: 2.5227 - val_loss: 7.3464 - val_mae: 2.1412 - val_mse: 7.3464\n",
            "Epoch 909/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.6866 - mae: 1.0453 - mse: 2.6866 - val_loss: 7.2866 - val_mae: 2.1229 - val_mse: 7.2866\n",
            "Epoch 910/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.5881 - mae: 1.0410 - mse: 2.5881 - val_loss: 6.9270 - val_mae: 2.1060 - val_mse: 6.9270\n",
            "Epoch 911/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.9195 - mae: 1.1029 - mse: 2.9195 - val_loss: 6.8234 - val_mae: 2.0641 - val_mse: 6.8234\n",
            "Epoch 912/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.7041 - mae: 1.0615 - mse: 2.7041 - val_loss: 7.1970 - val_mae: 2.0937 - val_mse: 7.1970\n",
            "Epoch 913/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.6216 - mae: 1.0248 - mse: 2.6216 - val_loss: 7.0342 - val_mae: 2.0922 - val_mse: 7.0342\n",
            "Epoch 914/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.5829 - mae: 1.0202 - mse: 2.5829 - val_loss: 7.2605 - val_mae: 2.1071 - val_mse: 7.2605\n",
            "Epoch 915/1000\n",
            "251/251 [==============================] - 0s 130us/sample - loss: 2.6830 - mae: 1.0423 - mse: 2.6830 - val_loss: 6.6438 - val_mae: 2.0365 - val_mse: 6.6438\n",
            "Epoch 916/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.5794 - mae: 1.0389 - mse: 2.5794 - val_loss: 7.4439 - val_mae: 2.1251 - val_mse: 7.4439\n",
            "Epoch 917/1000\n",
            "251/251 [==============================] - 0s 151us/sample - loss: 2.9987 - mae: 1.1405 - mse: 2.9987 - val_loss: 7.0400 - val_mae: 2.0858 - val_mse: 7.0400\n",
            "Epoch 918/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.6026 - mae: 1.0022 - mse: 2.6026 - val_loss: 6.6616 - val_mae: 2.0601 - val_mse: 6.6616\n",
            "Epoch 919/1000\n",
            "251/251 [==============================] - 0s 123us/sample - loss: 2.6376 - mae: 1.0260 - mse: 2.6376 - val_loss: 6.9679 - val_mae: 2.1035 - val_mse: 6.9679\n",
            "Epoch 920/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.6382 - mae: 1.0404 - mse: 2.6382 - val_loss: 7.2104 - val_mae: 2.1313 - val_mse: 7.2104\n",
            "Epoch 921/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 2.7501 - mae: 1.0551 - mse: 2.7501 - val_loss: 6.9849 - val_mae: 2.0863 - val_mse: 6.9849\n",
            "Epoch 922/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 2.8560 - mae: 1.0946 - mse: 2.8560 - val_loss: 6.8692 - val_mae: 2.0685 - val_mse: 6.8692\n",
            "Epoch 923/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.7610 - mae: 1.0637 - mse: 2.7610 - val_loss: 6.8838 - val_mae: 2.1102 - val_mse: 6.8838\n",
            "Epoch 924/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.6090 - mae: 1.0484 - mse: 2.6090 - val_loss: 6.6663 - val_mae: 2.0576 - val_mse: 6.6663\n",
            "Epoch 925/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.5318 - mae: 1.0067 - mse: 2.5318 - val_loss: 7.9032 - val_mae: 2.2037 - val_mse: 7.9032\n",
            "Epoch 926/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.5854 - mae: 1.0489 - mse: 2.5854 - val_loss: 6.9148 - val_mae: 2.0778 - val_mse: 6.9148\n",
            "Epoch 927/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.5836 - mae: 1.0151 - mse: 2.5836 - val_loss: 8.0623 - val_mae: 2.2177 - val_mse: 8.0623\n",
            "Epoch 928/1000\n",
            "251/251 [==============================] - 0s 164us/sample - loss: 2.8010 - mae: 1.0773 - mse: 2.8010 - val_loss: 6.7995 - val_mae: 2.0641 - val_mse: 6.7995\n",
            "Epoch 929/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.6926 - mae: 1.0408 - mse: 2.6926 - val_loss: 6.9209 - val_mae: 2.1037 - val_mse: 6.9209\n",
            "Epoch 930/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.7064 - mae: 1.0487 - mse: 2.7064 - val_loss: 6.9750 - val_mae: 2.0901 - val_mse: 6.9750\n",
            "Epoch 931/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.7441 - mae: 1.0594 - mse: 2.7441 - val_loss: 6.6070 - val_mae: 2.0609 - val_mse: 6.6070\n",
            "Epoch 932/1000\n",
            "251/251 [==============================] - 0s 147us/sample - loss: 2.6191 - mae: 1.0082 - mse: 2.6191 - val_loss: 7.1407 - val_mae: 2.1279 - val_mse: 7.1407\n",
            "Epoch 933/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.6993 - mae: 1.0546 - mse: 2.6993 - val_loss: 6.8294 - val_mae: 2.0829 - val_mse: 6.8294\n",
            "Epoch 934/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.7220 - mae: 1.0657 - mse: 2.7220 - val_loss: 7.5825 - val_mae: 2.1436 - val_mse: 7.5825\n",
            "Epoch 935/1000\n",
            "251/251 [==============================] - 0s 124us/sample - loss: 2.6143 - mae: 1.0292 - mse: 2.6143 - val_loss: 7.5513 - val_mae: 2.1447 - val_mse: 7.5513\n",
            "Epoch 936/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.7659 - mae: 1.0451 - mse: 2.7659 - val_loss: 6.6001 - val_mae: 2.0402 - val_mse: 6.6001\n",
            "Epoch 937/1000\n",
            "251/251 [==============================] - 0s 143us/sample - loss: 2.5568 - mae: 1.0019 - mse: 2.5568 - val_loss: 6.7998 - val_mae: 2.0862 - val_mse: 6.7998\n",
            "Epoch 938/1000\n",
            "251/251 [==============================] - 0s 125us/sample - loss: 2.6020 - mae: 1.0278 - mse: 2.6020 - val_loss: 6.8306 - val_mae: 2.0574 - val_mse: 6.8306\n",
            "Epoch 939/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.8496 - mae: 1.0983 - mse: 2.8496 - val_loss: 6.7796 - val_mae: 2.0591 - val_mse: 6.7796\n",
            "Epoch 940/1000\n",
            "251/251 [==============================] - 0s 150us/sample - loss: 2.6717 - mae: 1.0216 - mse: 2.6717 - val_loss: 6.9158 - val_mae: 2.0828 - val_mse: 6.9158\n",
            "Epoch 941/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.5427 - mae: 1.0447 - mse: 2.5427 - val_loss: 6.6959 - val_mae: 2.0683 - val_mse: 6.6959\n",
            "Epoch 942/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.6814 - mae: 1.0529 - mse: 2.6814 - val_loss: 6.6480 - val_mae: 2.0451 - val_mse: 6.6480\n",
            "Epoch 943/1000\n",
            "251/251 [==============================] - 0s 162us/sample - loss: 2.6731 - mae: 1.0535 - mse: 2.6731 - val_loss: 6.8080 - val_mae: 2.1048 - val_mse: 6.8080\n",
            "Epoch 944/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.6021 - mae: 1.0303 - mse: 2.6021 - val_loss: 7.0795 - val_mae: 2.0979 - val_mse: 7.0795\n",
            "Epoch 945/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.5678 - mae: 1.0427 - mse: 2.5678 - val_loss: 7.7760 - val_mae: 2.1629 - val_mse: 7.7760\n",
            "Epoch 946/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.8281 - mae: 1.0852 - mse: 2.8281 - val_loss: 7.8555 - val_mae: 2.1892 - val_mse: 7.8555\n",
            "Epoch 947/1000\n",
            "251/251 [==============================] - 0s 138us/sample - loss: 2.7305 - mae: 1.0439 - mse: 2.7305 - val_loss: 7.1202 - val_mae: 2.0929 - val_mse: 7.1202\n",
            "Epoch 948/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.5686 - mae: 1.0053 - mse: 2.5686 - val_loss: 6.6415 - val_mae: 2.0561 - val_mse: 6.6415\n",
            "Epoch 949/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.9401 - mae: 1.1127 - mse: 2.9401 - val_loss: 6.9287 - val_mae: 2.0775 - val_mse: 6.9287\n",
            "Epoch 950/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 2.6206 - mae: 1.0370 - mse: 2.6206 - val_loss: 6.8032 - val_mae: 2.0630 - val_mse: 6.8032\n",
            "Epoch 951/1000\n",
            "251/251 [==============================] - 0s 153us/sample - loss: 2.7068 - mae: 1.0551 - mse: 2.7068 - val_loss: 6.9424 - val_mae: 2.0845 - val_mse: 6.9424\n",
            "Epoch 952/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.5660 - mae: 1.0340 - mse: 2.5660 - val_loss: 6.8399 - val_mae: 2.0953 - val_mse: 6.8399\n",
            "Epoch 953/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.6201 - mae: 1.0072 - mse: 2.6201 - val_loss: 6.9319 - val_mae: 2.1000 - val_mse: 6.9319\n",
            "Epoch 954/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.6111 - mae: 1.0349 - mse: 2.6111 - val_loss: 7.0663 - val_mae: 2.1075 - val_mse: 7.0663\n",
            "Epoch 955/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.7633 - mae: 1.0544 - mse: 2.7633 - val_loss: 7.3680 - val_mae: 2.1226 - val_mse: 7.3680\n",
            "Epoch 956/1000\n",
            "251/251 [==============================] - 0s 178us/sample - loss: 2.5057 - mae: 0.9791 - mse: 2.5057 - val_loss: 6.8806 - val_mae: 2.0780 - val_mse: 6.8806\n",
            "Epoch 957/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.6079 - mae: 1.0324 - mse: 2.6079 - val_loss: 6.9581 - val_mae: 2.1022 - val_mse: 6.9581\n",
            "Epoch 958/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.5211 - mae: 1.0314 - mse: 2.5211 - val_loss: 7.5945 - val_mae: 2.1670 - val_mse: 7.5945\n",
            "Epoch 959/1000\n",
            "251/251 [==============================] - 0s 152us/sample - loss: 2.4496 - mae: 1.0068 - mse: 2.4496 - val_loss: 6.6598 - val_mae: 2.0532 - val_mse: 6.6598\n",
            "Epoch 960/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.6891 - mae: 1.0455 - mse: 2.6891 - val_loss: 7.2380 - val_mae: 2.0942 - val_mse: 7.2380\n",
            "Epoch 961/1000\n",
            "251/251 [==============================] - 0s 155us/sample - loss: 2.5208 - mae: 1.0268 - mse: 2.5208 - val_loss: 6.6104 - val_mae: 2.0529 - val_mse: 6.6104\n",
            "Epoch 962/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.5801 - mae: 1.0085 - mse: 2.5801 - val_loss: 6.8658 - val_mae: 2.0887 - val_mse: 6.8658\n",
            "Epoch 963/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.6190 - mae: 1.0376 - mse: 2.6190 - val_loss: 6.6931 - val_mae: 2.0689 - val_mse: 6.6931\n",
            "Epoch 964/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 2.6017 - mae: 1.0558 - mse: 2.6017 - val_loss: 6.7731 - val_mae: 2.0621 - val_mse: 6.7731\n",
            "Epoch 965/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.7110 - mae: 1.0303 - mse: 2.7110 - val_loss: 6.6017 - val_mae: 2.0481 - val_mse: 6.6017\n",
            "Epoch 966/1000\n",
            "251/251 [==============================] - 0s 146us/sample - loss: 2.5601 - mae: 1.0414 - mse: 2.5601 - val_loss: 6.8142 - val_mae: 2.0570 - val_mse: 6.8142\n",
            "Epoch 967/1000\n",
            "251/251 [==============================] - 0s 154us/sample - loss: 2.6902 - mae: 1.0269 - mse: 2.6902 - val_loss: 6.8621 - val_mae: 2.0791 - val_mse: 6.8621\n",
            "Epoch 968/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.5506 - mae: 1.0134 - mse: 2.5506 - val_loss: 6.9924 - val_mae: 2.0955 - val_mse: 6.9924\n",
            "Epoch 969/1000\n",
            "251/251 [==============================] - 0s 167us/sample - loss: 2.7677 - mae: 1.0537 - mse: 2.7677 - val_loss: 7.7174 - val_mae: 2.1785 - val_mse: 7.7174\n",
            "Epoch 970/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.4953 - mae: 1.0037 - mse: 2.4953 - val_loss: 6.5681 - val_mae: 2.0568 - val_mse: 6.5681\n",
            "Epoch 971/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.7583 - mae: 1.0670 - mse: 2.7583 - val_loss: 6.7764 - val_mae: 2.0643 - val_mse: 6.7764\n",
            "Epoch 972/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 2.5464 - mae: 0.9771 - mse: 2.5464 - val_loss: 6.8489 - val_mae: 2.0950 - val_mse: 6.8489\n",
            "Epoch 973/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.6049 - mae: 1.0849 - mse: 2.6049 - val_loss: 6.9184 - val_mae: 2.0891 - val_mse: 6.9184\n",
            "Epoch 974/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.5304 - mae: 1.0033 - mse: 2.5304 - val_loss: 6.5468 - val_mae: 2.0489 - val_mse: 6.5468\n",
            "Epoch 975/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.7516 - mae: 1.0621 - mse: 2.7516 - val_loss: 7.0068 - val_mae: 2.1141 - val_mse: 7.0068\n",
            "Epoch 976/1000\n",
            "251/251 [==============================] - 0s 131us/sample - loss: 2.5382 - mae: 1.0241 - mse: 2.5382 - val_loss: 6.9758 - val_mae: 2.1055 - val_mse: 6.9758\n",
            "Epoch 977/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.6952 - mae: 1.0268 - mse: 2.6952 - val_loss: 6.9557 - val_mae: 2.1021 - val_mse: 6.9557\n",
            "Epoch 978/1000\n",
            "251/251 [==============================] - 0s 132us/sample - loss: 2.7854 - mae: 1.0885 - mse: 2.7854 - val_loss: 7.0199 - val_mae: 2.1085 - val_mse: 7.0199\n",
            "Epoch 979/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 2.4787 - mae: 0.9828 - mse: 2.4787 - val_loss: 7.0388 - val_mae: 2.0964 - val_mse: 7.0388\n",
            "Epoch 980/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.4426 - mae: 0.9835 - mse: 2.4426 - val_loss: 6.7604 - val_mae: 2.0693 - val_mse: 6.7604\n",
            "Epoch 981/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.8612 - mae: 1.0971 - mse: 2.8612 - val_loss: 6.9041 - val_mae: 2.0786 - val_mse: 6.9041\n",
            "Epoch 982/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.5912 - mae: 1.0082 - mse: 2.5912 - val_loss: 6.8514 - val_mae: 2.0806 - val_mse: 6.8514\n",
            "Epoch 983/1000\n",
            "251/251 [==============================] - 0s 220us/sample - loss: 2.5087 - mae: 1.0155 - mse: 2.5087 - val_loss: 7.7931 - val_mae: 2.1855 - val_mse: 7.7931\n",
            "Epoch 984/1000\n",
            "251/251 [==============================] - 0s 148us/sample - loss: 2.7699 - mae: 1.0544 - mse: 2.7699 - val_loss: 6.7548 - val_mae: 2.0743 - val_mse: 6.7548\n",
            "Epoch 985/1000\n",
            "251/251 [==============================] - 0s 127us/sample - loss: 2.5326 - mae: 1.0205 - mse: 2.5326 - val_loss: 7.1376 - val_mae: 2.1213 - val_mse: 7.1376\n",
            "Epoch 986/1000\n",
            "251/251 [==============================] - 0s 126us/sample - loss: 2.5093 - mae: 0.9892 - mse: 2.5093 - val_loss: 7.4345 - val_mae: 2.1528 - val_mse: 7.4345\n",
            "Epoch 987/1000\n",
            "251/251 [==============================] - 0s 140us/sample - loss: 2.5328 - mae: 0.9957 - mse: 2.5328 - val_loss: 6.6907 - val_mae: 2.0653 - val_mse: 6.6907\n",
            "Epoch 988/1000\n",
            "251/251 [==============================] - 0s 124us/sample - loss: 2.7535 - mae: 1.0457 - mse: 2.7535 - val_loss: 7.3616 - val_mae: 2.1270 - val_mse: 7.3616\n",
            "Epoch 989/1000\n",
            "251/251 [==============================] - 0s 133us/sample - loss: 2.6445 - mae: 1.0235 - mse: 2.6445 - val_loss: 6.9021 - val_mae: 2.0973 - val_mse: 6.9021\n",
            "Epoch 990/1000\n",
            "251/251 [==============================] - 0s 136us/sample - loss: 2.5954 - mae: 1.0075 - mse: 2.5954 - val_loss: 7.6680 - val_mae: 2.1451 - val_mse: 7.6680\n",
            "Epoch 991/1000\n",
            "251/251 [==============================] - 0s 144us/sample - loss: 2.5221 - mae: 0.9757 - mse: 2.5221 - val_loss: 6.8930 - val_mae: 2.1073 - val_mse: 6.8930\n",
            "Epoch 992/1000\n",
            "251/251 [==============================] - 0s 141us/sample - loss: 2.6720 - mae: 1.0377 - mse: 2.6720 - val_loss: 6.8798 - val_mae: 2.0723 - val_mse: 6.8798\n",
            "Epoch 993/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.6277 - mae: 1.0223 - mse: 2.6277 - val_loss: 7.3035 - val_mae: 2.1400 - val_mse: 7.3035\n",
            "Epoch 994/1000\n",
            "251/251 [==============================] - 0s 149us/sample - loss: 2.5099 - mae: 1.0084 - mse: 2.5099 - val_loss: 7.7076 - val_mae: 2.1596 - val_mse: 7.7076\n",
            "Epoch 995/1000\n",
            "251/251 [==============================] - 0s 139us/sample - loss: 2.8345 - mae: 1.0556 - mse: 2.8345 - val_loss: 7.1900 - val_mae: 2.1118 - val_mse: 7.1900\n",
            "Epoch 996/1000\n",
            "251/251 [==============================] - 0s 142us/sample - loss: 2.6125 - mae: 1.0522 - mse: 2.6125 - val_loss: 6.7600 - val_mae: 2.0585 - val_mse: 6.7600\n",
            "Epoch 997/1000\n",
            "251/251 [==============================] - 0s 128us/sample - loss: 2.6117 - mae: 0.9879 - mse: 2.6117 - val_loss: 6.7198 - val_mae: 2.0639 - val_mse: 6.7198\n",
            "Epoch 998/1000\n",
            "251/251 [==============================] - 0s 135us/sample - loss: 2.5535 - mae: 1.0281 - mse: 2.5535 - val_loss: 6.8592 - val_mae: 2.1029 - val_mse: 6.8592\n",
            "Epoch 999/1000\n",
            "251/251 [==============================] - 0s 134us/sample - loss: 2.5650 - mae: 1.0356 - mse: 2.5650 - val_loss: 6.8940 - val_mae: 2.1133 - val_mse: 6.8940\n",
            "Epoch 1000/1000\n",
            "251/251 [==============================] - 0s 137us/sample - loss: 2.6378 - mae: 1.0256 - mse: 2.6378 - val_loss: 6.9182 - val_mae: 2.0795 - val_mse: 6.9182\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5obUY1dBEnFY",
        "colab_type": "text"
      },
      "source": [
        "## Evaluación el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3FgAK4CCSnX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "outputId": "f8d51770-0111-4630-f037-88ef7892ea9c"
      },
      "source": [
        "hist = pd.DataFrame(history.history)\n",
        "hist['epoch'] = history.epoch\n",
        "hist.tail()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>loss</th>\n",
              "      <th>mae</th>\n",
              "      <th>mse</th>\n",
              "      <th>val_loss</th>\n",
              "      <th>val_mae</th>\n",
              "      <th>val_mse</th>\n",
              "      <th>epoch</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>995</th>\n",
              "      <td>2.612458</td>\n",
              "      <td>1.052235</td>\n",
              "      <td>2.612458</td>\n",
              "      <td>6.759988</td>\n",
              "      <td>2.058468</td>\n",
              "      <td>6.759988</td>\n",
              "      <td>995</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>996</th>\n",
              "      <td>2.611689</td>\n",
              "      <td>0.987882</td>\n",
              "      <td>2.611689</td>\n",
              "      <td>6.719792</td>\n",
              "      <td>2.063948</td>\n",
              "      <td>6.719791</td>\n",
              "      <td>996</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>997</th>\n",
              "      <td>2.553481</td>\n",
              "      <td>1.028138</td>\n",
              "      <td>2.553481</td>\n",
              "      <td>6.859209</td>\n",
              "      <td>2.102868</td>\n",
              "      <td>6.859209</td>\n",
              "      <td>997</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>998</th>\n",
              "      <td>2.564960</td>\n",
              "      <td>1.035566</td>\n",
              "      <td>2.564960</td>\n",
              "      <td>6.893959</td>\n",
              "      <td>2.113281</td>\n",
              "      <td>6.893960</td>\n",
              "      <td>998</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>999</th>\n",
              "      <td>2.637798</td>\n",
              "      <td>1.025617</td>\n",
              "      <td>2.637797</td>\n",
              "      <td>6.918227</td>\n",
              "      <td>2.079524</td>\n",
              "      <td>6.918226</td>\n",
              "      <td>999</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "         loss       mae       mse  val_loss   val_mae   val_mse  epoch\n",
              "995  2.612458  1.052235  2.612458  6.759988  2.058468  6.759988    995\n",
              "996  2.611689  0.987882  2.611689  6.719792  2.063948  6.719791    996\n",
              "997  2.553481  1.028138  2.553481  6.859209  2.102868  6.859209    997\n",
              "998  2.564960  1.035566  2.564960  6.893959  2.113281  6.893960    998\n",
              "999  2.637798  1.025617  2.637797  6.918227  2.079524  6.918226    999"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PHxBjzT8Ep82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_history(history):     \n",
        "  hist = pd.DataFrame(history.history)\n",
        "  hist['epoch'] = history.epoch\n",
        "\n",
        "  plt.figure()\n",
        "  plt.xlabel('Epoch')\n",
        "  plt.ylabel('Mean Square Error')\n",
        "  plt.plot(hist['epoch'], hist['mse'],\n",
        "           label='Train Error')\n",
        "  plt.plot(hist['epoch'], hist['val_mse'],\n",
        "           label = 'Val Error')\n",
        "  plt.ylim([0,20])\n",
        "  plt.legend()\n",
        "  plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnwnYCxcEqCw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "581bc742-7621-47aa-a7b3-f418a7681479"
      },
      "source": [
        "plot_history(history)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nlFKuNEAopZRy9f+YvOZHFN4PuwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CE_4ZyUyF9t0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "d91589fa-45a6-4cd6-d0ec-52fd96d3fcd7"
      },
      "source": [
        "model = build_model()\n",
        "model.compile(loss='mse',\n",
        "                optimizer=optimizer,\n",
        "                metrics=['mae', 'mse'])\n",
        "\n",
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0,\n",
        "                    callbacks=[early_stop] )\n",
        "\n",
        "\n",
        "plot_history(history)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAEKCAYAAAAB0GKPAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nl/8PAF10UYFViK8AAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i2CvAw6kHhFn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = build_model()\n",
        "\n",
        "model.compile(loss='mse',optimizer=optimizer,metrics=['mse','mae'])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o3YqSK1kHhIc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "early_stop = keras.callbacks.EarlyStopping(monitor='val_loss', patience=10)\n",
        "\n",
        "history = model.fit(normed_train_data, train_labels, epochs=EPOCHS,\n",
        "                    validation_split = 0.2, verbose=0,\n",
        "                    callbacks=[early_stop] )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MLDBpB3cHhLQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "78b1e96e-2d04-44cb-e537-64d19049520d"
      },
      "source": [
        "plt.figure()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Abs Error [MPG]')\n",
        "plt.plot(hist['epoch'], hist['mae'],\n",
        "         label='Train Error')   \n",
        "plt.plot(hist['epoch'], hist['val_mae'],\n",
        "         label = 'Val Error')\n",
        "plt.ylim([0,5])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEKCAYAAAAYd05sAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nWwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7cGbwlQxEqAO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "outputId": "35bfc7b3-59f6-48b4-a632-a3564af89754"
      },
      "source": [
        "plt.figure()\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Mean Abs Error [MPG]')\n",
        "plt.plot(hist['epoch'], hist['mae'],\n",
        "         label='Train Error')   \n",
        "plt.plot(hist['epoch'], hist['val_mae'],\n",
        "         label = 'Val Error')\n",
        "plt.ylim([0,5])\n",
        "plt.xlim([0,60])\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEKCAYAAAAVaT4rAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO3deXhU1fnA8e+bfScLYZEEwiZrIITI\nKsqmBUVRERTRurVUf3WvdWtt1drW1i5SbV0Ldau0LqjFlU1ZFDBAEAg7BAhbSICEJGQ/vz/OBAKE\nZBJyM0nm/TzPPDP33pl73xuG954559xzxBiDUkop7+Hj6QCUUko1Lk38SinlZTTxK6WUl9HEr5RS\nXkYTv1JKeRlN/Eop5WX8nNy5iGQAx4ByoMwYk+Lk8ZRSStXO0cTvMsoYk90Ix1FKKeUGrepRSikv\nI07euSsiO4EjgAFeNsa8Us17pgPTAUJDQwf27NnTsXg8YX9uEUEFe4nyKYR2iZ4ORynVwqxatSrb\nGBNbl884nfg7GGP2ikgbYB5wtzFm8dnen5KSYlJTUx2LxxNmLdtJ+qf/4Fn/V+AnS6B9P0+HpJRq\nQURkVV3bTx2t6jHG7HU9ZwFzgEFOHq8pio8KYX55Mkb8YP37ng5HKaWcS/wiEioi4ZWvgUuB9U4d\nr6mKjw7hCBFktRlmE39FhadDUkp5OSdL/G2BpSKyFlgJfGKM+dzB4zVJcVHBAKyNuhRy98Ce5R6O\nSCnl7RzrzmmM2QH0d2r/zUVooB8xoQEs872AS/1DYN270GmYp8NSqsGVlpaSmZlJUVGRp0NpkYKC\ngoiLi8Pf3/+c99UY/fi9Xlx0CNtzBXpcBhvmwLg/gF+Ap8NSqkFlZmYSHh5OQkICIuLpcFoUYww5\nOTlkZmbSuXPnc96f9uNvBPFRwew5UgiJk+H4EdixyNMhKdXgioqKiImJ0aTvABEhJiamwX5NaeJv\nBPHRIew7epzyLqMgOMpW9yjVAmnSd05D/m018TeCTtEhlJYbdueWQe+rYNMnUJzv6bCUUl5KE38j\nGN6tNQDz0w/a6p7SQtj8mYejUqplycnJISkpiaSkJNq1a0eHDh1OLJeUlLi1j1tvvZXNmze7fczX\nXnuN2NjYE8dJSkqq0+c9RRt3G0F8dAh9O0Tw6fr9/PjCoRARZ6t7+k32dGhKtRgxMTGkpaUB8MQT\nTxAWFsaDDz54ynuMMRhj8PGpvsw7a9asOh932rRpPPfcc2fdXlZWhp/fyVRbWwxVlZeX4+vrW+eY\naqMl/kYyvm971uw+yr68YkicBNsXQEGOp8NSqsXbtm0bvXv3Ztq0afTp04f9+/czffp0UlJS6NOn\nD0899dSJ91544YWkpaVRVlZGZGQkjzzyCP3792fo0KFkZWW5fcz58+czcuRIJkyYQGJiYrUxvPXW\nWyQmJtK3b18ee+wxgBPHve++++jXrx8rV65s8L8HaIm/0Yzv245nv9jM5+sPcFviZFg2A9I/hAtu\n93RoSjW4J/+3gfR9eQ26z97nRfDrK/rU67ObNm3ijTfeICXFDmnzzDPPEB0dTVlZGaNGjeLaa6+l\nd+/ep3wmNzeXiy++mGeeeYYHHniAmTNn8sgjj5yx77fffpuvvvrqxHJlsk5NTSU9PZ2OHTuybdu2\nU2LIzMzkl7/8JampqbRq1YqxY8cyd+5cxo0bR25uLhdddFGNvyLOlZb4G0mX2DB6tgvns/X7oW1f\niO2pvXuUaiRdu3Y9kfQB3nnnHZKTk0lOTmbjxo2kp6ef8Zng4GDGjx8PwMCBA8nIyKh239OmTSMt\nLe3EIyDA3qMzdOhQOnbsWG0MK1asYPTo0bRu3Rp/f39uuOEGFi+241cGBARw9dVXN8h5n42W+BvR\nZYnt+ev8LWQdK6ZN4rWw8Gk4uhsiO9b+YaWakfqWzJ0SGhp64vXWrVuZMWMGK1euJDIykhtvvLHa\n/vGVCRzA19eXsrKyeh+zuuWzCQ4OdrxbrJb4G9H4vu0wBr7YcAD6XmtX6oidSjWqvLw8wsPDiYiI\nYP/+/XzxxReNHsPgwYNZtGgROTk5lJWVMXv2bC6++OJGO76W+BtR97bhdGsTxqfrDnDT0CEQPwRS\nZ8LQu8D33MffUErVLjk5md69e9OzZ086derE8OHDz2l/p9fxv/zyy7V+Ji4ujt/85jeMHDkSYwxX\nXHEFl19+eZ1/VdSXoxOx1FVLnIjldH/5cjMvLNrGyl+MpfXehfDO9TDxHzBgmqdDU+qcbNy4kV69\nenk6jBatur9xk5uIRZ1pfGJ7Kgx8ueEgnD/OTse45M9QUe7p0JRSXkITfyPr2S6chJgQ27tHBC56\nCA5vh/UfeDo0pZSX0MTfyESE8Ynt+WZ7DkcKSqDnBGjTGxY/q7NzKaUahSZ+D7isb3vKKwzzNh4E\nHx+46EHI3gwbP/J0aEopL6CJ3wP6doggLiqYz9bttyt6XwUx3WHxn7TUr5RynCZ+DxARxvdtx9Jt\n2eQeLwUfX7jo53BwPWzRUTuVUs7SxO8h4xPbU1puWLDxoF3RdxJEdYav/wBNqIutUs3FqFGjzrgZ\n67nnnuPOO++s8XNhYWHVrvf19T1luOVnnnmmwWL1NE38HpIUF0n7VkF8lLbPrvD1gxE/g/1rYes8\nzwanVDM0depUZs+efcq62bNnM3Xq1HrtLzg4+JQxeKoboK28/NRu2O7egNVYN2qdjSZ+D/HxEa67\nIJ6vtxxiW9Yxu7L/9dCqIyz+o5b6laqja6+9lk8++eTEpCsZGRns27ePESNGkJ+fz5gxY0hOTiYx\nMZGPPqp/R4qEhAQefvhhkpOTeffddxk5ciT33XcfKSkpzJgxg4yMDEaPHk2/fv0YM2YMu3fvBuCW\nW27hjjvuYPDgwTz00EMNcs71pUM2eNCNQzrxj6+288+lGfz+mkQ7bMOI+2Hu/XZ6xl4TPB2iUvXz\n2SNwYF3D7rNdIow/e3VLdHQ0gwYN4rPPPmPixInMnj2bKVOmICIEBQUxZ84cIiIiyM7OZsiQIVx5\n5ZU1DoZ2/PhxkpKSTiw/+uijXHfddYCd9GX16tUAvPTSS5SUlFA56sAVV1zBzTffzM0338zMmTO5\n5557+PDDDwHIzMzkm2++cWRylbrQEr8HtQ4LZFJyBz5YnUlOfrFdmXQjtE20yb/wsGcDVKqZqVrd\nU7WaxxjDY489Rr9+/Rg7dix79+7l4MGDNe7r9KqeyqQPnPL69OVvv/2WG264AYCbbrqJpUuXntg2\nefJkjyd90BK/x91+YWfeWbmHt5bv5t6x3cEvAK5+EV4ZBZ/8DCbXfSo4pTyuhpK5kyZOnMj999/P\n6tWrKSwsZODAgYAdSO3QoUOsWrUKf39/EhISqh2K2V31HXLZ3fc5TUv8HtatTTijesTy5vIMikpd\nDUXtEmHkw7DhA9gwx7MBKtWMhIWFMWrUKG677bZTGnVzc3Np06YN/v7+LFq0iF27djkWw7Bhw078\n6nj77bcZMWKEY8eqL038TcCPR3QhO7+ED9fsPbly+P1wXjLMfQDy3Z/rUylvN3XqVNauXXtK4p82\nbRqpqakkJibyxhtv0LNnz1r3U1nHX/morldPdZ5//nlmzZpFv379ePPNN5kxY0a9z8UpOixzE2CM\n4fK/LaWkvIJ59190ssHp0GZ4aQR0GwvXv20HdVOqidJhmZ2nwzK3ICLCj0Z0ZltWPl9tOXRyQ2wP\nGPM4bP4Evv+P5wJUSrUomvibiAn9zqNtRCCvLdlx6oYh/wcdh8KnD0Hu3uo/rJRSdaCJv4kI8PPh\nlmGdWbYth/R9eSc3+PjCVf+AilL45AHPBaiUG5pS1XFL05B/W038TcgNgzoSEuDLa0tPK/VHd7GD\nuG35HPaleSY4pWoRFBRETk6OJn8HGGPIyckhKCioQfan/fibkFYh/kxJieftFbt46Ac9adeqyj/y\nBbfDkr/Aty/ApNc8F6RSZxEXF0dmZiaHDh2q/c2qzoKCgoiLi2uQfWnib2Juv7Azb6/YxbNfbObP\nU/qf3BDUCgbeDMtfhDG/hsh4zwWpVDX8/f3p3Lmzp8NQbtCqniYmPjqE2y/swvurM1m9+8ipGwff\nYZ9XvNT4gSmlWgzHE7+I+IrIGhGZ6/SxWoq7RnejTXggT3y8gYqKKvWlkfF23P5V/4LjRz0Wn1Kq\neWuMEv+9wMZGOE6LERbox2OX9eL7zFzeXbXn1I3D7oKSfJv8lVKqHhxN/CISB1wOaGtkHU1MOo+U\nTlH88fPNdnrGSu37Q+eLbXVPWYnnAlRKNVtOl/ifAx4CzjqDuIhMF5FUEUnV3gAniQhPXNmHw4Ul\nPDd/y6kbh90Dx/bD+vc8E5xSqllzLPGLyAQgyxizqqb3GWNeMcakGGNSYmNjnQqnWerboRVTB3Xk\njW93seXgsZMbuo2BNr3hm+d1pi6lVJ05WeIfDlwpIhnAbGC0iLzl4PFapAcv7UFYoB9PfLzh5I0x\nIjDsbshKh+0LPBugUqrZcSzxG2MeNcbEGWMSgOuBhcaYG506XksVHRrAzy49n2+25/D5+gMnN/S9\nFsLbw7K/eS44pVSzpP34m4EbBnWkZ7twnvxfOocLXA26fgG2X//Or3UYB6VUnTRK4jfGfGWM0ZnD\n68nP14c/Te7P4YISHvhv2sm+/QNvgaBI+PTnUFHu0RiVUs2Hlvibib4dWvH4Fb35avMhXvx6u10Z\nHAmX/QkyV9qGXqWUcoMm/mbkxsEdmdCvPX/+cjMrduTYlYnXQq8rYdFv4WC6ZwNUSjULmvibERHh\nmUn9SIgJ5e531pCdX2x7+Ez4KwRGwJyfQHlp7TtSSnk1TfzNTFigH3+flkzu8VLum51GeYWB0NY2\n+R/4Hpb82dMhKqWaOE38zVCv9hE8eWUflm7L5oWF2+zK3ldC4hRY/Kz28lFK1UgTfzN13QXxXD2g\nA88t2HKyvv+yP0JoLMy5A8qKPRugUqrJqjHxi0i0G4/IxgpWnSQiPH1VX+Kigvn1xxtslU9wFFz5\nPBzaCIt+5+kQlVJNVG0zcO1zPaSG9/gCHRssIuW20EA/Hh7Xk7v+vYb3V2Uy5YJ46H4JJP8Qlj0H\nIdF2QDep6Z9PKeVtakv8G40xA2p6g4isacB4VB1dntiemR138uyXm7m8X3tCA/1s3/7ifJj3K8jb\nDz/4HfhorZ5SyqotGwx1Yx/uvEc5RET45YTeHDpWzMuLd9iVfoEw6Z8w5Kew4kV471YoLfJsoEqp\nJqPGxG+MOSVbiEgHEenoevhV9x7V+JI7RjGhX3teWbyd/bnH7UofHxj3O7j0t5D+Ibx1DRw/UvOO\nlFJeobbG3UdF5FdVVn0LzAW+BH7uZGCqbh4e15MKA3/64vRJW+6ypf89K2HmeMjd65kAlVJNRm1V\nPZOBqncE5Rhj+gF9sFMqqiYiPjqEW4cn8P7qTNbvzT11Y+K1cOP7kJsJH97pmQCVUk1GrS1+xpiC\nKoszXOvKgWCnglL189NR3YgODeDpT9JPTtpSqcvFMPIRO4xzxlLPBKiUahJqS/xhIuJfuWCM+ReA\niAQCEQ7GpeohIsif+8d2Z/mOw8xLP3jmGy64HcLawcLf6pSNSnmx2hL/e8DLIhJSuUJEQoGXXNtU\nEzN1UEe6xoby+882cbzktDH6/YPhogdh9zewY5FnAlRKeVxtif9xIAvYLSKrRGQ1kAEcdG1TTYyf\nrw9PTexLRk4Bj37w/ZlVPsk/hIg4WPi0lvqV8lK1decsN8Y8AsQDtwA3Ax2NMY8YY8oaIT5VD8O7\nteb+sefzYdo+Xv8m49SNfoFw8c9h7yrY8oVH4lNKeVZt3Tm7i8hHwHfAY8BhY8zxRolMnZO7RnVj\nbK82PP3JRr7LOHzqxqRpEJVgJ2/RUr9SXqe2qp6Z2H77k4DVgM7v10z4+Ah/npJEh6hg/u/t1WTl\nVbnPztcfLn7Ejt+/8X+eC1Ip5RG1Jf5wY8yrxpjNxphngYRGiEk1kFbB/rx040COFZXy03+vprS8\n4uTGflMgprsdxVMnalfKq9SW+INEZICIJItIMhB82rJq4nq1j+APk/rxXcYRfvfpxpMbfHxh1KN2\nCOcNczwXoFKq0dU2OucB4C9nWTbAaCeCUg1rYlIH1uw+yqxlGSTFRzIxqYPd0PtqaPNn+Or30Hui\nrQJSSrV4NSZ+Y8zIRopDOewXl/diw75cHnl/HT3ahdOzXYQdyG3M4/DO9fDfm2HyLNvrRynVoskZ\n/byrbhS5pqYPG2M+aMhgUlJSTGpqakPuUlWRlVfE5c8vJSTAl4/vupBWwa4S/oqX4bOHoOsYuO4t\nCAipeUdKqSZDRFYZY1Lq8hl37tz9JTDB9biiymNCfYJUntMmIogXpyWz98hxHvhPGhUVrov+4J/Y\nKRu3L4R/T4HiY54NVCnlqNoS/zXAFqAfsBP4rTHmVtfjNsejUw0uJSGaX17eiwWbsnhh0baTG5J/\nCNe8Cru+gTevhuNHPRekUspRtd25+6Ex5nrgYmA78GcRWSoiFzdKdMoRNw9L4Kqk8/jr/C0s2px1\nckO/yTDlddiXBq9fAQU5ngtSKeUYdydiLQJygTwgDAhyLCLlOBHh99f0o0fbcO6bncaew4UnN/a6\nAqa+A9lb7KxdOmWjUi1ObUM2jBaRV4BVwChghjEmyRijg7w0c8EBvrx040AqjOEnb66isKTK0Evd\nL4HJ/4L9afDpgx6LUSnljNpK/POBQcBSIBD4oYj8rfLheHTKUQmtQ5lxfRKbDuTxkzdXUVxW5Q7e\nHuNhxIOw5k1Y/YbnglRKNbjaEv9twF+xg7SlYkv+VR+qmRvdsy3PXNOPJVuzuW92GmVVh3UY9Rh0\nGQWfPAj71nguSKVUg6qxH39j0378nvPakh08/clGJg+M4w+T+uHjI3ZDQQ68fJG92Wv61xAS7dlA\nlVKnaPB+/CLyhBsHrfU9qun70Ygu3DOmO++uyuTpTzaenMAlNAamvAHHDsAH06GiouYdKaWavNrG\n6vmRiOTVsF2A64EnztggEgQsxrYN+AHvGWN+Xc84VSO4f2x38o6XMnPZTloF+3Pv2O52Q9xAGPcM\nfPIALP6jnbRdKdVs1Zb4XwXC3XhPdYqB0caYfNeE7UtF5DNjzPK6Bqkah4jwqwm9OVZUxl/nb6FV\nsB+3DO9sN6bcBpnfwVfPQNs+ttunUqpZqm2Qtifru2Nj6wryXYv+rkfTaVBQ1fLxEf4wKZFjRaU8\nOTed8yKDubRPOxCBy/8C2Vvhvdtg2nvQRe/jU6o5cvcGrnoREV8RScNO2D7PGLOimvdMF5FUEUk9\ndOiQk+EoN/n5+jDj+gH0i4vk3tlprMvMtRsCQmDauxDTDd6ZCpnasUup5sjRxO+arD0JiAMGiUjf\nat7zijEmxRiTEhsb62Q4qg6CA3x59YcDiQ4N4PbXv2PfUddUyyHRcNMcCIuFtydB1saad6SUanJq\nTfyuUvv953IQY8xRYBEw7lz2oxpXm/AgZt5yAcdLyrntX9+RX+y6uze8Hdz0IfgG2gHdjmR4NE6l\nVN3UmviNMeXA1LruWERiRSTS9ToYuATYVOcIlUf1aBfO36clszUrn7v/vfrkDV7RnW3Jv/Q4vDHR\ndvdUSjUL7lb1LBORF0RkROV8u27MudseWCQi32Pv/J1njJl7TtEqj7jo/FiemtiHRZsP8dTc9JN9\n/Nv2hhvfh/xD8MZVcOygZwNVSrmltu6clZJcz09VWVfjnLvGmO+BAfWMSzUx0wZ3IiO7gFeX7CQm\nNLBKH/8UuGE2/Pt6mDUebv4YWsV5NlilVI3cSvzGmFFOB6KavkfG9yKnoIS/zt9CaXkFP7v0fEQE\nOl9kq33evhZmjocffggxXT0drlLqLNyq6hGRViLyl8pulyLyZxFp5XRwqmnx9RH+dG1/rr8gnhcW\nbeOZzzadrPbpOBhu/h+U5MOsyyBLm3OUaqrcreOfCRwDprgeecAsp4JSTZePj/C7qxO5aUgnXl68\n49Q6//OS4NZPAQP/uszO5KWUanLcTfxdjTG/NsbscD2eBLo4GZhqunx8hKcm9uG24Z2ZtSyDxz9a\nf3Li9ja94NbPwD8EXr/SzuGrlGpS3E38x0XkwsoFERkOHHcmJNUciAiPT+jFHRd35a3lu7nvP2kc\nzHNN0xjT1Sb/sFib/HUiF6WaFHd79dwBvFGlXv8IcLMzIanmQkR4eFwPQgJ8mbFgK59vOMDUC+K5\nY2RX2kfGw4/mw7u3wsd3w8ENcOlvwdfdr5xSyim1TsQiIj7AtcaY/4pIBIAxpqahmutNJ2Jpvnbn\nFPKPr7bx3qpMfESYnBLHnSO7EhcRAPN+Bcv/Dl1GwrWzdDIXpRpQfSZicWsGLhFJreuO60MTf/OX\neaSQF7/azn9T92AM/Oaqvkwd1BFWvwlz74fIeJg6G2J7eDpUpVqEBp+Bq4r5IvKgiMSLSHTlox4x\nqhYuLiqE316dyNc/H8XQrjE8/uF6UjMOQ/JNcMtcKD4GL18Mc+6AnUt0Ri+lPMDdEv/OalYbY0yD\n9uzREn/Lknu8lIkvLKWwpJy591xIm/AgyM2Er/8I6z+AkmMQlQD9b4CkqRDZ0dMhK9XsOFLV46rj\nH2qMWXYuwblDE3/Ls+lAHlf//RsSO7Ti7R8Pxt/X9SOzpBA2/g/S3oKdiwGB838AF/3cDgOhlHKL\nI1U9xpgK4IV6R6W8Ws92ETwzKZGVGYf53adVxu4PCIH+19m7fe/9Hi5+CPasgNfG2AHfMhwvZyjl\ntdyt418gIpNERByNRrVIE5M6cOvwBGYty+CjtL1nviGqE4x6DO5bD5c8BQfX2zt/Z10G2xeCG9WR\nSin3uVvHfwwIBcqAIkCwdfwRDRmMVvW0XKXlFUx7dQXr9uYy56fD6Nmuhq9O6XFY9TosmwHH9kGn\nC2HsExB/QWOFq1Sz4VivHmNMuDHGxxgTYIyJcC03aNJXLZu/rw8vTBtAeJAfP34jldW7j9Tw5mAY\ncgfcmwaX/QmyN8M/x8LsaTr4m1INoMbELyI3Vnk9/LRtdzkVlGqZ2oQH8fJNAykpq+Caf3zDz/67\nlqxjRWf/gF8gDPox3JMGo35pG4FfHAof/h8crq6jmVLKHTVW9YjIamNM8umvq1tuCFrV4x0Kist4\nfuE2/rl0B0F+vtw7tjs3D0s42ePnrB/MgaV/gZWvQnkxnDcAel0JvSfq+P/KazV4d04RWWOMGXD6\n6+qWG4Imfu+yM7uAp/63gUWbD9GtTRh3jerGqB5taBXiX/MHc/fCunch/SPYt9qua9MHek2AkBgo\nL4HyUtejBEJbw4CbIDDM+ZNSqpE5kfi1xK8ct2DjQX4zN52MnEJ8fYSBnaIY26sNo3u2pWtsKDV2\nJju6BzbNhfSPYfe32BlBqxAfMBUQGmvvERh4i61Caim+ed7eDT3qMU9HojzEicRfCGzD9uLp6nqN\na7mLMSa0nrFWSxO/9yqvMKzNPMrCjVks2JTFxv12HMAurUN5+uq+DOvauvadFOVBRRn4+IFvAPj6\ng48v7PkOFjwJGUvs3cGjfgGJk+225mznEnh9gn095U3ofaVn41Ee4UTi71TTh40xu+pysNpo4leV\n9h49zsJNWfxr2U52ZhfwyPie/HhEl5pL/zUxxt4TsOBJ2L8W2vSGQdPh/HEQ0b5hg28Mxfm2odvH\nDwLDbfXX/y23cyAor+LY6JyNRRO/Ol1+cRkPvbeWT9cd4PLE9vzh2n6EBZ7DmP4VFZD+IXz1e8je\nYte1T7IXgPN/YF/7+NgLRVkxlBba+wrEB4Ii7MxiTeE+xrkPQOpMO+FNcCS8fJGNf8qbTSM+1Wg0\n8asWyRjDq0t28Mxnm+gSG8bLNw2ka+w5NtQaA1kbYcvn9rFnJWAgINw+lxbatoHTia8tYQdGQEgU\ndBkFfSdBu8TGS7jbF8GbV8HQu+AHv7Xrls2w8x5c8yr0m9I4cahzl7cPwtuf03dHE79q0b7Zls1d\n76yhpKyCX1/Rmyv6n0eQfwPV0xfkwLZ5kJlq2wcCQuyNZP6uZ1Nh2xCKj7keeZC3184pXFEGrc+3\nF4C+k6B1d/eOaVwXmMLDUJjjehyG44fhvOTq71QuyoMXh4FfENyxxMYGUFEOs8bDoU22yifivDM/\nu3eVrRJypy0gexus/bc9r7gLILqL/pJoSOVlsPA3sOw5GHgrTPhrvf++jZL4RSQKiDfGfF+nD7pB\nE7+qzb6jx7nz7dWs3XOU8EA/Lktsz1UDOjC4czQ+Ph5ITAU5sPFjWP8+ZCwFDIS1sz2HfPyqPHxt\n19LKqqOSQvv69F5IVZ0/HsY8Dm37nFz38T2w5k247cszLww52+HF4ZAwHKa9dzKRHFgHi34Hmz+1\ny8PuhrFP2Sqt6uxbA29NsheiSsHR9gIQfwH0nABtetX1L6Uq5WfBe7fZzgbt+9s2pzG/ghE/q9fu\nnJyB6yvgSuwcvauALGCZMeaBesR5Vpr4lTvKKwzLd+Twweq9fL5+PwUl5XSIDGZi0nlcPaAD3duG\neyawvP2wYQ5kbbAluooyqCi1pfHyUvALAP9QW0oPqHwOs/cehES7nmPsurX/hqUz7C+LflNg5KNw\neLtNyMPvg0uerD6GFa/AZz+HK/4GHYfatowNH0BgKxh+Nxw7AN+9Bv2nwpXP255PVWUsg39fB8FR\ncNMce6Nc5ne2Z1Tmd3b4DASSbrBdSFvFOf5nbVF2fQvv3gJFR20pv/9UmPMT+P4/cPXL0P/6Ou/S\nycS/xhgzQER+hC3t/1pEvjfG9KtzlDXQxK/q6nhJOV+mH2DOmr0s2ZpNeYWhb4cIrkrqwJVJ59nJ\nX5qrwsO27n7FS/biERBi64Onfw3+Zzmvigp4cyLsXmEvOn7BMOROGHaXTebGwOJnYdFvofsPYPK/\n7H4BtnwB//2h7fJ604fQqsOZ+y/IttUTK16xy4N/AiMesPs+F+VlkH8QwtvVvZttaRGsfh2WPmcv\nqBNfgI5Dav5M3n44ustWqfkF1D9udxkDy/8BXz5uR6Od8ia062u3lZXA29fCrmX2l1rXUXXatZOJ\nfx1wKfA68AtjzHea+FVTc+hYMf9bu485a/aybm8uPgIjusdyTXIHftCnXcO1BzS2vP2w+I+w6RM7\nX3GHWu6bPLobZt8AnS+GCz64odYAABSHSURBVO+3dy6f7rt/wic/g/hBdp/bF9qSZ9u+cOP71X/m\n9GMs+h2snW17O134ACT/0P5yqYviY3Y+5uUvQu5u274S3QViutlhOGK6QWwvaNvbJvWqTozi+hwc\n229/4eTttTf1DbvLju90+gXy+BF7gVjxEpQV2cb8rqNsj6hul0B427rF747MVFj4NOxYZKvJrvoH\nBLU69T1FuTBzvP273vaZ7SxQG2Ngx1dIt9GOJf7JwOPY6p07RaQL8KwxZlJdDlYbTfyqoWzLOsac\nNXv5cM0+9h49TkSQH1cN6MCUlHj6dmhV+w68QfpH8P6PIKytnRKz0zB7EQiqw8C7B9bB/Cdg23zb\nltH5YuhzNfS8vOaLQN5+WPmy7ZJalAsdh9kxl47ts20VOdvg8A7bLgKA2AtCu77QNhF8/WD5S5B/\nADoNh5GPQMIIKMm3pepVs2zD9FUvQdxA+6tg5Suw5M/2eP2vh+6X2mS8dZ69cIDtzhscZS8qle0x\npYW2SqzraNvu0vmis//iqiozFb56xnYaCI62MQ6afvZG3Ny98NpYwMDt8yAy/uz73r0cFvwGdi1F\nnszTXj1KVVXhag/4T+oePlt/gJKyCvp2iOC6lHgu73ce0aGN8DO/Kdu52A533XEoTHn9ZC+hutq/\n1rZvbJgDRzLsRaDLKNsgXFFq74koL7HPhTmw+TMw5dDrChh2T/XTbVaU2xJwVjocWA8HvreT9BzJ\nsNs7XWiTaecRZ3522wL42NWmkXSD7QKbl2mT/Zhfn6xmAVtyPrAOtn4B27+y7RonenS5HkVH7T5K\nC2w7TddR0GO8/TXi6wc+/q47xf3sRWTJX04m/OH3wAU/dm+sqIMbYOY4e/wuI21VVIdk+wvAP9g2\nvC982l5oQ9vARQ8iQ+5wrMTfBZgBDMF2Q/gWuN8Ys6MuB6uNJn7lpKOFJXyUto//fLeH9P15+Agk\nd4xidK82jOnZlvPbhtX/zuDmrKTQJpWGOHdjYH+a6yLwoa1HR2wvJ99AW5/uF2yrVob+ny3F11VR\nHhRm1/7Zolz4/DE7r3OHgTD2yeovEu4qLbI9tzZ/au/9yKtmNrlKdU34Ve1ZCUv/CntX2180YO8f\nie5sfwkFR9kG/kHTISDE0Tr+5cDfgXdcq64H7jbGDK7TCdVCE79qLBv25fLlhoMs3JTFur25AHSI\nDGZUz1hSOkUzoGMkHaNDvPNC0FCMsaV233O407oh5GZCRIeGvQ/BGPvrI2+//UVTXuLqyVVqS/89\nxjfMaLB5++wFYN8a+6ukQ7JtrK/SRuBk4j+jIVdE1hpj+tflYLXRxK884UBuEYs2Z7Fg40GWbcvh\neGk5ANGhASTFR5IUH8nonm20bUA1SU4M0lbZOvMwcASYja3quQ6IMsY8Ws9Yq6WJX3laWXkFWw7m\ns2bPEdJ2HyVtz1G2ZuUDMKRLNNMv6sLI89t45mYxparhROLfiU301X3LjTGmHhV0Z6eJXzVFuYWl\nvLtqDzOX7mRfbhHd24Tx4xFdmDjgPAL9bBdRYwzFZRXkF5dhjP214KsXB9UIGnWsHhHxN8aU1rA9\nHngDaIu9eLxijJlR0z418aumrLS8gk++388ri3eQvj+PyBB/QgP8OFZUSkFJOeUVJ/8viUB0SAAx\nYQG0DgskJiyQmNAAYsPts10XQIeo4OZ9k5nyuPok/jq1uoht6RoN3ABMwCb1sykDfmaMWS0i4cAq\nEZlnjEmvyzGVair8fX24akAHJiadxzfb7ZARIhAW6EdooC+hgX6EBfphDOTkF5NdUGKf80tYl3mU\n7PwS8ovLzthv3w4RXNq7HZf2aUuPtuF1alAuK6/AR0SrnlSduNu4OwSb7K8CooGfAh8bY464fSCR\nj4AXjDHzzvYeLfGrlq6otJycghKyjxWTU1DM5gP5zEs/wJo9RzEGOkaHcGnvtpzfLpxAPx+C/H1P\nPAPsyilgx6ECth8qYEd2PrtzCmkbEcRD43pwRb/zzvkCYIxhV04hy3fksPtwIQM6RjGoczStgmuZ\nB1l5jBN1/L8DJgO7sV055wCpxpjOdQwsAVgM9DXG5J22bTowHaBjx44Dd+1q0Em9lGoWso4VsWBj\nFl9uOMCybTmUlFczF4BLgK8PCa1D6NI6jM6xoSzZeoj1e/PoHx/J45f3IiXB/WETjDHszC5g+Y7D\nrNiZw/IdORzMKwZsdZUx4COQGBfJsK4xDOsawwUJ0c13+IsWyInEnwVsAZ4D/meMKRaRHXVp1BWR\nMOBr4LfGmA9qeq+W+JWCwpIyDheUUFRaQVFpOcVlFRSXllPh+kXQISr4lIbjigrDB2v28uwXmziY\nV8zlie15ZHxP4qNDzti3MYbthwpYviOHFTsPs3xHDoeO2UQfGx7I4M7RDOkSw5Au0cRFhZC25yjf\nbM/hm23ZpO05SlmFIcjfhxHdY7mkV1tG9WxDbHjDT15fUlbB4YIScgqKSYgJJdTNWdeMMV5374UT\nid8XuASYCowBFgFjsSN0nllZeebn/YG5wBfGmL/U9n5N/ErVX2FJGa8s3sHLX++gtLyCyJAA/H0F\nP1/B39cHfx8fW82UbxN924hABneOYUiXGAZ3iaZL69Aak2ZBcRkrMw6zaFMW89MPsi+3CBEYEB/J\nyB5tiArxx9fHBz9fwc9H8PUR/KpZ9vGBvOOlZOfbWHLybYLPPlZCdkEx2ceKySs6mV4iQ/z50YWd\nuXlYAuFBZ1Y5HS8p57+pe3h1yQ6OFZUxuHM0Q7vGMLRrDOe3CW/x7R+O9uoRkUBsg+5UYASwwBhz\nQw3vF+xonoeNMfe5cwxN/EqduwO5RbzxbQZHCkspK6+grMJQWl5BWbkhJNCXQQnRDO4SQ0JM/e9M\nNsaQvj+P+elZLNh0kO8zc+sdb2SIv+3lFBpA6/BAWocGEBMWSOuwQMKC/PhozV4WbMqiVbC9ANwy\n3F4AjhSU8Ma3u3j92wwOF5QwsFMUXVqHsnxnDnsOHwdst9oLEqKIDg08pc0k0N8HPx+hrMJQXm7s\nc4WhwhhSEqK4qHssfr5nmaimiWm07pwiEgFcZYx5o4b3XAgsAdYBlRWWjxljPj3bZzTxK9U85ReX\nUVRqu7SWlldQXnEymVZdLiu36yKC/YgNCyQqNAB/NxLs95lH+duCrczfmEVEkB8je7RhXvpBjpeW\nM6ZnG+4Y2ZULqrRtZB4pZPmOw3y7PYc1u49wzBVfcVkFJWXVt59U/jCoMPbX0OSB8UxJiadjzKlV\nZuUVhoycAjbtP8ahY0UUlJSTX1xGflEZBcVlFJaUU+a6iFReTE68roDyKusFGNatNZMHxtGlnvNI\n65y7SqkWbV1mLjMWbGXx1kNM6Neen1zUlR7t6jbjWkWFocT1S6iyCsrX1SW2pKyChZsO8p/v9vD1\nlkNUGBjaJYaLe8SyK6eA9P3H2HLg2IlhPSr5+wqhgX6EBtiuvb4+Pvj6cGK/viKubrfg62Nf+/oI\nx0vK+S7jMBUGBiVEMzkljssS29fapnG0sIRVu46watcRHh7fSxO/Uko1hP25x3kvNZP/rtrDnsPH\niQzxp1e7CHq1j6BX+3B6tY/gvMhgQgN9T9zBXR8H84r4YPVe3k3dw47sAkIDfBnRPZZWwf4EB/gS\n4noE+fuyLSuf1F1H2OYaRsTPR9j++8s18SulVEOqqDAcKSwhOjTA0R5DxhhSdx3hP9/tYdWuIxQU\nl3G8pJzC0pN3hUcE+TGwUxQpCdEM7BRF/7hIQgL9nLtzV0SGAQlVP1NTHb9SSrUEPj5CTFjDd1k9\nnYhwQUL0KW0VYC8IJeUVFJVUEB7k1yC9lNxK/CLyJtAVSAMqK7cMdiwepZRSDhERAv3OrTrpdO6W\n+FOA3qYp1QsppZSqF3c7qq4H2jkZiFJKqcbhbom/NZAuIiuB4sqVxpgrHYlKKaWUY9xN/E84GYRS\nSqnG41biN8Z87XQgSimlGodbdfwiMkREvhORfBEpEZFyEcmr/ZNKKaWaGncbd1/ADs62FQgGfgT8\n3amglFJKOcft4eeMMdsAX2NMuTFmFjDOubCUUko5xd3G3UIRCQDSROSPwH7qcNFQSinVdLibvG9y\nvfcuoACIByY5FZRSSinnuNurZ5eIBAPtjTFPOhyTUkopB7nbq+cK7Dg9n7uWk0TkYycDU0op5Qx3\nq3qeAAYBRwGMMWlAZ4diUkop5SB3E3+pMeb0STV1wDallGqG3O3Vs0FEbgB8RaQ7cA/wjXNhKaWU\ncoq7Jf67gT7YAdreAfKA+5wKSimllHPc7dVTCPzC9VBKKdWM1Zj4a+u5o8MyK6VU81NbiX8osAdb\nvbMCcG6mYaWUUo2itsTfDrgEO0DbDcAnwDvGmA1OB6aUUsoZNTbuugZk+9wYczMwBNgGfCUidzVK\ndEoppRpcrY27IhIIXI4t9ScAfwPmOBuWUkopp9TWuPsG0Bf4FHjSGLO+UaJSSinlmNpK/DdiR+O8\nF7hH5ETbrgDGGBPhYGxKKaUcUGPiN8bomPtKKdXCaGJXSikvo4lfKaW8jCZ+pZTyMpr4lVLKy2ji\nV0opL+NY4heRmSKSJSLa918ppZoQJ0v8/wLGObh/pZRS9eBY4jfGLAYOO7V/pZRS9ePxOn4RmS4i\nqSKSeujQIU+Ho5RSLZ7HE78x5hVjTIoxJiU2NtbT4SilVIvn8cSvlFKqcWniV0opL+Nkd853gG+B\nHiKSKSK3O3UspZRS7qt1Ipb6MsZMdWrfSiml6k+repRSysto4ldKKS+jiV8ppbyMJn6llPIymviV\nUsrLaOJXSikvo4lfKaW8jCZ+pZTyMpr4lVLKy2jiV0opL6OJXymlvIwmfqWU8jKa+JVSysto4ldK\nKS+jiV8ppbyMJn6llPIymviVUsrLaOJXSikvo4lfKaW8jCZ+pZTyMpr4lVLKy2jiV0opL6OJXyml\nvIwmfqWU8jKa+JVSysto4ldKKS+jiV8ppbyMJn6llPIymviVUsrLaOJXSikvo4lfKaW8jCZ+pZTy\nMpr4lVLKy2jiV0opL6OJXymlvIyjiV9ExonIZhHZJiKPOHkspZRS7nEs8YuIL/B3YDzQG5gqIr2d\nOp5SSin3OFniHwRsM8bsMMaUALOBiQ4eTymllBv8HNx3B2BPleVMYPDpbxKR6cB012KxiKx3MCZP\nag1kezoIB+n5NW96fs1Xj7p+wMnE7xZjzCvAKwAikmqMSfFwSI5oyecGen7NnZ5f8yUiqXX9jJNV\nPXuB+CrLca51SimlPMjJxP8d0F1EOotIAHA98LGDx1NKKeUGx6p6jDFlInIX8AXgC8w0xmyo5WOv\nOBVPE9CSzw30/Jo7Pb/mq87nJsYYJwJRSinVROmdu0op5WU08SullJdpEom/pQ3tICIzRSSr6j0J\nIhItIvNEZKvrOcqTMZ4LEYkXkUUiki4iG0TkXtf6Zn+OIhIkIitFZK3r3J50re8sIitc39H/uDos\nNFsi4isia0Rkrmu5xZyfiGSIyDoRSavs6tgSvpuVRCRSRN4TkU0islFEhtb1/Dye+Fvo0A7/Asad\ntu4RYIExpjuwwLXcXJUBPzPG9AaGAD91/Zu1hHMsBkYbY/oDScA4ERkC/AH4qzGmG3AEuN2DMTaE\ne4GNVZZb2vmNMsYkVem73xK+m5VmAJ8bY3oC/bH/jnU7P2OMRx/AUOCLKsuPAo96Oq4GOK8EYH2V\n5c1Ae9fr9sBmT8fYgOf6EXBJSztHIARYjb3jPBvwc60/5Tvb3B7Ye2oWAKOBuYC0sPPLAFqftq5F\nfDeBVsBOXB1z6nt+Hi/xU/3QDh08FIuT2hpj9rteHwDaejKYhiIiCcAAYAUt5Bxd1SBpQBYwD9gO\nHDXGlLne0ty/o88BDwEVruUYWtb5GeBLEVnlGhIGWsh3E+gMHAJmuarqXhORUOp4fk0h8XsdYy/L\nzb4frYiEAe8D9xlj8qpua87naIwpN8YkYUvGg4CeHg6pwYjIBCDLGLPK07E46EJjTDK2+vinInJR\n1Y3N+buJvfcqGXjRGDMAKOC0ah13zq8pJH5vGdrhoIi0B3A9Z3k4nnMiIv7YpP+2MeYD1+oWdY7G\nmKPAImzVR6SIVN7w2Jy/o8OBK0UkAzti7mhsnXFLOT+MMXtdz1nAHOzFu6V8NzOBTGPMCtfye9gL\nQZ3Orykkfm8Z2uFj4GbX65ux9eLNkogI8E9gozHmL1U2NftzFJFYEYl0vQ7Gtl1sxF4ArnW9rVme\nG4Ax5lFjTJwxJgH7f22hMWYaLeT8RCRURMIrXwOXAutpAd9NAGPMAWCPiFSOyDkGSKeu5+fpxgpX\nY8RlwBZsXeovPB1PA5zPO8B+oBR7hb4dW4+6ANgKzAeiPR3nOZzfhdifkt8Daa7HZS3hHIF+wBrX\nua0HfuVa3wVYCWwD3gUCPR1rA5zrSGBuSzo/13msdT02VOaTlvDdrHKOSUCq6zv6IRBV1/PTIRuU\nUsrLNIWqHqWUUo1IE79SSnkZTfxKKeVlNPErpZSX0cSvlFJeRhO/8ioiUu4atbHy0WCDdYlIQtUR\nWZVqqhybelGpJuq4scMxKOW1tMSvFCfGcP+jaxz3lSLSzbU+QUQWisj3IrJARDq61rcVkTmucfvX\nisgw1658ReRV11j+X7ru/lWqSdHEr7xN8GlVPddV2ZZrjEkEXsCOYAnwPPC6MaYf8DbwN9f6vwFf\nGztufzL2LlGA7sDfjTF9gKPAJIfPR6k60zt3lVcRkXxjTFg16zOwE7DscA1Ad8AYEyMi2dhxzktd\n6/cbY1qLyCEgzhhTXGUfCcA8YyfDQEQeBvyNMU87f2ZKuU9L/EqdZM7yui6Kq7wuR9vRVBOkiV+p\nk66r8vyt6/U32FEsAaYBS1yvFwB3womJW1o1VpBKnSstjShvE+yaXavS58aYyi6dUSLyPbbUPtW1\n7m7sbEc/x858dKtr/b3AKyJyO7Zkfyd2RFalmjyt41eKE3X8KcaYbE/HopTTtKpHKaW8jJb4lVLK\ny2iJXymlvIwmfqWU8jKa+JVSysto4ldKKS+jiV8ppbzM/wNyUeyN7nqSTwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-r0WJONIMf7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "outputId": "c030aa38-f301-4ab9-b811-5a2a8955f196"
      },
      "source": [
        "loss, mse, mae = model.evaluate(normed_test_data, test_labels, verbose=1)\n",
        "print(\"Testing set Mean Abs Error: {:5.2f} MPG\".format(mae))\n",
        "print(\"Testing set Mean Sqr Error: {:5.2f} MPG\".format(mse))"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "78/78 [==============================] - 0s 156us/sample - loss: 6.1147 - mse: 6.1147 - mae: 1.9511\n",
            "Testing set Mean Abs Error:  1.95 MPG\n",
            "Testing set Mean Sqr Error:  6.11 MPG\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUZp4j2wJBcH",
        "colab_type": "text"
      },
      "source": [
        "## Predicciones con el modelo"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srQFrVMhIMiR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "d40d47e3-9b2d-43db-8712-31f1f40fa21d"
      },
      "source": [
        "test_predictions = model.predict(normed_test_data).flatten()\n",
        "plt.scatter(test_labels, test_predictions)\n",
        "plt.xlabel('True Values [MPG]')\n",
        "plt.ylabel('Predictions [MPG]')\n",
        "plt.axis('equal')\n",
        "plt.axis('square') \n",
        "plt.xlim([0,plt.xlim()[1]])\n",
        "plt.ylim([0,plt.ylim()[1]])\n",
        "_ = plt.plot([-100, 100], [-100, 100])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAQAAAAEGCAYAAACKK0t7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjIsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8li6FKAAAgAElEQVR4nO2deZhddZnnP99aQiqGWIREhIKYhGAY\nbJRIBCTqaFxAQE2D4+DY86CdmbjRItLRYDuKSzdRpl2ftm0ENTaIQRNDhNaIBHfFzgYhAZR1pCSG\nrQiBSlLLO3+ccyu3bp1zz6lb99ztvJ/nOU/ds93zVlLve36/d/vJzHAcJ5+01VsAx3HqhxsAx8kx\nbgAcJ8e4AXCcHOMGwHFyTEe9BUjDjBkzbPbs2fUWw3Gaks2bNz9mZjOjzjWFAZg9ezabNm2qtxiO\n05RIeijunE8BHCfHuAFwnBzjBsBxcowbAMfJMW4AHCfHuAFwnBzjBsBxWpjde/aVPe8GwHFalN17\n9nH+139X9ho3AI7TghSUf9dTPgJwnFxRrPzfetcpZa91A+A4LUSp8p8yZ3rZ690AOE6LMF7lBzcA\njtMSVKL84AbAcZqeSpUf3AA4TlMzEeUHNwCO07RMVPnBDYDjNCXVUH5wA+A4TUe1lB/cADhOU1FN\n5Qc3AI7TNFRb+cENgOM0BVkoP7gBcJyGJyvlBzcAjtPQZKn84AbAcRqWrJUf3AA4TkNSC+UHNwCO\n03DUSvnBDYDjNBS1VH5wA+A4DUOtlR/cADhOQ1AP5YcmWR3YcZqRdVt7uWLDPfy5r5+jurtYfsZ8\nlizoGXNdvZQf3AA4Tias29rLpWu30z8wBEBvXz+Xrt0OMMoI1FP5wacAjpMJV2y4Z0T5C/QPDHHF\nhntG9uut/FADAyCpXdJWSTeG+3Mk3SbpXkmrJU3KWgbHqTV/7usve7wRlB9qMwK4CLiraP+zwBfM\nbB7wJLC0BjI4Tk05qrsr9nijKD9kbAAkHQ2cDVwV7gtYDHw/vGQVsCRLGZz8sm5rL4tWbmTOiptY\ntHIj67b21uzZy8+YT1dn+6hjXZ3tLHvV3IZRfsjeCfhF4MPAoeH+4UCfmQ2G+w8DY92igKRlwDKA\nWbNmZSym02qkdcJlReEZxVGAZa+ay6rfPtgwyg8ZGgBJ5wC7zWyzpFeP934zuxK4EmDhwoVWZfGc\nFqecE64WBgACI1B4ViMN+4vJcgSwCHizpLOAycA04EtAt6SOcBRwNFC7cZmTG5KccLUkK+VPm2dQ\njsx8AGZ2qZkdbWazgfOBjWb2DuBW4K3hZRcAN2Qlg5NfyjnhakmWyn/p2u309vVjHJzijNfPUY88\ngI8AH5J0L4FP4Oo6yOC0OHFOuOVnzK+ZDFkO+9PkGaShJpmAZvYz4Gfh5/uB8msWO84EiXLCVTJE\nrpSs5/zVmuJ4KrDTshQ74WpJLRx+R3V30Ruh7OOd4ngqsJN7qpkvUCtvf7WmOD4CcHJNNfMFahnq\nq9YUxw2Ak2suW7+jKvkC9YjzV2OK41MAJ7es29pLX/9A5LnxONMaNcknDW4AnNxSLmSW1pnWzMoP\nPgVwcky5t3waZ1otlb8aWX9RuAFwckOpEnVP6eTJZ8dOAQ6b0jlKuaKU7/RjD6+p8mdV2OQGwMkF\nUUrU2SY628XA0MFas67Odj7xpheVvW/FmjuY1tXJ3v2DNRn2Z1nY5D4AJxdEKdHAsPGcSR30hPP9\ndmlEsQq5AFH37Rsc5tGn99dszp9lYZMbACcXxCnLU/0DI0k1QxaMBIoLa+LuM6iZwy/LwiY3AE4u\nKKdE5YbYcfcdNqWz6jLGkWVhkxsAJxeUU6KonHoIRg3Lz5hPR4SW7N03WLMWY0sW9HD5uSfS092F\ngJ7uLi4/90SPAjhOWuJSZwFEMKQv5ajuLk4/9nCGI04ODFvdugtVEzcATm6IUqJFKzdGKr9gpIFn\nlAGA+nQXqjY+BXByTTknX6GB54yp0UtX1Lq7UBa4AXByTZwSd7RpJMnnY2efUPfuQlnhBsDJNVHO\nQQFtbRqJ82fphKs3Mmv8jtsLFy60TZs21VsMpwWISuuFwDnY29dPR5toaxPXLD216Qp74pC02cwW\nRp1zJ6DTshSUvbevn3aJIbNRHv9Cws/l557ID953elNX9VWKGwCnJSnN4S9k+ZWOd/sHhlj5o7uZ\nckh77pQf3AA4LUpUdl8cu/bsY8qk9twpP7gBcJqUpPr48cToBblUfvAogNOEpFkVZzwx+gsXz8ul\n8kOCAZC0J2F7WtIfaiWs40C6VXGiwnulCPi7xfO45A3NH8+vlKQpwH1mtqDcBZK2VlEexynLuq29\nZYt3ChTn/hdHAZ4/bTLDZjVr5tHoJBmA81J8R5prHGfCFIb+cZQO+0tz/5u9gWcWlJ0ChOv4lSXN\nNY5TDcp59pNSc135o0nyASyVtLxov7do7v+e7MVznIOU8+yfd3IPV2y4J3J5L1f+eJKmAO8Bziza\n321mPZImAxuAr2UmmeMUsW5rL23hPL6Uw6Z0smZzb2TX3Fp2721GkgyAzOzxov3vAZjZPknNXwvp\nNAWFuX+U8nd1tmNGZFQgzxl+aUnKA+gu3jGzfwKQ1AbMyEooxykmbu7fLnH5uSfyVMzyXrv27OOB\nR5/h2QNDXLx6W2QLr2quDNyMJBmAn0j6TMTxTwE/yUAexxlD3Nx/2IwlC3rKJv2UFv4UK3iahKJW\nJ8kALAfmSbpX0ppwuxeYB/x99uI5eaT0rfzcrugOvAXFT5P0A2OThdIkFLU6ZX0AZvYMcL6kuUBh\nuZSdZnZf5pI5uSRyBZ920QYMF13X2aaRsF8h1r/yR3eza8++2CafMHo0keWCG81CUhjweZK+CHwZ\nOB34uSu/kyWRK/gM2SjlB4I83iJOP/ZwphzSzpRJ7ax+98tHVvsppXi6kOWCG81C0hTg28AzwFeA\nqQSGIBWSJkv6vaTbJe2Q9Mnw+BxJt4XTitWSojsuOrkk7dt3YMhGhupRcf40i2lkueBGs5AUBjzS\nzP4h/LxB0pZxfPd+YLGZ7ZXUCfxK0o+ADwFfMLPvSvoasBT413FL7rQkcSv2RvHnvv5Ryr/0FXO4\nePW2kRLh807u4da7H40tGY5bK6AVev2lJbEfgKTDODjgai/eN7Mn4u6zoNng3nC3M9wMWAz8j/D4\nKuAy3AA4IeNpUXnEtMmjlP+qXz4wynewZnNvYvPOqLUCknoNtBJJU4DnApuLtmnAlvBzYpdOSe2S\ntgG7gZuB+4A+MxsML3kYiPyXlbRM0iZJmx599NE0v4vTAsTF9EuZ3NHGsNnIsH/tlt6qePTzFhpM\nKgaabWZzzWxOxDY36cvNbMjMTgKOBk4Bjk8rmJldaWYLzWzhzJkz097mNDnlHHDtEgKeP20y07o6\nR5X0Vsujn7fQYFIU4KXltrQPMbM+4Fbg5UC3pMLU42igNU2rUxGvOT7e2A+bcdtHX8uUQ9rH1PNX\ny6Oft9Bgkg9gE3An8Fi4Xxx8KcznI5E0Exgws76wbuD1wGcJDMFbge8CFwA3VCa604rcenf8dK94\nzl+a27/8jPmj8gegMo/+Ud1dkQ1HWjU0mGQAPkSgrP0ECvsDM9tb/pYRjgRWSWonGGlcb2Y3StoJ\nfDdMMd4KXF2Z6E6zE+VsK/emLZ7zlxb2VMujXy1D0iykWhkozAQ8H3gL8BDwT2a2LWPZRvCVgRqb\nSrzmpRl/ECjaIR1t9EU4AtsEkztr07q71aIAE14ZyMzul3QD0AX8T+CFQM0MgNO4RKXuFmrxyylN\nnLNtcmcbXZ3to84J6Ghvq1lJb1RosFVJcgLOlfRRSbcBnwRuB/6LmV1fE+mchqdSr3ncUL/v2YGR\nhTghWKW3s6ONd79qLhev3pbbst2sSBoB3AvcQeCo2wPMAt4rBb5AM/t8ptI5DU+lXvMkZ9vQsI38\nXHz8zDFJPmlGGU4ySYlAnwJ+QFCINRU4tGRzck6l4be4PPzXHD+TFWvuYNeefUAQarp55+5cxeZr\nSVI58GU1ksNpUir1msd57Vf+6G72DY6u/UtT2utURlkDIGmZmV050Wuc1mW84bdyHvbde/aNvPnT\n0Kqx+VqS5ANYIemxMucFXAS4Acgxab3m5SIGhe69cc08So+3cmy+liQZgJ8Db0q45uYqyeK0OHER\ng+LuvRcunjfK4QeBsieV9jqVkeQDeFetBHFan7g5+649+5gy6WCSz7Ezp7ZUIk4jkyoRyHGqQVzo\nTzAqySdPiTj1JikM6DhVI65774WL53HKnOm579FfD3wE4FSNpBz6qO69Fy6exyVvmF9xSrEzMVIZ\nAEkXAd8EngauAhYAK8zMFwdxgHgP/6aHnhjlvFv2qrkj3XuLh/1xDsJLrr8dcCOQFWmnAH9rZnuA\nNwCHERQErcxMKqfpiFPga3/3/0a117ps/Q4efrJ/TGFPnINwyKylW3LVm7QGoNAI5Czg381sB2M6\nszt5Jk6BS2P6Bkyb3DGmqq9cUo+n/WZHWgOwWdJPCAzABkmHwti1Gpz8Mp6svMf3HhhzLGl5L0/7\nzYa0BmApsAJ4mZk9C0wCPEegScnC2x6lwHFDxChjsWRBD5efeyLtir7L036zIW1DkGFJfwFOKGro\n6TQhWXnbo2oCTp07nR9s6U2dwlv4jjy15Ko3aVuCfRb478BOoPA/Y2b25gxlG8FbglWPRSs3Ribj\n9HR38esVsT1ex01hxZ6Hn+xn2uQOHt97gKO6u3jN8TNHogLP7epECpqAFIcNW60lV72ZcEswYAkw\n38z2V08spx7Uou118XJd1yw9dcThVzr6KO79VzoScYWvDWl9APcTLO3lNDlZr4gbtVBngahQYTHu\n7a89aUcAzwLbJN1CsOgnAGb2gUykcjJjom2vk+r5S5W/+Po0y/65t7+2pDUA68PNaXKWLOhh00NP\ncN1tf2LIjHaJ806uXj1/qfKXGpsk3NtfW9JGAVZJmkTQDhzgHjNLt4qj01Cs29rLms29DIXO3yEz\n1mzuZeELpicagTT1/EnpveVwb3/tSVsL8GqCpbwfJAjvHiPpAjP7RXaiOVlQro13wQDEDfOT6vmX\nvmIOF6/eNnJfVLShgCA2CuDUjrRTgH8G3mBm9wBIeiFwHXByVoI52ZAUBSg3zC9Xz7/0FXPGtO6O\na+9V7ZCjUzlpowCdBeUHMLM/4FGBpiQpClBuhFCunn/tlt4x9xljswF9mN9YpDUAmyRdJenV4fZ1\ngpWDnSZj+Rnz6WwfrZad7RpRynIjhEK67vOnTQYC5f67sJ6/XDFQT3cXCn9efu6JPsxvINJOAd4L\nvB8ohP1+CXw1E4mc7Ikq0QtJWrHn9GMPj6znj7vPh/uNTaoRgJntN7PPm9m54fYFzwpsTq7YcA8D\nw6MtwMCwjSTgxK3Ys/yM+WWTfMrd5zQuSQuDXG9mb5O0nQh/jpm9ODPJnKpQ6tGP88wXhvBxC308\n1T/A6Ss3MjhszJg6acyQf7wLhDiNQdliIElHmtkjkl4Qdd7MHspMsiK8GKgyohJxKvHMr/rNg1y2\nfseYqj6fzzcH5YqByk4BzOyR8OP7zOyh4g14X7UFdapLlEe/nGc+qk/A7j37+PSNO8cYDc/bbw3S\nOgFfD3yk5NgbI445DUSSZ754qA6Mif+vWHMH07o6GRyOHiWWfr+X8TYfST6A9xK86Y+VdEfRqUOB\n32QpmDNx4ub83V2dY4b7i1ZuHDNa2Dc4zP6n9zNj6iQei2jjVZxT4G29m5OkKMB3CNYGvCH8WdhO\nNrN3ZCybM0GWnzGfzraxLbaeOTA4pg1YudHCx84+IdHDXy6ByGlcknwAT5nZg8CXgCeK5v+Dkk4t\nd6+kYyTdKmmnpB3h2gJImi7pZkl/DH8eVq1fxhnNkgU9TOoY+188MGRjFDMuQ7Cnu2skAahcQk8t\nGo041SetD+BfgZcW7e+NOFbKIHCJmW0JuwhvlnQz8E7gFjNbKWkFQbNR9yVkwLqtvTxzILoar7ev\nnzkrbhqZqy8/Yz4r1tzBvsGDzZ6L3/JJXXqSEoicxiT1ugBWFC80s2GSVxZ+xMy2hJ+fBu4CeoC3\nEFQWEv5cMl6hnXiKPfmFVXXiKCzWcena7TzVP8C0rs6RCMF403Y9Eag5STsCuF/SBwje+hA4Bu9P\n+xBJswmWE7sNOKIovLgLOCLmnmXAMoBZs2alfVSuKXXEDaVo+ArBXP3TN+5kUkcbq9/98jGLdqTB\nE4Gak7RdgZ8HfBlYTPDiuAX4oJntTnHvVODnwD+a2VpJfWbWXXT+STMr6wfwRKB0xHX8HQ89CYrr\nob7mY8JdgUNFP7+CB3cCa4BrzWxtePgvRRmGRwKJRsQpT0Ep0yh/XCZggXLhOw/1tR5lfQCSPhz+\n/IqkL5duCfcKuBq4y8w+X3RqPXBB+PkCghCjUyEFpUyj/O0Spx87PTI0WExc+M5Dfa1H0gjgrvBn\nJePvRQSrCG+XtC089lGCVYWvl7QUeAh4WwXf7YSMp+/ekBm/f+DJVL6BqPCdh/pajyRP/g/Dn6vK\nXRdz76+IXx7uteP9PieacsrXLo1R9tJS4Diiwnce6ms9klKBf0iZKWOtlgZz4inXiKPSN3Nc+G6i\nawo4jUdSHsD/JWgI+gDQD3w93PYC92UrmpOGcvH38byZ26XEtl1pMgKd5iJpCvBzAEn/XBJG+KEk\nj8vVidJQ3Hkn94wsuFkamkuzMEdnm5g6uYO+Z5OXevB1+1qLtIlAz5E018zuB5A0B3hOdmI5cUSF\n4tZs7o18Ey9Z0MNT/QN8Yv2O2O/r7urkmQODPBkqv4f28kXaVOCLgZ9J+pmknwO3Ah/MTiwnjvGE\n4nbv2ce/3Hpv7Hf1dHfxnEM6GBga7ebx0F5+SJsI9GNJxwHHh4fu9qag9SFtKG73nn2c85Vfsfvp\n6P+mgp/g4tXbIs97aC8fpBoBSJoCLAcuNLPbgVmSzslUMieSNMt7F7r3Phqj/O3SyJQh6+XCncYm\n7RTgm8AB4OXhfi/wmUwkcsqSVHVX3Lo7Ln47bDYyv/cqvnyT1gAca2afAwYAzOxZ4pN8nAwpDsVB\n8DYvzNlX/ebBUX37e1K83T20l2/SRgEOSOoiTAqSdCzgPoA6ERXi6+3r57L1O+jsaOOapafy575+\nnj0wOObeqLe7h/byS1oD8AngxwTLgl9LkOf/zqyEyiNpymyLr2mLSPM1YNrkDv4chvJKowXdXZ1c\n9uYXubI7IyQagLCq727gXOA0gqH/RWb2WMay5YY0ZbZpm308vvdAbIHQcw7pcOV3RpHoAwhbgf2H\nmT1uZjeZ2Y2u/NUlTWw/bdXfUWVqADy055SS1gm4RdLLMpUkx6RR2DTKm1QD4KE9p5S0BuBU4HeS\n7pN0h6TtJQuFOBMgjcLGXdMGY7z3Htpz0pLWCXhGplLknDRltlHXTGpv43NvfXFkDQB4g04nmaR+\nAJOB9wDzgO3A1WY2NrbkTIglC3rY9NATXHfbnxgyo13ivJNHh+YKhT2fvnHnyBLdHzv7hFil9tCe\nk4akKcAqYCGB8r+RoDeAU2XWbe1lzebeEc/+kBlrNveOWr6rUNgzFHb0OaSjPfK7HGc8JBmAE8zs\nb8zs34C3Aq+sgUy5IykKUFzYUwj+FUKFpWv8Oc54SPIBjHSIMLPBICXAqTZxHv7evn5mr7iJjjZF\nLtHdPzDEJdffzsWrt/k836mIJAPwEkl7ws8CusJ9EaQITMtUupwQ19evQJTyFyhMG7yRh1MJSasD\nt5vZtHA71Mw6ij678leJqLBdJXgjD2e8pM0DcDJkyYIezju5h/YqTLE8288ZD24AGoB1W3tZ/Z9/\nSrVgR6FsN85YeLafMx7SJgI5VaS08u/JZ/aP6csXx69XLB75Du/R70wUNwA1JqryrxI828+pBm4A\nasx41vIrpburc9S+Z/s5E8V9ADWmUiddZ5u47M0vqrI0Tt5xA1BjxuukK1T6XfHfXuJve6fq+BSg\nxkRV9cXR09014vRznCzwEcAEWLe1l0UrNzJnxU0sWrkxVV7+kgU9rHjj8XS0BWG8GVMn8TenzfL6\nfacu+AigQtL08Yti9559rPrtg0zqaOM77zqFU+ZMB2DhC6a7R9+pOW4AKqRcBV+c4hYv2vGtIuUH\n9+g79cENQIWUq+BbtHLjmDd5OeV3nHrhBqBC4ir4xMHknsK04Kn+AVb99kFXfqfhcCdghURV8AnG\nrMfXPzDEp2/c6crvNCSZGQBJ35C0W9KdRcemS7pZ0h/Dn4dl9fysiVpTLy6bf3DYXPmdhiTLEcC3\ngDNLjq0AbjGz44Bbwv2mZcmCHn69YjEPrDybX69YHLsY54ypk1z5nYYkMwNgZr8Anig5/BaCRqOE\nP5dk9fx6EDUtmNTexsfOPqFOEjlOeWrtAzjCzB4JP+8Cjqjx8zMlKsknqm+/4zQKdYsCmJlJii2C\nl7QMWAYwa9asmsk1EeKSfBynUan1COAvko4ECH/ujrvQzK40s4VmtnDmzJk1E7BSPM7vNCO1NgDr\ngQvCzxcAN9T4+Zngyu80K1mGAa8DfgvMl/SwpKXASuD1kv4IvC7cb2pc+Z1mJjMfgJm9PebUa7N6\nZq1x5XeaHc8ErBBXfqcVcANQAa78TqvgBmCcuPI7rYQbgHHgyu+0Gm4AUuLK77QibgBS4MrvtCpu\nABJw5XdaGTcAZXDld1odNwAxuPI7ecANQASu/E5ecANQgiu/kyfcABThyu/kDTcAIa78Th5xA4Ar\nv5Nfcm8AXPmdPJNrA+DK7+Sd3BoAV37HyakBcOV3nIDcGQBXfsc5SK4MgCu/44wmNwbAld9xxpIL\nA+DK7zjRtLwBcOV3nHha2gC48jtOeVrWALjyO04yLWkAXPkdJx0tZwBc+R0nPS1lAFz5HWd8tIwB\ncOV3nPHTEgbAld9xKqPpDYArv+NUTlMbAFd+x5kYTWsAXPkdZ+I0pQFw5Xec6tB0BsCV33GqR1MZ\nAFd+x6kuTWMAXPkdp/rUxQBIOlPSPZLulbQi6frBIXPld5wMqLkBkNQO/AvwRuAE4O2STih3z/2P\n7XXld5wMqMcI4BTgXjO738wOAN8F3lLuhoEhc+V3nAzoqMMze4A/Fe0/DJxaepGkZcCycHf/qXMP\nv7MGslWTGcBj9RZinLjMtaOWcr8g7kQ9DEAqzOxK4EoASZvMbGGdRRoXLnNtaEaZoXHkrscUoBc4\npmj/6PCY4zg1ph4G4D+B4yTNkTQJOB9YXwc5HCf31HwKYGaDki4ENgDtwDfMbEfCbVdmL1nVcZlr\nQzPKDA0it8ys3jI4jlMnmiYT0HGc6uMGwHFyTEMbgPGmDNcLSd+QtFvSnUXHpku6WdIfw5+H1VPG\nUiQdI+lWSTsl7ZB0UXi8YeWWNFnS7yXdHsr8yfD4HEm3hX8nq0PnckMhqV3SVkk3hvsNIXPDGoBK\nUobryLeAM0uOrQBuMbPjgFvC/UZiELjEzE4ATgPeH/77NrLc+4HFZvYS4CTgTEmnAZ8FvmBm84An\ngaV1lDGOi4C7ivYbQuaGNQBUkDJcL8zsF8ATJYffAqwKP68CltRUqATM7BEz2xJ+fprgj7OHBpbb\nAvaGu53hZsBi4Pvh8YaSGUDS0cDZwFXhvmgQmRvZAESlDPfUSZZKOMLMHgk/7wKOqKcw5ZA0G1gA\n3EaDyx0OpbcBu4GbgfuAPjMbDC9pxL+TLwIfBobD/cNpEJkb2QC0DBbEWhsy3ippKrAG+KCZ7Sk+\n14hym9mQmZ1EkEF6CnB8nUUqi6RzgN1mtrneskTRsLUANH/K8F8kHWlmj0g6kuCN1VBI6iRQ/mvN\nbG14uOHlBjCzPkm3Ai8HuiV1hG/URvs7WQS8WdJZwGRgGvAlGkTmRh4BNHvK8HrggvDzBcANdZRl\nDOE89GrgLjP7fNGphpVb0kxJ3eHnLuD1BL6LW4G3hpc1lMxmdqmZHW1mswn+hjea2TtoFJnNrGE3\n4CzgDwTzvH+otzxl5LwOeAQYIJjPLSWY590C/BH4KTC93nKWyPwKguH9HcC2cDurkeUGXgxsDWW+\nE/h4eHwu8HvgXuB7wCH1ljVG/lcDNzaSzJ4K7Dg5ppGnAI7jZIwbAMfJMW4AHCfHuAFwnBzjBsBx\ncowbAMfJMW4AGgRJh0vaFm67JPUW7VelVFTSoZIeD9N/i4/fKOm8Mve9TtK6asgQ8/3XSHpA0v8K\n9z8jycIahcI1fx8eOyncf1jSdkl3SPqxpOeFxw+V9G+S7pO0RdImSX8bnpsf/nv2ZfW7NBtuABoE\nM3vczE6yIM/9awSloieF2wEIsvckVfx/ZkHV3y0UVVWG9f6nATdN7DeYMBeb2VVF+9sJMucKnMfo\nclqAV5rZiwkSgwply98E/gIcZ2YvJUhumgFgZvcAdW/F3Ui4AWhwJM0Lm3ZcC+wAjil+g0k6X1Kh\nzPQISWvDt97vw1r5Uq5jrGLdZGb7JJ0m6bdh44pfSzouQp7PSPpg0f7dYbkrki4In7tN0lcltUnq\nkPTv4dv6TkkfSPmrrwX+OvzeFxIsolFacl3gF8A8SfOBlwCXmdkwgJntNrPPpXxm7nAD0BwcTzAi\nOIHyRSNfBj5nwYITbyOsPy/hP4BTizr9nE9gFCB4w77SzBYAnwY+k1ZASX9FoLCnh6OYjvC7TwZm\nmNmJZvZXwLdTfmUfsEvS8cDbCfpBRD1XwDkEI4YXAdsKyu8k08jVgM5B7jOzTSmuex0wP9AJAA6T\n1GVm/YUDZrZf0k3AuWF7qhcR5PwDdAPflnRsBTK+DngZsCl8fhdBP4cNoUxfJphm/GQc37mawIi8\nCfivwHtLzv+SoMZ+G0GHndcVn5T0ceBc4HAzOwZnDG4AmoNnij4PAyran1z0WcApBZ9BGa4DlhMo\n6Q/sYGOKfwQ2mNlXJc0Dfhxx7yCjR46F54tgjYf/U3qDpBcTtHZ7P8GUY1npNTGsJxiV/MbM9hYZ\ntgKvNLPi6dAO4CRJbWY2bGafAj4laW/pjU6ATwGajHB4+6Sk40KH4F8Xnf4pgZIBUPCYR3ALwZv/\nPRwc/gM8l4NTjHfG3PsgwbAeSadwsGfDT4G3SZoRnjtc0ixJMwnWn/ge8HHgpSl+TQAsaP/1EeDy\nlNffQzAV+GTBWSppMqMNphDxFqIAAAC8SURBVFOEG4Dm5CMEQ+vfEJQfF3g/sCgMje0E/nfUzWY2\nROBkmwb8qujUZ4ErJG0hXmm+BxyhoAPyMuD+8Du3A58EfirpDoKh/hEEBuIXCtp4fRP46Hh+UTP7\njpltG8ct7wKeD9wnaRNB27BLxvPMPOHlwE7dkXQN8H0zyyzXoOhZHcBjZtad9bOaAR8BOI1AH3B5\nIREoK8Iw4SaCPAEHHwE4Tq7xEYDj5Bg3AI6TY9wAOE6OcQPgODnm/wNKLMs5RxjwdQAAAABJRU5E\nrkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KxwCOq9aIMoP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "outputId": "7931c154-219e-4a1d-bbfa-f06a43b3f400"
      },
      "source": [
        "error = test_predictions - test_labels\n",
        "plt.hist(error, bins = 25)\n",
        "plt.xlabel(\"Prediction Error [MPG]\")\n",
        "_ = plt.ylabel(\"Count\")"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nz/wAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "73yrgtUI-Y7y",
        "colab_type": "text"
      },
      "source": [
        "===========================================\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjwjDIuXeS_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Sequential\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import MaxPooling2D\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z7SShiqCGM8g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-fqZVN9F18n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJLHWHNueTZH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "putRyHXReTb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import to_categorical\n",
        "\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n",
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "train_images = train_images.astype('float32') / 255\n",
        "\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n",
        "test_images = test_images.astype('float32') / 255\n",
        "\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "print (train_images.shape)\n",
        "print (train_labels.shape)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jt2EkwxuQf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer='sgd',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels,\n",
        "          batch_size=100,\n",
        "          epochs=5,\n",
        "          verbose=1)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p_6zyoOJ1lHu",
        "colab_type": "text"
      },
      "source": [
        "## Datos Fashion-MNIST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ybltm0ul14JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6FGwIXd14WJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat', 'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v6I04A_S14ZE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "c\n",
        "test_images = test_images.astype('float32') / 255"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F0Nj5zs-2sQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (5, 5), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Conv2D(64, (5, 5), activation='relu'))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10, activation='softmax'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sRiC2Hnq2sTr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBDazX0d2sYp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
        "print('Test accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "L5XbYrrHKO5E",
        "colab": {}
      },
      "source": [
        "predictions = model.predict(test_images)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TTPAeEl45iNx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def plot_image(i, predictions_array, true_label, img):\n",
        "  predictions_array, true_label, img = predictions_array, true_label[i], img[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "\n",
        "  plt.imshow(img, cmap=plt.cm.binary)    \n",
        "\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "  if predicted_label == true_label:\n",
        "    color = 'blue'\n",
        "  else:\n",
        "    color = 'red'\n",
        "\n",
        "  plt.xlabel(\"{} {:2.0f}% ({})\".format(class_names[predicted_label],\n",
        "                                100*np.max(predictions_array),\n",
        "                                class_names[true_label]),\n",
        "                                color=color)\n",
        "\n",
        "def plot_value_array(i, predictions_array, true_label):\n",
        "  predictions_array, true_label = predictions_array, true_label[i]\n",
        "  plt.grid(False)\n",
        "  plt.xticks(range(10))\n",
        "  plt.yticks([])\n",
        "  thisplot = plt.bar(range(10), predictions_array, color=\"#00FF00\")\n",
        "  plt.ylim([0, 1])\n",
        "  predicted_label = np.argmax(predictions_array)\n",
        "\n",
        "  thisplot[predicted_label].set_color('red')\n",
        "  thisplot[true_label].set_color('black')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U6O2NNvyKd6s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape((60000, 28, 28))\n",
        "test_images = test_images.reshape((10000, 28, 28))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "STCV3LC-57tg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_rows = 7\n",
        "num_cols = 2\n",
        "num_images = num_rows*num_cols\n",
        "plt.figure(figsize=(2*2*num_cols, 2*num_rows))\n",
        "for i in range(num_images):\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+1)\n",
        "  plot_image(i, predictions[i], test_labels, test_images)\n",
        "  plt.subplot(num_rows, 2*num_cols, 2*i+2)     \n",
        "  plot_value_array(i, predictions[i], test_labels)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Y56EnBLQUm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images.reshape((60000, 28, 28, 1))\n",
        "test_images = test_images.reshape((10000, 28, 28, 1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5vu0mAps6wNt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#cal canviar l'especificació\n",
        "\n",
        "model = keras.Sequential([\n",
        "    keras.layers.Conv2D(64, 7, activation=\"relu\", padding=\"same\", input_shape=(28, 28, 1)),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.Conv2D(128, 3, activation=\"relu\", padding=\"same\"),\n",
        "    keras.layers.MaxPooling2D(2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(64, activation=\"relu\"),\n",
        "    keras.layers.Dense(10, activation=\"softmax\")\n",
        "    ])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G1qOIHnyL_Te",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model.compile(optimizer='sgd',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UR6POPWWMAoU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Comentari de que anterior capitol hem comentat això de l' Adam\n",
        "model.compile(optimizer='adam',\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model.fit(train_images, train_labels, epochs=5)\n",
        "\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels)\n",
        "print('\\nTest accuracy:', test_acc)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}